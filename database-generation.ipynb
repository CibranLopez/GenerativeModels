{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a69f99f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-11T07:44:12.390461Z",
     "start_time": "2024-10-11T07:44:05.261111Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/claudio/cibran/Work/UPC/GenerativeModels/venv/lib/python3.12/site-packages/matplotlib/projections/__init__.py:63: UserWarning: Unable to import Axes3D. This may be due to multiple versions of Matplotlib being installed (e.g. as a system package and as a pip package). As a result, the 3D projection is not available.\n",
      "  warnings.warn(\"Unable to import Axes3D. This may be due to multiple versions of \"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import json\n",
    "import os\n",
    "\n",
    "from libraries.dataset        import standardize_dataset\n",
    "from libraries.graph          import graph_POSCAR_encoding\n",
    "from libraries.structure      import compute_diffraction_pattern\n",
    "from torch_geometric.data     import Data\n",
    "from pymatgen.core            import Structure, Molecule, Lattice\n",
    "\n",
    "# Checking if pytorch can run in GPU, else CPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87e9c0c85579db94",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-11T07:44:44.870717Z",
     "start_time": "2024-10-11T07:44:44.784246Z"
    }
   },
   "outputs": [],
   "source": [
    "# In case database is created from scratch (otherwise, it is not being used)\n",
    "data_path = '/home/claudio/cibran/Work/UPC/CLUE/Loaded_PhaseTransition'\n",
    "\n",
    "# Type of data in folder\n",
    "data_type = 'POSCAR'  # 'POSCAR' or 'xyz'\n",
    "\n",
    "# Define diffraction type (None, 'neutron', 'xrd', 'EPA' or other)\n",
    "targets = ['H', 'Cv', 'gap']\n",
    "\n",
    "# Define folder in which all data will be stored\n",
    "data_folder = f'QM9-all-linked'\n",
    "\n",
    "encoding_type      = 'all-linked'  # 'voronoi', 'all-linked' or 'sphere-images'\n",
    "distance_threshold = None  # 6, used in general\n",
    "periodicity        = None  # Better False for molecules, always True for crystals\n",
    "\n",
    "# Define basic dataset parameters for tracking data\n",
    "dataset_parameters = {\n",
    "    'input_folder': data_path,\n",
    "    'output_folder': data_folder,\n",
    "    'target': targets,\n",
    "    'encoding_type': encoding_type,\n",
    "    'distance_threshold': distance_threshold\n",
    "}\n",
    "\n",
    "if not os.path.exists(data_folder):\n",
    "    os.system(f'mkdir {data_folder}')\n",
    "\n",
    "# Dump the dictionary with numpy arrays to a JSON file\n",
    "with open(f'{data_folder}/dataset_parameters.json', 'w') as json_file:\n",
    "    json.dump(dataset_parameters, json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4118e7c81dc9ba3",
   "metadata": {},
   "source": [
    "# Generation of graph database for training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d14155aab014776a",
   "metadata": {},
   "source": [
    "Load the datasets, already standardized if possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025973a4-b7a2-4114-8ec1-89bac3de9d87",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-10-11T07:44:45.935483Z"
    },
    "is_executing": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Generate the raw dataset from scratch, and standardize it\n",
    "\n",
    "# Read all materials within the database\n",
    "materials = os.listdir(data_path)\n",
    "\n",
    "dataset = []\n",
    "for material in materials:\n",
    "    try:\n",
    "        # Try to read the polymorphs\n",
    "        polymorphs = os.listdir(f'{data_path}/{material}')\n",
    "    except:\n",
    "        continue\n",
    "    \n",
    "    print(material)\n",
    "    for polymorf in polymorphs:\n",
    "        # Path to folder containing the POSCAR\n",
    "        path_to_POSCAR = f'{data_path}/{material}/{polymorf}'\n",
    "        \n",
    "        # Check that the folder is valid\n",
    "        if os.path.exists(path_to_POSCAR):\n",
    "            print(f'\\t{polymorf}')\n",
    "            \n",
    "            try:\n",
    "                if data_type == 'POSCAR':\n",
    "                    # Load pymatgen structure object\n",
    "                    structure = Structure.from_file(f'{path_to_POSCAR}/POSCAR')\n",
    "                elif data_type == 'xyz':\n",
    "                    molecule  = Molecule.from_file(path_to_POSCAR)\n",
    "                    \n",
    "                    # Define the molecule within a [100, 100, 100] POSCAR lattice\n",
    "                    structure = Structure(Lattice.cubic(100), molecule.species, molecule.cart_coords, coords_are_cartesian=True)\n",
    "                    \n",
    "                    with open(path_to_POSCAR, 'r') as file:\n",
    "                        lines = file.readlines()\n",
    "                    properties_values = lines[1].split()\n",
    "                    \n",
    "                    properties_tags = ['tag', 'index', 'A', 'B', 'C', 'mu', 'alpha', 'homo', 'lumo', 'gap', 'r2', 'zpve', 'U0', 'U', 'H', 'G', 'Cv']\n",
    "                    \n",
    "                    graph_level_data = {properties_tags[i]: properties_values[i] for i in enumerate(properties_tags)}\n",
    "                \n",
    "                nodes, edges, attributes = graph_POSCAR_encoding(structure,\n",
    "                                                                 encoding_type=encoding_type,\n",
    "                                                                 distance_threshold=distance_threshold,\n",
    "                                                                 periodicity=periodicity)\n",
    "            except:\n",
    "                print(f'Error: {material} {polymorf} not loaded')\n",
    "                continue\n",
    "\n",
    "            extracted_target = []\n",
    "            for target in targets:\n",
    "                if target == 'EPA':\n",
    "                    # Load ground state energy per atom\n",
    "                    extracted_target.append(float(np.loadtxt(f'{path_to_POSCAR}/EPA')))\n",
    "                elif target == 'bandgap':\n",
    "                    # Load band-gap\n",
    "                    extracted_target.append(float(np.loadtxt(f'{path_to_POSCAR}/bandgap')))\n",
    "                elif (target == 'neutron') or (target == 'xrd'):\n",
    "                    # Compute diffraction pattern from given structure\n",
    "                    extracted_target.append(compute_diffraction_pattern(structure, diffraction=target))\n",
    "                elif None:\n",
    "                    # Do not extract anything\n",
    "                    extracted_target.append(0)\n",
    "                else:\n",
    "                    extracted_target.append(float(graph_level_data[target]))\n",
    "            \n",
    "            # Construct temporal graph structure\n",
    "            graph = Data(x=nodes,\n",
    "                         edge_index=edges.t().contiguous(),\n",
    "                         edge_attr=attributes.ravel(),\n",
    "                         y=torch.tensor(extracted_target, dtype=torch.float),\n",
    "                         label=f'{material} {polymorf}'\n",
    "                        )\n",
    "\n",
    "            # Append to dataset and labels\n",
    "            dataset.append(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2cba29cab841e5e",
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "# Standardize dataset\n",
    "dataset_std, labels_std, dataset_parameters = standardize_dataset(dataset, transformation='inverse-quadratic')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64167d60-b767-42cd-881f-dba4f0a102cb",
   "metadata": {},
   "source": [
    "# Save dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4233942ef25f557",
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "dataset_name                = f'{data_folder}/dataset.pt'\n",
    "dataset_name_std            = f'{data_folder}/standardized_dataset.pt'\n",
    "dataset_parameters_name_std = f'{data_folder}/standardized_parameters.json'  # Parameters for rescaling the predictions\n",
    "\n",
    "torch.save(dataset,     dataset_name)\n",
    "torch.save(dataset_std, dataset_name_std)\n",
    "\n",
    "# Convert torch tensors to numpy arrays\n",
    "numpy_dict = {}\n",
    "for key, value in dataset_parameters.items():\n",
    "    try:\n",
    "        numpy_dict[key] = value.cpu().numpy().tolist()\n",
    "    except:\n",
    "        numpy_dict[key] = value\n",
    "\n",
    "# Dump the dictionary with numpy arrays to a JSON file\n",
    "with open(dataset_parameters_name_std, 'w') as json_file:\n",
    "    json.dump(numpy_dict, json_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
