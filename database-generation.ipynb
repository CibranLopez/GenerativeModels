{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a69f99f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-18T08:49:43.730865Z",
     "start_time": "2024-03-18T08:49:09.796936Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import json\n",
    "import os\n",
    "\n",
    "from libraries.dataset        import standardize_dataset, check_extend_POSCAR\n",
    "from libraries.graph          import graph_POSCAR_encoding\n",
    "from libraries.structure      import compute_diffraction_pattern\n",
    "from torch_geometric.data     import Data\n",
    "from pymatgen.core            import Structure\n",
    "\n",
    "# Checking if pytorch can run in GPU, else CPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33a85832",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-18T11:18:30.410202Z",
     "start_time": "2024-03-18T11:18:30.329209Z"
    }
   },
   "outputs": [],
   "source": [
    "# In case database is created from scratch (otherwise, it is not being used)\n",
    "data_path = '../../../Desktop/MOSES_dataset'\n",
    "\n",
    "# Define diffraction type ('neutron', 'xrd' or 'EPA')\n",
    "target = 'None'\n",
    "\n",
    "# Define folder in which all data will be stored\n",
    "data_folder = f'data/GM_molecules'\n",
    "\n",
    "# Define name for storing dataset basic description\n",
    "dataset_parameters_name = f'{data_folder}/dataset_parameters.json'\n",
    "\n",
    "encoding_type      = 'sphere-images'  # 'voronoi' or 'sphere-images'\n",
    "distance_threshold = 6  # Used in general\n",
    "\n",
    "minimum_lattice_vector = 0 * distance_threshold  # Allowing three convolutions\n",
    "\n",
    "# Define basic dataset parameters for tracking data\n",
    "dataset_parameters = {\n",
    "    'input_folder': data_path,\n",
    "    'output_folder': data_folder,\n",
    "    'target': target,\n",
    "    'encoding_type': encoding_type,\n",
    "    'distance_threshold': distance_threshold,\n",
    "    'minimum_lattice_vector': minimum_lattice_vector\n",
    "}\n",
    "\n",
    "if not os.path.exists(data_folder):\n",
    "    os.system(f'mkdir {data_folder}')\n",
    "\n",
    "# Dump the dictionary with numpy arrays to a JSON file\n",
    "with open(dataset_parameters_name, 'w') as json_file:\n",
    "    json.dump(dataset_parameters, json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4946b2e8",
   "metadata": {},
   "source": [
    "# Generation of graph database for training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b5cbe57",
   "metadata": {},
   "source": [
    "Load the datasets, already standardized if possible."
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1086310\n",
      "\tmol\n",
      "811091\n",
      "\tmol\n",
      "856756\n",
      "\tmol\n",
      "871948\n",
      "\tmol\n",
      "Error: 871948 mol not loaded\n",
      "15970\n",
      "\tmol\n",
      "491766\n",
      "\tmol\n",
      "150171\n",
      "\tmol\n",
      "39386\n",
      "\tmol\n",
      "911117\n",
      "\tmol\n",
      "386730\n",
      "\tmol\n",
      "647127\n",
      "\tmol\n",
      "700766\n",
      "\tmol\n",
      "727978\n",
      "\tmol\n",
      "338506\n",
      "\tmol\n",
      "673312\n",
      "\tmol\n",
      "353837\n",
      "\tmol\n",
      "Error: 353837 mol not loaded\n",
      "374629\n",
      "\tmol\n",
      "238480\n",
      "\tmol\n",
      "773294\n",
      "\tmol\n",
      "734553\n",
      "\tmol\n",
      "233068\n",
      "\tmol\n",
      "Error: 233068 mol not loaded\n",
      "809852\n",
      "\tmol\n",
      "Error: 809852 mol not loaded\n",
      "164344\n",
      "\tmol\n",
      "123483\n",
      "\tmol\n",
      "468297\n",
      "\tmol\n",
      "1038126\n",
      "\tmol\n",
      "444861\n",
      "\tmol\n",
      "862563\n",
      "\tmol\n",
      "883851\n",
      "\tmol\n",
      "1074209\n",
      "\tmol\n",
      "568311\n",
      "\tmol\n",
      "Error: 568311 mol not loaded\n",
      "925322\n",
      "\tmol\n",
      "244906\n",
      "\tmol\n",
      "263718\n",
      "\tmol\n",
      "Error: 263718 mol not loaded\n",
      "764223\n",
      "\tmol\n",
      "344880\n",
      "\tmol\n",
      "324159\n",
      "\tmol\n",
      "648953\n",
      "\tmol\n",
      "Error: 648953 mol not loaded\n",
      "368276\n",
      "\tmol\n",
      "623462\n",
      "\tmol\n",
      "932395\n",
      "\tmol\n",
      "975452\n",
      "\tmol\n",
      "Error: 975452 mol not loaded\n",
      "994960\n",
      "\tmol\n",
      "553950\n",
      "\tmol\n",
      "Error: 553950 mol not loaded\n",
      "533089\n",
      "\tmol\n",
      "538461\n",
      "\tmol\n",
      "1024579\n",
      "\tmol\n",
      "90107\n",
      "\tmol\n",
      "832213\n",
      "\tmol\n",
      "1068656\n",
      "\tmol\n",
      "134434\n",
      "\tmol\n",
      "586657\n",
      "\tmol\n",
      "941667\n",
      "\tmol\n",
      "966879\n",
      "\tmol\n",
      "100601\n",
      "\tmol\n",
      "806026\n",
      "\tmol\n",
      "1037952\n",
      "\tmol\n",
      "750016\n",
      "\tmol\n",
      "Error: 750016 mol not loaded\n",
      "291601\n",
      "\tmol\n",
      "650190\n",
      "\tmol\n",
      "617657\n",
      "\tmol\n",
      "630849\n",
      "\tmol\n",
      "391787\n",
      "\tmol\n",
      "1036880\n",
      "\tmol\n",
      "1056159\n",
      "\tmol\n",
      "1090275\n",
      "\tmol\n",
      "487603\n",
      "\tmol\n",
      "840633\n",
      "\tmol\n",
      "146014\n",
      "\tmol\n",
      "180338\n",
      "\tmol\n",
      "68524\n",
      "\tmol\n",
      "89816\n",
      "\tmol\n",
      "Error: 89816 mol not loaded\n",
      "986499\n",
      "\tmol\n",
      "907072\n",
      "\tmol\n",
      "587785\n",
      "\tmol\n",
      "356579\n",
      "\tmol\n",
      "390655\n",
      "\tmol\n",
      "616785\n",
      "\tmol\n",
      "651042\n",
      "\tmol\n",
      "Error: 651042 mol not loaded\n",
      "211338\n",
      "\tmol\n",
      "716603\n",
      "\tmol\n",
      "665277\n",
      "\tmol\n",
      "649881\n",
      "\tmol\n",
      "345952\n",
      "\tmol\n",
      "629158\n",
      "\tmol\n",
      "269222\n",
      "\tmol\n",
      "722436\n",
      "\tmol\n",
      "749907\n",
      "\tmol\n",
      "172221\n",
      "\tmol\n",
      "439435\n",
      "\tmol\n",
      "838729\n",
      "\tmol\n",
      "Error: 838729 mol not loaded\n",
      "1069784\n",
      "\tmol\n",
      "874406\n",
      "\tmol\n",
      "895934\n",
      "\tmol\n",
      "452904\n",
      "\tmol\n",
      "552882\n",
      "\tmol\n",
      "974580\n",
      "\tmol\n",
      "Error: 974580 mol not loaded\n",
      "933247\n",
      "\tmol\n",
      "Error: 933247 mol not loaded\n",
      "252863\n",
      "\tmol\n",
      "735481\n",
      "\tmol\n"
     ]
    }
   ],
   "source": [
    "# Generate the raw dataset from scratch, and standardize it\n",
    "\n",
    "# Read all materials within the database\n",
    "materials = os.listdir(data_path)\n",
    "\n",
    "dataset = []\n",
    "labels  = []\n",
    "for material in materials[:100]:\n",
    "    try:\n",
    "        # Try to read the polymorphs\n",
    "        polymorphs = os.listdir(f'{data_path}/{material}')\n",
    "    except:\n",
    "        continue\n",
    "    \n",
    "    print(material)\n",
    "    for polymorf in polymorphs:\n",
    "        # Path to folder containing the POSCAR\n",
    "        path_to_POSCAR = f'{data_path}/{material}/{polymorf}'\n",
    "        \n",
    "        # Check that the folder is valid\n",
    "        if os.path.exists(path_to_POSCAR):\n",
    "            print(f'\\t{polymorf}')\n",
    "            \n",
    "            try:\n",
    "                # Load pymatgen structure object\n",
    "                structure = Structure.from_file(f'{path_to_POSCAR}/POSCAR')\n",
    "                \n",
    "                # Check that POSCAR is big enough, otherwise extend it where necessary\n",
    "                structure = check_extend_POSCAR(structure, minimum_lattice_vector)\n",
    "                \n",
    "                nodes, edges, attributes = graph_POSCAR_encoding(structure,\n",
    "                                                                 encoding_type=encoding_type,\n",
    "                                                                 distance_threshold=distance_threshold)\n",
    "            except:\n",
    "                print(f'Error: {material} {polymorf} not loaded')\n",
    "                continue\n",
    "            \n",
    "            if target == 'EPA':\n",
    "                # Load ground state energy per atom\n",
    "                extracted_target = [float(np.loadtxt(f'{path_to_POSCAR}/EPA'))]\n",
    "            elif (target == 'neutron') or (target == 'xrd'):\n",
    "                # Compute diffraction pattern from given structure\n",
    "                extracted_target = compute_diffraction_pattern(structure, diffraction=target)\n",
    "            else:\n",
    "                # Do not extract anything\n",
    "                extracted_target = [0]\n",
    "            \n",
    "            # Construct temporal graph structure\n",
    "            graph = Data(x=nodes,\n",
    "                         edge_index=edges.t().contiguous(),\n",
    "                         edge_attr=attributes.ravel(),\n",
    "                         y=torch.tensor(extracted_target, dtype=torch.float)\n",
    "                        )\n",
    "\n",
    "            # Append to dataset and labels\n",
    "            dataset.append(graph)\n",
    "            labels.append(f'{material}-{polymorf}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-18T11:24:29.493927Z",
     "start_time": "2024-03-18T11:21:17.317265Z"
    }
   },
   "id": "965db1373732057c",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "614dc386",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-18T11:24:30.036059Z",
     "start_time": "2024-03-18T11:24:29.602424Z"
    }
   },
   "outputs": [],
   "source": [
    "# Standardize dataset\n",
    "dataset_std, dataset_parameters = standardize_dataset(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64167d60-b767-42cd-881f-dba4f0a102cb",
   "metadata": {},
   "source": [
    "# Save dataset"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "labels_name                 = f'{data_folder}/labels.pt'\n",
    "dataset_name                = f'{data_folder}/dataset.pt'\n",
    "dataset_name_std            = f'{data_folder}/standardized_dataset.pt'\n",
    "dataset_parameters_name_std = f'{data_folder}/standardized_parameters.json'  # Parameters for rescaling the predictions\n",
    "\n",
    "torch.save(labels,      labels_name)\n",
    "torch.save(dataset,     dataset_name)\n",
    "torch.save(dataset_std, dataset_name_std)\n",
    "\n",
    "# Convert torch tensors to numpy arrays\n",
    "numpy_dict = {key: value.cpu().numpy().tolist() for key, value in dataset_parameters.items()}\n",
    "\n",
    "# Dump the dictionary with numpy arrays to a JSON file\n",
    "with open(dataset_parameters_name_std, 'w') as json_file:\n",
    "    json.dump(numpy_dict, json_file)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-18T11:30:52.929327Z",
     "start_time": "2024-03-18T11:30:52.483628Z"
    }
   },
   "id": "e4233942ef25f557",
   "execution_count": 11
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
