{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6a69f99f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-18T13:40:24.094666890Z",
     "start_time": "2024-03-18T13:40:24.030766698Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "import numpy             as np\n",
    "import torch\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from torch_geometric.data   import Batch\n",
    "from torch_geometric.loader import DataLoader\n",
    "from libraries.model        import nGCNN, eGCNN, diffusion_step, get_graph_losses, add_features_to_graph, predict_noise, diffuse, denoise, EarlyStopping\n",
    "from libraries.dataset      import standardize_dataset, get_datasets\n",
    "\n",
    "# Checking if pytorch can run in GPU, else CPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "device(type='cuda')"
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-18T13:40:24.998910366Z",
     "start_time": "2024-03-18T13:40:24.989517716Z"
    }
   },
   "id": "74450972cebeaa56",
   "execution_count": 44
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "686ad446",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-18T13:40:26.787368946Z",
     "start_time": "2024-03-18T13:40:26.785975143Z"
    }
   },
   "outputs": [],
   "source": [
    "# Based on adding and removing noise to graphs\n",
    "# The models is able to learn hidden patterns\n",
    "# It can be conditionally trained with respect to some target property\n",
    "# Although denoising includes noise, I think it is better not to add it when training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "33a85832",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-18T13:40:27.122320520Z",
     "start_time": "2024-03-18T13:40:27.115010460Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "'models/GM_molecules/GM_v0'"
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define name of data folder where reference dataset are contained\n",
    "# It shall be consistent with data_folder and data will be moved to models folder\n",
    "data_name = 'GM_molecules'\n",
    "\n",
    "# Define folder in which data is stored\n",
    "data_folder = f'data/{data_name}'\n",
    "\n",
    "# The folder is named as target_folder_vi (eg, target_folder_v0)\n",
    "general_folder = f'models/{data_name}'\n",
    "if not os.path.exists(general_folder):\n",
    "    # Generate new folder\n",
    "    os.system(f'mkdir {general_folder}')\n",
    "\n",
    "# Each new run generates a new folder, with different generations and training most likely (as data might vary as well)\n",
    "i = 0\n",
    "while True:\n",
    "    target_folder = f'{general_folder}/GM_v{i}'\n",
    "    if not os.path.exists(target_folder):\n",
    "        # Copy all data\n",
    "        os.system(f'cp -r {data_folder} {target_folder}')\n",
    "        break\n",
    "    i += 1\n",
    "\n",
    "edge_model_name = f'{target_folder}/edge_model.pt'\n",
    "node_model_name = f'{target_folder}/node_model.pt'\n",
    "target_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "75aa6001",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-18T13:40:30.155440169Z",
     "start_time": "2024-03-18T13:40:30.154035815Z"
    }
   },
   "outputs": [],
   "source": [
    "# Machine-learning parameters\n",
    "n_epochs      = 1000\n",
    "batch_size    = 256\n",
    "learning_rate = 0.0001\n",
    "patience      = 20\n",
    "delta         = 0.2\n",
    "check_labels  = True  # Whether to train-test split attending to labels or not\n",
    "\n",
    "# Number of diffusing and denoising steps\n",
    "n_t_steps = 100\n",
    "\n",
    "# Amount of noise for the generative process\n",
    "sigma = 0  # Zero for training purposes\n",
    "\n",
    "# Decay of parameter alpha\n",
    "noise_contribution = 0.05\n",
    "alpha_decay = 0.5 * (1 - noise_contribution**2)\n",
    "\n",
    "# Dropouts for node and edge models (independent of each other)\n",
    "dropout_node = 0.2\n",
    "dropout_edge = 0.2\n",
    "\n",
    "# Create and save as a dictionary\n",
    "model_parameters = {\n",
    "    'data_folder':        data_folder,\n",
    "    'n_epochs':           n_epochs,\n",
    "    'batch_size':         batch_size,\n",
    "    'learning_rate':      learning_rate,\n",
    "    'patience':           patience,\n",
    "    'delta':              delta,\n",
    "    'check_labels':       check_labels,\n",
    "    'n_t_steps':          n_t_steps,\n",
    "    'sigma':              sigma,\n",
    "    'noise_contribution': noise_contribution,\n",
    "    'dropout_node':       dropout_node,\n",
    "    'dropout_edge':       dropout_edge\n",
    "}\n",
    "\n",
    "# Write the dictionary to the file in JSON format\n",
    "with open(f'{target_folder}/model_parameters.json', 'w') as json_file:\n",
    "    json.dump(model_parameters, json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4946b2e8",
   "metadata": {},
   "source": [
    "# Load of graph database for training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b5cbe57",
   "metadata": {},
   "source": [
    "Load the dataset, already standardized."
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "labels_name                 = f'{target_folder}/labels.pt'\n",
    "dataset_name                = f'{target_folder}/dataset.pt'\n",
    "dataset_name_std            = f'{target_folder}/standardized_dataset.pt'\n",
    "dataset_parameters_name_std = f'{target_folder}/standardized_parameters.json'  # Parameters for rescaling the predictions\n",
    "\n",
    "if os.path.exists(dataset_name_std) and os.path.exists(dataset_parameters_name_std) and os.path.exists(labels_name):\n",
    "    # Load the standardized dataset, with corresponding labels and parameters\n",
    "    dataset = torch.load(dataset_name_std)\n",
    "    labels  = torch.load(labels_name)\n",
    "    \n",
    "    # Load the data from the JSON file\n",
    "    with open(dataset_parameters_name_std, 'r') as json_file:\n",
    "        numpy_dict = json.load(json_file)\n",
    "\n",
    "    # Convert NumPy arrays back to PyTorch tensors\n",
    "    dataset_parameters = {key: torch.tensor(value) for key, value in numpy_dict.items()}\n",
    "\n",
    "elif os.path.exists(dataset_name) and os.path.exists(labels_name):\n",
    "    # Load the raw dataset, with corresponding labels, and standardize it\n",
    "    dataset = torch.load(dataset_name)\n",
    "    labels  = torch.load(labels_name)\n",
    "    \n",
    "    # Standardize dataset\n",
    "    dataset, dataset_parameters = standardize_dataset(dataset)\n",
    "    \n",
    "    # Save standardized dataset\n",
    "    torch.save(dataset, dataset_name_std)\n",
    "    \n",
    "    # Convert torch tensors to numpy arrays\n",
    "    numpy_dict = {key: value.cpu().numpy().tolist() for key, value in dataset_parameters.items()}\n",
    "\n",
    "    # Dump the dictionary with numpy arrays to a JSON file\n",
    "    with open(dataset_parameters_name_std, 'w') as json_file:\n",
    "        json.dump(numpy_dict, json_file)\n",
    "\n",
    "else:\n",
    "    sys.exit('Error: the database is not available')\n",
    "\n",
    "# Defining target factor\n",
    "target_factor = dataset_parameters['target_std'] / dataset_parameters['scale']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-18T13:40:32.685624320Z",
     "start_time": "2024-03-18T13:40:32.123555034Z"
    }
   },
   "id": "a0ffba165c9329cd",
   "execution_count": 48
  },
  {
   "cell_type": "markdown",
   "source": [
    "Split in train, validation and test sets."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4295b379d810af37"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training   graphs: 68\n",
      "Number of validation graphs: 9\n",
      "Number of testing    graphs: 8\n"
     ]
    }
   ],
   "source": [
    "train_ratio = 0.8\n",
    "test_ratio  = 0.1\n",
    "\n",
    "# Check if data has been already split, else do it randomly\n",
    "path_to_train_labels = f'{target_folder}/train_labels.txt'\n",
    "path_to_val_labels   = f'{target_folder}/validation_labels.txt'\n",
    "path_to_test_labels  = f'{target_folder}/test_labels.txt'\n",
    "\n",
    "# Copy labels\n",
    "material_labels = labels.copy()\n",
    "\n",
    "if os.path.exists(path_to_train_labels) and os.path.exists(path_to_val_labels) and os.path.exists(path_to_test_labels):\n",
    "    # Read labels splitting (which are strings)\n",
    "    train_labels = np.genfromtxt(path_to_train_labels, dtype='str').tolist()\n",
    "    val_labels   = np.genfromtxt(path_to_val_labels,   dtype='str').tolist()\n",
    "    test_labels  = np.genfromtxt(path_to_test_labels,  dtype='str').tolist()\n",
    "else:\n",
    "    if check_labels:\n",
    "        # Splitting into train-test sets considering that Fvs from the same materials must be in the same dataset\n",
    "        material_labels = [label.split()[0] for label in material_labels]\n",
    "        \n",
    "        # Define unique labels\n",
    "        unique_labels = np.unique(material_labels)\n",
    "    else:\n",
    "        # Completely randomly splitting\n",
    "        # Copy material_labels\n",
    "        unique_labels = material_labels.copy()\n",
    "    \n",
    "    # Shuffle the list of unique labels\n",
    "    np.random.shuffle(unique_labels)\n",
    "\n",
    "    # Define the sizes of the train and test sets\n",
    "    # Corresponds to the size wrt the number of unique materials in the dataset\n",
    "    train_size = int(train_ratio * len(unique_labels))\n",
    "    test_size  = int(test_ratio  * len(unique_labels))\n",
    "    \n",
    "    train_labels = unique_labels[:train_size]\n",
    "    val_labels   = unique_labels[train_size:-test_size]\n",
    "    test_labels  = unique_labels[-test_size:]\n",
    "\n",
    "    # Save this splitting for transfer-learning approaches\n",
    "    np.savetxt(path_to_train_labels, train_labels, fmt='%s')\n",
    "    np.savetxt(path_to_val_labels,   val_labels,   fmt='%s')\n",
    "    np.savetxt(path_to_test_labels,  test_labels,  fmt='%s')\n",
    "\n",
    "# Use the computed indexes to generate train and test sets\n",
    "# We iteratively check where labels equals a unique train/test labels and append the index to a list\n",
    "train_dataset = get_datasets(train_labels, material_labels, dataset)\n",
    "val_dataset   = get_datasets(val_labels,   material_labels, dataset)\n",
    "test_dataset  = get_datasets(test_labels,  material_labels, dataset)\n",
    "\n",
    "print(f'Number of training   graphs: {len(train_dataset)}')\n",
    "print(f'Number of validation graphs: {len(val_dataset)}')\n",
    "print(f'Number of testing    graphs: {len(test_dataset)}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-18T13:45:33.828198917Z",
     "start_time": "2024-03-18T13:45:33.786261106Z"
    }
   },
   "id": "cf6d6f22a60cb749",
   "execution_count": 70
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "for graph in train_dataset:\n",
    "    graph.y = torch.tensor([0], dtype=torch.float)\n",
    "\n",
    "for graph in val_dataset:\n",
    "    graph.y = torch.tensor([0], dtype=torch.float)\n",
    "\n",
    "for graph in test_dataset:\n",
    "    graph.y = torch.tensor([0], dtype=torch.float)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-18T13:45:36.364480287Z",
     "start_time": "2024-03-18T13:45:36.362522441Z"
    }
   },
   "id": "6fc3e15d5a51e08e",
   "execution_count": 71
  },
  {
   "cell_type": "markdown",
   "source": [
    "Define data loaders."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "549a2953188746d3"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, pin_memory=True)\n",
    "val_loader   = DataLoader(val_dataset,   batch_size=batch_size, shuffle=True, pin_memory=True)\n",
    "test_loader  = DataLoader(test_dataset,  batch_size=batch_size, shuffle=True, pin_memory=True)"
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-18T13:45:36.964604075Z",
     "start_time": "2024-03-18T13:45:36.961445529Z"
    }
   },
   "id": "86402c04-4b6c-4dfb-b112-6574fc89380d",
   "execution_count": 72
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Definition of the model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "28881dd9d41fdf8e"
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "1591eccef168173b",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-18T13:45:37.964746054Z",
     "start_time": "2024-03-18T13:45:37.960085141Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Node GCNN:\n",
      "nGCNN(\n",
      "  (conv1): GraphConv(6, 256)\n",
      "  (conv2): GraphConv(256, 5)\n",
      ")\n",
      "\n",
      "Edge GCNN:\n",
      "eGCNN(\n",
      "  (linear1): Linear(in_features=7, out_features=64, bias=True)\n",
      "  (linear2): Linear(in_features=64, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Determine number of node-level features in dataset, considering the t_step information\n",
    "n_node_features = train_dataset[0].num_node_features + 1\n",
    "\n",
    "# Determine the number of graph-level features to be predicted\n",
    "n_graph_features = len(train_dataset[0].y)\n",
    "\n",
    "# Instantiate the models for nodes and edges\n",
    "node_model = nGCNN(n_node_features, n_graph_features, dropout_node).to(device)\n",
    "edge_model = eGCNN(n_node_features, n_graph_features, dropout_edge).to(device)\n",
    "\n",
    "# Moving models to device\n",
    "node_model = node_model.to(device)\n",
    "edge_model = edge_model.to(device)\n",
    "\n",
    "# Load previous model if available\n",
    "try:\n",
    "    # Load model state\n",
    "    node_model.load_state_dict(torch.load(node_model_name))\n",
    "    edge_model.load_state_dict(torch.load(edge_model_name))\n",
    "    \n",
    "    # Evaluate model state\n",
    "    node_model.eval()\n",
    "    edge_model.eval()\n",
    "except FileNotFoundError:\n",
    "    pass\n",
    "\n",
    "print('\\nNode GCNN:')\n",
    "print(node_model)\n",
    "print('\\nEdge GCNN:')\n",
    "print(edge_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Training of the model"
   ],
   "metadata": {},
   "id": "31a76fc0"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, total loss: 0.0349, edge loss: 0.0160, node loss: 0.0189\n",
      "Epoch: 2, total loss: 0.0343, edge loss: 0.0151, node loss: 0.0193\n",
      "Epoch: 3, total loss: 0.0373, edge loss: 0.0149, node loss: 0.0225\n",
      "Epoch: 4, total loss: 0.0387, edge loss: 0.0148, node loss: 0.0239\n",
      "Epoch: 5, total loss: 0.0383, edge loss: 0.0148, node loss: 0.0235\n",
      "Epoch: 6, total loss: 0.0374, edge loss: 0.0148, node loss: 0.0227\n",
      "Epoch: 7, total loss: 0.0369, edge loss: 0.0148, node loss: 0.0221\n",
      "Epoch: 8, total loss: 0.0380, edge loss: 0.0148, node loss: 0.0232\n",
      "Epoch: 9, total loss: 0.0396, edge loss: 0.0147, node loss: 0.0248\n",
      "Epoch: 10, total loss: 0.0401, edge loss: 0.0147, node loss: 0.0253\n",
      "Epoch: 11, total loss: 0.0387, edge loss: 0.0147, node loss: 0.0240\n",
      "Epoch: 12, total loss: 0.0362, edge loss: 0.0147, node loss: 0.0215\n",
      "Epoch: 13, total loss: 0.0350, edge loss: 0.0148, node loss: 0.0202\n",
      "Epoch: 14, total loss: 0.0339, edge loss: 0.0147, node loss: 0.0192\n",
      "Epoch: 15, total loss: 0.0338, edge loss: 0.0147, node loss: 0.0191\n",
      "Epoch: 16, total loss: 0.0334, edge loss: 0.0147, node loss: 0.0186\n",
      "Epoch: 17, total loss: 0.0332, edge loss: 0.0147, node loss: 0.0184\n",
      "Epoch: 18, total loss: 0.0325, edge loss: 0.0147, node loss: 0.0178\n",
      "Epoch: 19, total loss: 0.0323, edge loss: 0.0147, node loss: 0.0176\n",
      "Epoch: 20, total loss: 0.0323, edge loss: 0.0147, node loss: 0.0176\n",
      "Epoch: 21, total loss: 0.0327, edge loss: 0.0147, node loss: 0.0180\n",
      "Epoch: 22, total loss: 0.0327, edge loss: 0.0147, node loss: 0.0180\n",
      "Epoch: 23, total loss: 0.0323, edge loss: 0.0147, node loss: 0.0175\n",
      "Epoch: 24, total loss: 0.0316, edge loss: 0.0147, node loss: 0.0169\n",
      "Epoch: 25, total loss: 0.0311, edge loss: 0.0147, node loss: 0.0164\n",
      "Epoch: 26, total loss: 0.0309, edge loss: 0.0147, node loss: 0.0161\n",
      "Epoch: 27, total loss: 0.0307, edge loss: 0.0147, node loss: 0.0160\n",
      "Epoch: 28, total loss: 0.0306, edge loss: 0.0147, node loss: 0.0159\n",
      "Epoch: 29, total loss: 0.0307, edge loss: 0.0147, node loss: 0.0160\n",
      "Epoch: 30, total loss: 0.0308, edge loss: 0.0147, node loss: 0.0161\n",
      "Epoch: 31, total loss: 0.0309, edge loss: 0.0147, node loss: 0.0162\n",
      "Epoch: 32, total loss: 0.0308, edge loss: 0.0147, node loss: 0.0161\n",
      "Epoch: 33, total loss: 0.0307, edge loss: 0.0147, node loss: 0.0160\n",
      "Epoch: 34, total loss: 0.0305, edge loss: 0.0147, node loss: 0.0157\n",
      "Epoch: 35, total loss: 0.0303, edge loss: 0.0147, node loss: 0.0156\n",
      "Epoch: 36, total loss: 0.0302, edge loss: 0.0147, node loss: 0.0154\n",
      "Epoch: 37, total loss: 0.0301, edge loss: 0.0147, node loss: 0.0154\n",
      "Epoch: 38, total loss: 0.0301, edge loss: 0.0147, node loss: 0.0153\n",
      "Epoch: 39, total loss: 0.0300, edge loss: 0.0147, node loss: 0.0153\n",
      "Epoch: 40, total loss: 0.0300, edge loss: 0.0147, node loss: 0.0153\n",
      "Epoch: 41, total loss: 0.0300, edge loss: 0.0147, node loss: 0.0153\n",
      "Epoch: 42, total loss: 0.0301, edge loss: 0.0147, node loss: 0.0154\n",
      "Epoch: 43, total loss: 0.0302, edge loss: 0.0147, node loss: 0.0155\n",
      "Epoch: 44, total loss: 0.0304, edge loss: 0.0147, node loss: 0.0157\n",
      "Epoch: 45, total loss: 0.0306, edge loss: 0.0147, node loss: 0.0159\n",
      "Epoch: 46, total loss: 0.0309, edge loss: 0.0147, node loss: 0.0162\n",
      "Epoch: 47, total loss: 0.0310, edge loss: 0.0147, node loss: 0.0163\n",
      "Epoch: 48, total loss: 0.0312, edge loss: 0.0147, node loss: 0.0165\n",
      "Epoch: 49, total loss: 0.0312, edge loss: 0.0147, node loss: 0.0165\n",
      "Epoch: 50, total loss: 0.0311, edge loss: 0.0147, node loss: 0.0164\n",
      "Epoch: 51, total loss: 0.0307, edge loss: 0.0147, node loss: 0.0160\n",
      "Epoch: 52, total loss: 0.0304, edge loss: 0.0147, node loss: 0.0157\n",
      "Epoch: 53, total loss: 0.0300, edge loss: 0.0147, node loss: 0.0153\n",
      "Epoch: 54, total loss: 0.0299, edge loss: 0.0147, node loss: 0.0152\n",
      "Epoch: 55, total loss: 0.0298, edge loss: 0.0147, node loss: 0.0151\n",
      "Epoch: 56, total loss: 0.0298, edge loss: 0.0147, node loss: 0.0151\n",
      "Epoch: 57, total loss: 0.0298, edge loss: 0.0147, node loss: 0.0151\n",
      "Epoch: 58, total loss: 0.0297, edge loss: 0.0147, node loss: 0.0150\n",
      "Epoch: 59, total loss: 0.0297, edge loss: 0.0147, node loss: 0.0150\n",
      "Epoch: 60, total loss: 0.0297, edge loss: 0.0147, node loss: 0.0150\n",
      "Epoch: 61, total loss: 0.0296, edge loss: 0.0147, node loss: 0.0149\n",
      "Epoch: 62, total loss: 0.0296, edge loss: 0.0147, node loss: 0.0149\n",
      "Epoch: 63, total loss: 0.0296, edge loss: 0.0147, node loss: 0.0149\n",
      "Epoch: 64, total loss: 0.0296, edge loss: 0.0147, node loss: 0.0149\n",
      "Epoch: 65, total loss: 0.0297, edge loss: 0.0147, node loss: 0.0149\n",
      "Epoch: 66, total loss: 0.0297, edge loss: 0.0147, node loss: 0.0150\n",
      "Epoch: 67, total loss: 0.0297, edge loss: 0.0147, node loss: 0.0151\n",
      "Epoch: 68, total loss: 0.0299, edge loss: 0.0147, node loss: 0.0151\n",
      "Epoch: 69, total loss: 0.0299, edge loss: 0.0147, node loss: 0.0152\n",
      "Epoch: 70, total loss: 0.0300, edge loss: 0.0147, node loss: 0.0153\n",
      "Epoch: 71, total loss: 0.0299, edge loss: 0.0147, node loss: 0.0152\n",
      "Epoch: 72, total loss: 0.0297, edge loss: 0.0147, node loss: 0.0151\n",
      "Epoch: 73, total loss: 0.0296, edge loss: 0.0147, node loss: 0.0149\n",
      "Epoch: 74, total loss: 0.0295, edge loss: 0.0147, node loss: 0.0148\n",
      "Epoch: 75, total loss: 0.0294, edge loss: 0.0147, node loss: 0.0147\n",
      "Epoch: 76, total loss: 0.0294, edge loss: 0.0147, node loss: 0.0147\n",
      "Epoch: 77, total loss: 0.0293, edge loss: 0.0147, node loss: 0.0147\n",
      "Epoch: 78, total loss: 0.0294, edge loss: 0.0147, node loss: 0.0147\n",
      "Epoch: 79, total loss: 0.0294, edge loss: 0.0147, node loss: 0.0147\n",
      "Epoch: 80, total loss: 0.0294, edge loss: 0.0147, node loss: 0.0147\n",
      "Epoch: 81, total loss: 0.0293, edge loss: 0.0147, node loss: 0.0146\n",
      "Epoch: 82, total loss: 0.0293, edge loss: 0.0147, node loss: 0.0146\n",
      "Epoch: 83, total loss: 0.0292, edge loss: 0.0147, node loss: 0.0145\n",
      "Epoch: 84, total loss: 0.0293, edge loss: 0.0147, node loss: 0.0145\n",
      "Epoch: 85, total loss: 0.0292, edge loss: 0.0147, node loss: 0.0145\n",
      "Epoch: 86, total loss: 0.0292, edge loss: 0.0147, node loss: 0.0145\n",
      "Epoch: 87, total loss: 0.0292, edge loss: 0.0147, node loss: 0.0145\n",
      "Epoch: 88, total loss: 0.0292, edge loss: 0.0147, node loss: 0.0145\n",
      "Epoch: 89, total loss: 0.0293, edge loss: 0.0147, node loss: 0.0146\n",
      "Epoch: 90, total loss: 0.0292, edge loss: 0.0147, node loss: 0.0145\n",
      "Epoch: 91, total loss: 0.0293, edge loss: 0.0147, node loss: 0.0145\n",
      "Epoch: 92, total loss: 0.0292, edge loss: 0.0147, node loss: 0.0145\n",
      "Epoch: 93, total loss: 0.0292, edge loss: 0.0147, node loss: 0.0145\n",
      "Epoch: 94, total loss: 0.0292, edge loss: 0.0147, node loss: 0.0144\n",
      "Epoch: 95, total loss: 0.0291, edge loss: 0.0147, node loss: 0.0144\n",
      "Epoch: 96, total loss: 0.0291, edge loss: 0.0147, node loss: 0.0144\n",
      "Epoch: 97, total loss: 0.0291, edge loss: 0.0147, node loss: 0.0144\n",
      "Epoch: 98, total loss: 0.0290, edge loss: 0.0147, node loss: 0.0143\n",
      "Epoch: 99, total loss: 0.0290, edge loss: 0.0147, node loss: 0.0143\n",
      "Epoch: 100, total loss: 0.0289, edge loss: 0.0147, node loss: 0.0142\n",
      "Epoch: 101, total loss: 0.0289, edge loss: 0.0147, node loss: 0.0142\n",
      "Epoch: 102, total loss: 0.0289, edge loss: 0.0147, node loss: 0.0142\n",
      "Epoch: 103, total loss: 0.0289, edge loss: 0.0147, node loss: 0.0142\n",
      "Epoch: 104, total loss: 0.0288, edge loss: 0.0147, node loss: 0.0141\n",
      "Epoch: 105, total loss: 0.0288, edge loss: 0.0147, node loss: 0.0141\n",
      "Epoch: 106, total loss: 0.0288, edge loss: 0.0147, node loss: 0.0141\n",
      "Epoch: 107, total loss: 0.0287, edge loss: 0.0147, node loss: 0.0140\n",
      "Epoch: 108, total loss: 0.0287, edge loss: 0.0147, node loss: 0.0140\n",
      "Epoch: 109, total loss: 0.0286, edge loss: 0.0147, node loss: 0.0139\n",
      "Epoch: 110, total loss: 0.0286, edge loss: 0.0147, node loss: 0.0139\n",
      "Epoch: 111, total loss: 0.0286, edge loss: 0.0147, node loss: 0.0139\n",
      "Epoch: 112, total loss: 0.0287, edge loss: 0.0147, node loss: 0.0140\n",
      "Epoch: 113, total loss: 0.0288, edge loss: 0.0147, node loss: 0.0141\n",
      "Epoch: 114, total loss: 0.0287, edge loss: 0.0147, node loss: 0.0139\n",
      "Epoch: 115, total loss: 0.0288, edge loss: 0.0147, node loss: 0.0141\n",
      "Epoch: 116, total loss: 0.0286, edge loss: 0.0147, node loss: 0.0139\n",
      "Epoch: 117, total loss: 0.0284, edge loss: 0.0147, node loss: 0.0137\n",
      "Epoch: 118, total loss: 0.0284, edge loss: 0.0147, node loss: 0.0137\n",
      "Epoch: 119, total loss: 0.0283, edge loss: 0.0147, node loss: 0.0136\n",
      "Epoch: 120, total loss: 0.0283, edge loss: 0.0147, node loss: 0.0136\n",
      "Epoch: 121, total loss: 0.0282, edge loss: 0.0147, node loss: 0.0135\n",
      "Epoch: 122, total loss: 0.0282, edge loss: 0.0147, node loss: 0.0135\n",
      "Epoch: 123, total loss: 0.0282, edge loss: 0.0147, node loss: 0.0135\n",
      "Epoch: 124, total loss: 0.0282, edge loss: 0.0147, node loss: 0.0135\n",
      "Epoch: 125, total loss: 0.0282, edge loss: 0.0147, node loss: 0.0135\n",
      "Epoch: 126, total loss: 0.0282, edge loss: 0.0147, node loss: 0.0135\n",
      "Epoch: 127, total loss: 0.0282, edge loss: 0.0147, node loss: 0.0135\n",
      "Epoch: 128, total loss: 0.0282, edge loss: 0.0147, node loss: 0.0135\n",
      "Epoch: 129, total loss: 0.0282, edge loss: 0.0147, node loss: 0.0135\n",
      "Epoch: 130, total loss: 0.0282, edge loss: 0.0147, node loss: 0.0135\n",
      "Epoch: 131, total loss: 0.0281, edge loss: 0.0147, node loss: 0.0134\n",
      "Epoch: 132, total loss: 0.0279, edge loss: 0.0147, node loss: 0.0132\n",
      "Epoch: 133, total loss: 0.0280, edge loss: 0.0147, node loss: 0.0133\n",
      "Epoch: 134, total loss: 0.0279, edge loss: 0.0147, node loss: 0.0132\n",
      "Epoch: 135, total loss: 0.0281, edge loss: 0.0147, node loss: 0.0134\n",
      "Epoch: 136, total loss: 0.0279, edge loss: 0.0147, node loss: 0.0132\n",
      "Epoch: 137, total loss: 0.0278, edge loss: 0.0147, node loss: 0.0131\n",
      "Epoch: 138, total loss: 0.0278, edge loss: 0.0147, node loss: 0.0131\n",
      "Epoch: 139, total loss: 0.0277, edge loss: 0.0147, node loss: 0.0130\n",
      "Epoch: 140, total loss: 0.0277, edge loss: 0.0147, node loss: 0.0130\n",
      "Epoch: 141, total loss: 0.0277, edge loss: 0.0147, node loss: 0.0130\n",
      "Epoch: 142, total loss: 0.0276, edge loss: 0.0147, node loss: 0.0129\n",
      "Epoch: 143, total loss: 0.0276, edge loss: 0.0147, node loss: 0.0129\n",
      "Epoch: 144, total loss: 0.0276, edge loss: 0.0147, node loss: 0.0128\n",
      "Epoch: 145, total loss: 0.0276, edge loss: 0.0147, node loss: 0.0128\n",
      "Epoch: 146, total loss: 0.0275, edge loss: 0.0147, node loss: 0.0128\n",
      "Epoch: 147, total loss: 0.0278, edge loss: 0.0147, node loss: 0.0130\n",
      "Epoch: 148, total loss: 0.0276, edge loss: 0.0147, node loss: 0.0129\n",
      "Epoch: 149, total loss: 0.0277, edge loss: 0.0147, node loss: 0.0130\n",
      "Epoch: 150, total loss: 0.0277, edge loss: 0.0147, node loss: 0.0130\n",
      "Epoch: 151, total loss: 0.0275, edge loss: 0.0147, node loss: 0.0128\n",
      "Epoch: 152, total loss: 0.0277, edge loss: 0.0147, node loss: 0.0130\n",
      "Epoch: 153, total loss: 0.0273, edge loss: 0.0147, node loss: 0.0126\n",
      "Epoch: 154, total loss: 0.0273, edge loss: 0.0147, node loss: 0.0127\n",
      "Epoch: 155, total loss: 0.0272, edge loss: 0.0147, node loss: 0.0125\n",
      "Epoch: 156, total loss: 0.0272, edge loss: 0.0147, node loss: 0.0125\n",
      "Epoch: 157, total loss: 0.0272, edge loss: 0.0147, node loss: 0.0124\n",
      "Epoch: 158, total loss: 0.0272, edge loss: 0.0147, node loss: 0.0125\n",
      "Epoch: 159, total loss: 0.0271, edge loss: 0.0147, node loss: 0.0124\n",
      "Epoch: 160, total loss: 0.0272, edge loss: 0.0147, node loss: 0.0125\n",
      "Epoch: 161, total loss: 0.0271, edge loss: 0.0147, node loss: 0.0124\n",
      "Epoch: 162, total loss: 0.0270, edge loss: 0.0147, node loss: 0.0123\n",
      "Epoch: 163, total loss: 0.0270, edge loss: 0.0147, node loss: 0.0123\n",
      "Epoch: 164, total loss: 0.0275, edge loss: 0.0147, node loss: 0.0127\n",
      "Epoch: 165, total loss: 0.0274, edge loss: 0.0147, node loss: 0.0127\n",
      "Epoch: 166, total loss: 0.0273, edge loss: 0.0147, node loss: 0.0126\n",
      "Epoch: 167, total loss: 0.0269, edge loss: 0.0147, node loss: 0.0122\n",
      "Epoch: 168, total loss: 0.0270, edge loss: 0.0147, node loss: 0.0123\n",
      "Epoch: 169, total loss: 0.0267, edge loss: 0.0147, node loss: 0.0120\n",
      "Epoch: 170, total loss: 0.0267, edge loss: 0.0147, node loss: 0.0120\n",
      "Epoch: 171, total loss: 0.0266, edge loss: 0.0147, node loss: 0.0119\n",
      "Epoch: 172, total loss: 0.0266, edge loss: 0.0147, node loss: 0.0119\n",
      "Epoch: 173, total loss: 0.0266, edge loss: 0.0147, node loss: 0.0119\n",
      "Epoch: 174, total loss: 0.0267, edge loss: 0.0147, node loss: 0.0120\n",
      "Epoch: 175, total loss: 0.0271, edge loss: 0.0147, node loss: 0.0124\n",
      "Epoch: 176, total loss: 0.0270, edge loss: 0.0147, node loss: 0.0123\n",
      "Epoch: 177, total loss: 0.0268, edge loss: 0.0147, node loss: 0.0121\n",
      "Epoch: 178, total loss: 0.0270, edge loss: 0.0147, node loss: 0.0123\n",
      "Epoch: 179, total loss: 0.0268, edge loss: 0.0147, node loss: 0.0120\n",
      "Epoch: 180, total loss: 0.0265, edge loss: 0.0147, node loss: 0.0118\n",
      "Epoch: 181, total loss: 0.0266, edge loss: 0.0147, node loss: 0.0119\n",
      "Epoch: 182, total loss: 0.0265, edge loss: 0.0147, node loss: 0.0118\n",
      "Epoch: 183, total loss: 0.0264, edge loss: 0.0147, node loss: 0.0116\n",
      "Epoch: 184, total loss: 0.0267, edge loss: 0.0147, node loss: 0.0119\n",
      "Epoch: 185, total loss: 0.0265, edge loss: 0.0147, node loss: 0.0118\n",
      "Epoch: 186, total loss: 0.0264, edge loss: 0.0147, node loss: 0.0117\n",
      "Epoch: 187, total loss: 0.0266, edge loss: 0.0147, node loss: 0.0119\n",
      "Epoch: 188, total loss: 0.0263, edge loss: 0.0147, node loss: 0.0116\n",
      "Epoch: 189, total loss: 0.0265, edge loss: 0.0147, node loss: 0.0118\n",
      "Epoch: 190, total loss: 0.0262, edge loss: 0.0147, node loss: 0.0115\n",
      "Epoch: 191, total loss: 0.0262, edge loss: 0.0147, node loss: 0.0115\n",
      "Epoch: 192, total loss: 0.0263, edge loss: 0.0147, node loss: 0.0116\n",
      "Epoch: 193, total loss: 0.0262, edge loss: 0.0147, node loss: 0.0114\n",
      "Epoch: 194, total loss: 0.0266, edge loss: 0.0147, node loss: 0.0119\n",
      "Epoch: 195, total loss: 0.0260, edge loss: 0.0147, node loss: 0.0113\n",
      "Epoch: 196, total loss: 0.0262, edge loss: 0.0147, node loss: 0.0114\n",
      "Epoch: 197, total loss: 0.0259, edge loss: 0.0147, node loss: 0.0112\n",
      "Epoch: 198, total loss: 0.0260, edge loss: 0.0147, node loss: 0.0112\n",
      "Epoch: 199, total loss: 0.0257, edge loss: 0.0147, node loss: 0.0110\n",
      "Epoch: 200, total loss: 0.0260, edge loss: 0.0147, node loss: 0.0113\n",
      "Epoch: 201, total loss: 0.0261, edge loss: 0.0147, node loss: 0.0114\n",
      "Epoch: 202, total loss: 0.0266, edge loss: 0.0147, node loss: 0.0119\n",
      "Epoch: 203, total loss: 0.0261, edge loss: 0.0147, node loss: 0.0114\n",
      "Epoch: 204, total loss: 0.0267, edge loss: 0.0147, node loss: 0.0120\n",
      "Epoch: 205, total loss: 0.0266, edge loss: 0.0147, node loss: 0.0119\n",
      "Epoch: 206, total loss: 0.0263, edge loss: 0.0147, node loss: 0.0115\n",
      "Epoch: 207, total loss: 0.0265, edge loss: 0.0147, node loss: 0.0118\n",
      "Epoch: 208, total loss: 0.0257, edge loss: 0.0147, node loss: 0.0110\n",
      "Epoch: 209, total loss: 0.0256, edge loss: 0.0147, node loss: 0.0109\n",
      "Epoch: 210, total loss: 0.0255, edge loss: 0.0147, node loss: 0.0108\n",
      "Epoch: 211, total loss: 0.0255, edge loss: 0.0147, node loss: 0.0108\n",
      "Epoch: 212, total loss: 0.0254, edge loss: 0.0147, node loss: 0.0107\n",
      "Epoch: 213, total loss: 0.0254, edge loss: 0.0147, node loss: 0.0107\n",
      "Epoch: 214, total loss: 0.0255, edge loss: 0.0147, node loss: 0.0108\n",
      "Epoch: 215, total loss: 0.0255, edge loss: 0.0147, node loss: 0.0108\n",
      "Epoch: 216, total loss: 0.0254, edge loss: 0.0147, node loss: 0.0108\n",
      "Epoch: 217, total loss: 0.0258, edge loss: 0.0147, node loss: 0.0111\n",
      "Epoch: 218, total loss: 0.0258, edge loss: 0.0147, node loss: 0.0111\n",
      "Epoch: 219, total loss: 0.0263, edge loss: 0.0147, node loss: 0.0116\n",
      "Epoch: 220, total loss: 0.0258, edge loss: 0.0147, node loss: 0.0110\n",
      "Epoch: 221, total loss: 0.0273, edge loss: 0.0147, node loss: 0.0126\n",
      "Epoch: 222, total loss: 0.0259, edge loss: 0.0147, node loss: 0.0112\n",
      "Epoch: 223, total loss: 0.0257, edge loss: 0.0147, node loss: 0.0110\n",
      "Epoch: 224, total loss: 0.0253, edge loss: 0.0147, node loss: 0.0106\n",
      "Epoch: 225, total loss: 0.0254, edge loss: 0.0147, node loss: 0.0107\n",
      "Epoch: 226, total loss: 0.0257, edge loss: 0.0147, node loss: 0.0110\n",
      "Epoch: 227, total loss: 0.0257, edge loss: 0.0147, node loss: 0.0110\n",
      "Epoch: 228, total loss: 0.0256, edge loss: 0.0147, node loss: 0.0109\n",
      "Epoch: 229, total loss: 0.0254, edge loss: 0.0147, node loss: 0.0107\n",
      "Epoch: 230, total loss: 0.0254, edge loss: 0.0147, node loss: 0.0107\n",
      "Epoch: 231, total loss: 0.0255, edge loss: 0.0147, node loss: 0.0107\n",
      "Epoch: 232, total loss: 0.0256, edge loss: 0.0147, node loss: 0.0109\n",
      "Epoch: 233, total loss: 0.0255, edge loss: 0.0147, node loss: 0.0108\n",
      "Epoch: 234, total loss: 0.0256, edge loss: 0.0147, node loss: 0.0109\n",
      "Epoch: 235, total loss: 0.0255, edge loss: 0.0147, node loss: 0.0108\n",
      "Epoch: 236, total loss: 0.0259, edge loss: 0.0147, node loss: 0.0111\n",
      "Epoch: 237, total loss: 0.0254, edge loss: 0.0147, node loss: 0.0107\n",
      "Epoch: 238, total loss: 0.0255, edge loss: 0.0147, node loss: 0.0108\n",
      "Epoch: 239, total loss: 0.0251, edge loss: 0.0147, node loss: 0.0104\n",
      "Epoch: 240, total loss: 0.0251, edge loss: 0.0147, node loss: 0.0103\n",
      "Epoch: 241, total loss: 0.0251, edge loss: 0.0147, node loss: 0.0103\n",
      "Epoch: 242, total loss: 0.0253, edge loss: 0.0147, node loss: 0.0105\n",
      "Epoch: 243, total loss: 0.0252, edge loss: 0.0147, node loss: 0.0105\n",
      "Epoch: 244, total loss: 0.0256, edge loss: 0.0147, node loss: 0.0109\n",
      "Epoch: 245, total loss: 0.0252, edge loss: 0.0147, node loss: 0.0105\n",
      "Epoch: 246, total loss: 0.0258, edge loss: 0.0147, node loss: 0.0110\n",
      "Epoch: 247, total loss: 0.0253, edge loss: 0.0147, node loss: 0.0106\n",
      "Epoch: 248, total loss: 0.0257, edge loss: 0.0147, node loss: 0.0110\n",
      "Epoch: 249, total loss: 0.0253, edge loss: 0.0147, node loss: 0.0106\n",
      "Epoch: 250, total loss: 0.0256, edge loss: 0.0147, node loss: 0.0109\n",
      "Epoch: 251, total loss: 0.0252, edge loss: 0.0147, node loss: 0.0105\n",
      "Epoch: 252, total loss: 0.0255, edge loss: 0.0147, node loss: 0.0108\n",
      "Epoch: 253, total loss: 0.0254, edge loss: 0.0147, node loss: 0.0106\n",
      "Epoch: 254, total loss: 0.0253, edge loss: 0.0147, node loss: 0.0106\n",
      "Epoch: 255, total loss: 0.0250, edge loss: 0.0147, node loss: 0.0103\n",
      "Epoch: 256, total loss: 0.0248, edge loss: 0.0147, node loss: 0.0101\n",
      "Epoch: 257, total loss: 0.0248, edge loss: 0.0147, node loss: 0.0101\n",
      "Epoch: 258, total loss: 0.0248, edge loss: 0.0147, node loss: 0.0100\n",
      "Epoch: 259, total loss: 0.0246, edge loss: 0.0147, node loss: 0.0099\n",
      "Epoch: 260, total loss: 0.0250, edge loss: 0.0147, node loss: 0.0103\n",
      "Epoch: 261, total loss: 0.0255, edge loss: 0.0147, node loss: 0.0108\n",
      "Epoch: 262, total loss: 0.0251, edge loss: 0.0147, node loss: 0.0104\n",
      "Epoch: 263, total loss: 0.0253, edge loss: 0.0147, node loss: 0.0105\n",
      "Epoch: 264, total loss: 0.0254, edge loss: 0.0147, node loss: 0.0107\n",
      "Epoch: 265, total loss: 0.0250, edge loss: 0.0147, node loss: 0.0103\n",
      "Epoch: 266, total loss: 0.0255, edge loss: 0.0147, node loss: 0.0108\n",
      "Epoch: 267, total loss: 0.0248, edge loss: 0.0147, node loss: 0.0101\n",
      "Epoch: 268, total loss: 0.0248, edge loss: 0.0147, node loss: 0.0101\n",
      "Epoch: 269, total loss: 0.0250, edge loss: 0.0147, node loss: 0.0103\n",
      "Epoch: 270, total loss: 0.0249, edge loss: 0.0147, node loss: 0.0102\n",
      "Epoch: 271, total loss: 0.0251, edge loss: 0.0147, node loss: 0.0104\n",
      "Epoch: 272, total loss: 0.0251, edge loss: 0.0147, node loss: 0.0104\n",
      "Epoch: 273, total loss: 0.0253, edge loss: 0.0147, node loss: 0.0106\n",
      "Epoch: 274, total loss: 0.0254, edge loss: 0.0147, node loss: 0.0107\n",
      "Epoch: 275, total loss: 0.0251, edge loss: 0.0147, node loss: 0.0103\n",
      "Epoch: 276, total loss: 0.0249, edge loss: 0.0147, node loss: 0.0102\n",
      "Epoch: 277, total loss: 0.0247, edge loss: 0.0147, node loss: 0.0100\n",
      "Epoch: 278, total loss: 0.0253, edge loss: 0.0147, node loss: 0.0106\n",
      "Epoch: 279, total loss: 0.0248, edge loss: 0.0147, node loss: 0.0101\n",
      "Epoch: 280, total loss: 0.0251, edge loss: 0.0147, node loss: 0.0104\n",
      "Epoch: 281, total loss: 0.0252, edge loss: 0.0147, node loss: 0.0104\n",
      "Epoch: 282, total loss: 0.0248, edge loss: 0.0147, node loss: 0.0101\n",
      "Epoch: 283, total loss: 0.0251, edge loss: 0.0147, node loss: 0.0104\n",
      "Epoch: 284, total loss: 0.0252, edge loss: 0.0147, node loss: 0.0105\n",
      "Epoch: 285, total loss: 0.0248, edge loss: 0.0147, node loss: 0.0100\n",
      "Epoch: 286, total loss: 0.0245, edge loss: 0.0147, node loss: 0.0098\n",
      "Epoch: 287, total loss: 0.0246, edge loss: 0.0147, node loss: 0.0099\n",
      "Epoch: 288, total loss: 0.0248, edge loss: 0.0147, node loss: 0.0101\n",
      "Epoch: 289, total loss: 0.0249, edge loss: 0.0147, node loss: 0.0102\n",
      "Epoch: 290, total loss: 0.0250, edge loss: 0.0147, node loss: 0.0103\n",
      "Epoch: 291, total loss: 0.0254, edge loss: 0.0147, node loss: 0.0107\n",
      "Epoch: 292, total loss: 0.0249, edge loss: 0.0147, node loss: 0.0102\n",
      "Epoch: 293, total loss: 0.0248, edge loss: 0.0147, node loss: 0.0101\n",
      "Epoch: 294, total loss: 0.0248, edge loss: 0.0147, node loss: 0.0101\n",
      "Epoch: 295, total loss: 0.0246, edge loss: 0.0147, node loss: 0.0099\n",
      "Epoch: 296, total loss: 0.0247, edge loss: 0.0147, node loss: 0.0100\n",
      "Epoch: 297, total loss: 0.0248, edge loss: 0.0147, node loss: 0.0101\n",
      "Epoch: 298, total loss: 0.0247, edge loss: 0.0147, node loss: 0.0100\n",
      "Epoch: 299, total loss: 0.0254, edge loss: 0.0147, node loss: 0.0107\n",
      "Epoch: 300, total loss: 0.0249, edge loss: 0.0147, node loss: 0.0102\n",
      "Epoch: 301, total loss: 0.0250, edge loss: 0.0147, node loss: 0.0103\n",
      "Epoch: 302, total loss: 0.0244, edge loss: 0.0147, node loss: 0.0097\n",
      "Epoch: 303, total loss: 0.0244, edge loss: 0.0147, node loss: 0.0097\n",
      "Epoch: 304, total loss: 0.0244, edge loss: 0.0147, node loss: 0.0097\n",
      "Epoch: 305, total loss: 0.0243, edge loss: 0.0147, node loss: 0.0096\n",
      "Epoch: 306, total loss: 0.0244, edge loss: 0.0147, node loss: 0.0097\n",
      "Epoch: 307, total loss: 0.0245, edge loss: 0.0147, node loss: 0.0098\n",
      "Epoch: 308, total loss: 0.0250, edge loss: 0.0147, node loss: 0.0104\n",
      "Epoch: 309, total loss: 0.0244, edge loss: 0.0147, node loss: 0.0097\n",
      "Epoch: 310, total loss: 0.0248, edge loss: 0.0147, node loss: 0.0101\n",
      "Epoch: 311, total loss: 0.0249, edge loss: 0.0147, node loss: 0.0102\n",
      "Epoch: 312, total loss: 0.0250, edge loss: 0.0147, node loss: 0.0103\n",
      "Epoch: 313, total loss: 0.0244, edge loss: 0.0147, node loss: 0.0097\n",
      "Epoch: 314, total loss: 0.0249, edge loss: 0.0147, node loss: 0.0102\n",
      "Epoch: 315, total loss: 0.0252, edge loss: 0.0147, node loss: 0.0105\n",
      "Epoch: 316, total loss: 0.0250, edge loss: 0.0147, node loss: 0.0103\n",
      "Epoch: 317, total loss: 0.0253, edge loss: 0.0147, node loss: 0.0106\n",
      "Epoch: 318, total loss: 0.0243, edge loss: 0.0147, node loss: 0.0096\n",
      "Epoch: 319, total loss: 0.0243, edge loss: 0.0147, node loss: 0.0096\n",
      "Epoch: 320, total loss: 0.0244, edge loss: 0.0147, node loss: 0.0097\n",
      "Epoch: 321, total loss: 0.0242, edge loss: 0.0147, node loss: 0.0095\n",
      "Epoch: 322, total loss: 0.0248, edge loss: 0.0147, node loss: 0.0101\n",
      "Epoch: 323, total loss: 0.0246, edge loss: 0.0147, node loss: 0.0099\n",
      "Epoch: 324, total loss: 0.0243, edge loss: 0.0147, node loss: 0.0096\n",
      "Epoch: 325, total loss: 0.0243, edge loss: 0.0147, node loss: 0.0096\n",
      "Epoch: 326, total loss: 0.0243, edge loss: 0.0147, node loss: 0.0096\n",
      "Epoch: 327, total loss: 0.0245, edge loss: 0.0147, node loss: 0.0098\n",
      "Epoch: 328, total loss: 0.0246, edge loss: 0.0147, node loss: 0.0098\n",
      "Epoch: 329, total loss: 0.0246, edge loss: 0.0147, node loss: 0.0099\n",
      "Epoch: 330, total loss: 0.0244, edge loss: 0.0147, node loss: 0.0097\n",
      "Epoch: 331, total loss: 0.0245, edge loss: 0.0147, node loss: 0.0098\n",
      "Epoch: 332, total loss: 0.0245, edge loss: 0.0147, node loss: 0.0098\n",
      "Epoch: 333, total loss: 0.0251, edge loss: 0.0147, node loss: 0.0104\n",
      "Epoch: 334, total loss: 0.0250, edge loss: 0.0147, node loss: 0.0103\n",
      "Epoch: 335, total loss: 0.0249, edge loss: 0.0147, node loss: 0.0102\n",
      "Epoch: 336, total loss: 0.0247, edge loss: 0.0147, node loss: 0.0100\n",
      "Epoch: 337, total loss: 0.0247, edge loss: 0.0147, node loss: 0.0101\n",
      "Epoch: 338, total loss: 0.0244, edge loss: 0.0147, node loss: 0.0096\n",
      "Epoch: 339, total loss: 0.0240, edge loss: 0.0147, node loss: 0.0094\n",
      "Epoch: 340, total loss: 0.0243, edge loss: 0.0147, node loss: 0.0096\n",
      "Epoch: 341, total loss: 0.0242, edge loss: 0.0147, node loss: 0.0095\n",
      "Epoch: 342, total loss: 0.0252, edge loss: 0.0147, node loss: 0.0105\n",
      "Epoch: 343, total loss: 0.0245, edge loss: 0.0147, node loss: 0.0098\n",
      "Epoch: 344, total loss: 0.0241, edge loss: 0.0147, node loss: 0.0093\n",
      "Epoch: 345, total loss: 0.0242, edge loss: 0.0147, node loss: 0.0095\n",
      "Epoch: 346, total loss: 0.0243, edge loss: 0.0147, node loss: 0.0096\n",
      "Epoch: 347, total loss: 0.0249, edge loss: 0.0147, node loss: 0.0102\n",
      "Epoch: 348, total loss: 0.0244, edge loss: 0.0147, node loss: 0.0097\n",
      "Epoch: 349, total loss: 0.0250, edge loss: 0.0147, node loss: 0.0103\n",
      "Epoch: 350, total loss: 0.0242, edge loss: 0.0147, node loss: 0.0095\n",
      "Epoch: 351, total loss: 0.0245, edge loss: 0.0147, node loss: 0.0098\n",
      "Epoch: 352, total loss: 0.0242, edge loss: 0.0147, node loss: 0.0094\n",
      "Epoch: 353, total loss: 0.0243, edge loss: 0.0147, node loss: 0.0096\n",
      "Epoch: 354, total loss: 0.0240, edge loss: 0.0147, node loss: 0.0093\n",
      "Epoch: 355, total loss: 0.0241, edge loss: 0.0147, node loss: 0.0094\n",
      "Epoch: 356, total loss: 0.0238, edge loss: 0.0147, node loss: 0.0091\n",
      "Epoch: 357, total loss: 0.0244, edge loss: 0.0147, node loss: 0.0097\n",
      "Epoch: 358, total loss: 0.0242, edge loss: 0.0147, node loss: 0.0096\n",
      "Epoch: 359, total loss: 0.0244, edge loss: 0.0147, node loss: 0.0097\n",
      "Epoch: 360, total loss: 0.0245, edge loss: 0.0147, node loss: 0.0098\n",
      "Epoch: 361, total loss: 0.0246, edge loss: 0.0147, node loss: 0.0099\n",
      "Epoch: 362, total loss: 0.0244, edge loss: 0.0147, node loss: 0.0097\n",
      "Epoch: 363, total loss: 0.0240, edge loss: 0.0147, node loss: 0.0093\n",
      "Epoch: 364, total loss: 0.0243, edge loss: 0.0147, node loss: 0.0096\n",
      "Epoch: 365, total loss: 0.0247, edge loss: 0.0147, node loss: 0.0100\n",
      "Epoch: 366, total loss: 0.0242, edge loss: 0.0147, node loss: 0.0095\n",
      "Epoch: 367, total loss: 0.0250, edge loss: 0.0147, node loss: 0.0103\n",
      "Epoch: 368, total loss: 0.0246, edge loss: 0.0147, node loss: 0.0099\n",
      "Epoch: 369, total loss: 0.0240, edge loss: 0.0147, node loss: 0.0093\n",
      "Epoch: 370, total loss: 0.0238, edge loss: 0.0147, node loss: 0.0091\n",
      "Epoch: 371, total loss: 0.0242, edge loss: 0.0147, node loss: 0.0094\n",
      "Epoch: 372, total loss: 0.0242, edge loss: 0.0147, node loss: 0.0095\n",
      "Epoch: 373, total loss: 0.0246, edge loss: 0.0147, node loss: 0.0099\n",
      "Epoch: 374, total loss: 0.0241, edge loss: 0.0147, node loss: 0.0094\n",
      "Epoch: 375, total loss: 0.0245, edge loss: 0.0147, node loss: 0.0098\n",
      "Epoch: 376, total loss: 0.0245, edge loss: 0.0147, node loss: 0.0098\n",
      "Epoch: 377, total loss: 0.0246, edge loss: 0.0147, node loss: 0.0099\n",
      "Epoch: 378, total loss: 0.0248, edge loss: 0.0147, node loss: 0.0101\n",
      "Epoch: 379, total loss: 0.0246, edge loss: 0.0147, node loss: 0.0099\n",
      "Epoch: 380, total loss: 0.0252, edge loss: 0.0147, node loss: 0.0105\n",
      "Epoch: 381, total loss: 0.0244, edge loss: 0.0147, node loss: 0.0097\n",
      "Epoch: 382, total loss: 0.0243, edge loss: 0.0147, node loss: 0.0096\n",
      "Epoch: 383, total loss: 0.0240, edge loss: 0.0147, node loss: 0.0093\n",
      "Epoch: 384, total loss: 0.0239, edge loss: 0.0147, node loss: 0.0092\n",
      "Epoch: 385, total loss: 0.0240, edge loss: 0.0147, node loss: 0.0093\n",
      "Epoch: 386, total loss: 0.0246, edge loss: 0.0147, node loss: 0.0099\n",
      "Epoch: 387, total loss: 0.0240, edge loss: 0.0147, node loss: 0.0093\n",
      "Epoch: 388, total loss: 0.0242, edge loss: 0.0147, node loss: 0.0095\n",
      "Epoch: 389, total loss: 0.0237, edge loss: 0.0147, node loss: 0.0090\n",
      "Epoch: 390, total loss: 0.0244, edge loss: 0.0147, node loss: 0.0097\n",
      "Epoch: 391, total loss: 0.0248, edge loss: 0.0147, node loss: 0.0101\n",
      "Epoch: 392, total loss: 0.0247, edge loss: 0.0147, node loss: 0.0099\n",
      "Epoch: 393, total loss: 0.0250, edge loss: 0.0147, node loss: 0.0103\n",
      "Epoch: 394, total loss: 0.0245, edge loss: 0.0147, node loss: 0.0098\n",
      "Epoch: 395, total loss: 0.0248, edge loss: 0.0147, node loss: 0.0100\n",
      "Epoch: 396, total loss: 0.0244, edge loss: 0.0147, node loss: 0.0097\n",
      "Epoch: 397, total loss: 0.0244, edge loss: 0.0147, node loss: 0.0098\n",
      "Epoch: 398, total loss: 0.0242, edge loss: 0.0147, node loss: 0.0095\n",
      "Epoch: 399, total loss: 0.0242, edge loss: 0.0147, node loss: 0.0095\n",
      "Epoch: 400, total loss: 0.0244, edge loss: 0.0147, node loss: 0.0097\n",
      "Epoch: 401, total loss: 0.0242, edge loss: 0.0147, node loss: 0.0095\n",
      "Epoch: 402, total loss: 0.0242, edge loss: 0.0147, node loss: 0.0095\n",
      "Epoch: 403, total loss: 0.0239, edge loss: 0.0147, node loss: 0.0091\n",
      "Epoch: 404, total loss: 0.0239, edge loss: 0.0147, node loss: 0.0092\n",
      "Epoch: 405, total loss: 0.0239, edge loss: 0.0147, node loss: 0.0092\n",
      "Epoch: 406, total loss: 0.0239, edge loss: 0.0147, node loss: 0.0092\n",
      "Epoch: 407, total loss: 0.0242, edge loss: 0.0147, node loss: 0.0095\n",
      "Epoch: 408, total loss: 0.0242, edge loss: 0.0147, node loss: 0.0095\n",
      "Epoch: 409, total loss: 0.0242, edge loss: 0.0147, node loss: 0.0095\n",
      "Epoch: 410, total loss: 0.0249, edge loss: 0.0147, node loss: 0.0102\n",
      "Epoch: 411, total loss: 0.0247, edge loss: 0.0147, node loss: 0.0100\n",
      "Epoch: 412, total loss: 0.0251, edge loss: 0.0147, node loss: 0.0104\n",
      "Epoch: 413, total loss: 0.0241, edge loss: 0.0147, node loss: 0.0094\n",
      "Epoch: 414, total loss: 0.0239, edge loss: 0.0147, node loss: 0.0092\n",
      "Epoch: 415, total loss: 0.0237, edge loss: 0.0147, node loss: 0.0090\n",
      "Epoch: 416, total loss: 0.0234, edge loss: 0.0147, node loss: 0.0087\n",
      "Epoch: 417, total loss: 0.0236, edge loss: 0.0147, node loss: 0.0089\n",
      "Epoch: 418, total loss: 0.0236, edge loss: 0.0147, node loss: 0.0089\n",
      "Epoch: 419, total loss: 0.0237, edge loss: 0.0147, node loss: 0.0090\n",
      "Epoch: 420, total loss: 0.0243, edge loss: 0.0147, node loss: 0.0096\n",
      "Epoch: 421, total loss: 0.0253, edge loss: 0.0147, node loss: 0.0106\n",
      "Epoch: 422, total loss: 0.0257, edge loss: 0.0147, node loss: 0.0110\n",
      "Epoch: 423, total loss: 0.0254, edge loss: 0.0147, node loss: 0.0107\n",
      "Epoch: 424, total loss: 0.0240, edge loss: 0.0147, node loss: 0.0093\n",
      "Epoch: 425, total loss: 0.0238, edge loss: 0.0147, node loss: 0.0091\n",
      "Epoch: 426, total loss: 0.0235, edge loss: 0.0147, node loss: 0.0088\n",
      "Epoch: 427, total loss: 0.0235, edge loss: 0.0147, node loss: 0.0088\n",
      "Epoch: 428, total loss: 0.0236, edge loss: 0.0147, node loss: 0.0089\n",
      "Epoch: 429, total loss: 0.0235, edge loss: 0.0147, node loss: 0.0088\n",
      "Epoch: 430, total loss: 0.0238, edge loss: 0.0147, node loss: 0.0091\n",
      "Epoch: 431, total loss: 0.0237, edge loss: 0.0147, node loss: 0.0090\n",
      "Epoch: 432, total loss: 0.0239, edge loss: 0.0147, node loss: 0.0093\n",
      "Epoch: 433, total loss: 0.0239, edge loss: 0.0147, node loss: 0.0092\n",
      "Epoch: 434, total loss: 0.0239, edge loss: 0.0147, node loss: 0.0092\n",
      "Epoch: 435, total loss: 0.0239, edge loss: 0.0147, node loss: 0.0093\n",
      "Epoch: 436, total loss: 0.0239, edge loss: 0.0147, node loss: 0.0093\n",
      "Epoch: 437, total loss: 0.0242, edge loss: 0.0147, node loss: 0.0095\n",
      "Epoch: 438, total loss: 0.0254, edge loss: 0.0147, node loss: 0.0107\n",
      "Epoch: 439, total loss: 0.0256, edge loss: 0.0147, node loss: 0.0110\n",
      "Epoch: 440, total loss: 0.0245, edge loss: 0.0147, node loss: 0.0098\n",
      "Epoch: 441, total loss: 0.0251, edge loss: 0.0147, node loss: 0.0104\n",
      "Epoch: 442, total loss: 0.0237, edge loss: 0.0147, node loss: 0.0090\n",
      "Epoch: 443, total loss: 0.0240, edge loss: 0.0147, node loss: 0.0092\n",
      "Epoch: 444, total loss: 0.0241, edge loss: 0.0147, node loss: 0.0094\n",
      "Epoch: 445, total loss: 0.0234, edge loss: 0.0147, node loss: 0.0087\n",
      "Epoch: 446, total loss: 0.0239, edge loss: 0.0147, node loss: 0.0091\n",
      "Epoch: 447, total loss: 0.0237, edge loss: 0.0147, node loss: 0.0090\n",
      "Epoch: 448, total loss: 0.0238, edge loss: 0.0147, node loss: 0.0091\n",
      "Epoch: 449, total loss: 0.0240, edge loss: 0.0147, node loss: 0.0092\n",
      "Epoch: 450, total loss: 0.0238, edge loss: 0.0147, node loss: 0.0091\n",
      "Epoch: 451, total loss: 0.0241, edge loss: 0.0147, node loss: 0.0094\n",
      "Epoch: 452, total loss: 0.0245, edge loss: 0.0147, node loss: 0.0098\n",
      "Epoch: 453, total loss: 0.0245, edge loss: 0.0147, node loss: 0.0098\n",
      "Epoch: 454, total loss: 0.0239, edge loss: 0.0147, node loss: 0.0092\n",
      "Epoch: 455, total loss: 0.0242, edge loss: 0.0147, node loss: 0.0095\n",
      "Epoch: 456, total loss: 0.0234, edge loss: 0.0147, node loss: 0.0087\n",
      "Epoch: 457, total loss: 0.0236, edge loss: 0.0147, node loss: 0.0089\n",
      "Epoch: 458, total loss: 0.0236, edge loss: 0.0147, node loss: 0.0089\n",
      "Epoch: 459, total loss: 0.0234, edge loss: 0.0147, node loss: 0.0087\n",
      "Epoch: 460, total loss: 0.0238, edge loss: 0.0147, node loss: 0.0091\n",
      "Epoch: 461, total loss: 0.0236, edge loss: 0.0147, node loss: 0.0089\n",
      "Epoch: 462, total loss: 0.0238, edge loss: 0.0147, node loss: 0.0091\n",
      "Epoch: 463, total loss: 0.0241, edge loss: 0.0147, node loss: 0.0093\n",
      "Epoch: 464, total loss: 0.0240, edge loss: 0.0147, node loss: 0.0093\n",
      "Epoch: 465, total loss: 0.0234, edge loss: 0.0147, node loss: 0.0086\n",
      "Epoch: 466, total loss: 0.0239, edge loss: 0.0147, node loss: 0.0092\n",
      "Epoch: 467, total loss: 0.0234, edge loss: 0.0147, node loss: 0.0086\n",
      "Epoch: 468, total loss: 0.0235, edge loss: 0.0147, node loss: 0.0088\n",
      "Epoch: 469, total loss: 0.0233, edge loss: 0.0147, node loss: 0.0086\n",
      "Epoch: 470, total loss: 0.0236, edge loss: 0.0147, node loss: 0.0089\n",
      "Epoch: 471, total loss: 0.0244, edge loss: 0.0147, node loss: 0.0097\n",
      "Epoch: 472, total loss: 0.0244, edge loss: 0.0147, node loss: 0.0097\n",
      "Epoch: 473, total loss: 0.0254, edge loss: 0.0147, node loss: 0.0107\n",
      "Epoch: 474, total loss: 0.0257, edge loss: 0.0147, node loss: 0.0109\n",
      "Epoch: 475, total loss: 0.0250, edge loss: 0.0147, node loss: 0.0103\n",
      "Epoch: 476, total loss: 0.0245, edge loss: 0.0147, node loss: 0.0098\n",
      "Epoch: 477, total loss: 0.0241, edge loss: 0.0147, node loss: 0.0094\n",
      "Epoch: 478, total loss: 0.0237, edge loss: 0.0147, node loss: 0.0090\n",
      "Epoch: 479, total loss: 0.0237, edge loss: 0.0147, node loss: 0.0090\n",
      "Epoch: 480, total loss: 0.0238, edge loss: 0.0147, node loss: 0.0091\n",
      "Epoch: 481, total loss: 0.0239, edge loss: 0.0147, node loss: 0.0092\n",
      "Epoch: 482, total loss: 0.0240, edge loss: 0.0147, node loss: 0.0093\n",
      "Epoch: 483, total loss: 0.0242, edge loss: 0.0147, node loss: 0.0095\n",
      "Epoch: 484, total loss: 0.0243, edge loss: 0.0147, node loss: 0.0096\n",
      "Epoch: 485, total loss: 0.0242, edge loss: 0.0147, node loss: 0.0095\n",
      "Epoch: 486, total loss: 0.0241, edge loss: 0.0147, node loss: 0.0094\n",
      "Epoch: 487, total loss: 0.0241, edge loss: 0.0147, node loss: 0.0094\n",
      "Epoch: 488, total loss: 0.0238, edge loss: 0.0147, node loss: 0.0091\n",
      "Epoch: 489, total loss: 0.0239, edge loss: 0.0147, node loss: 0.0091\n",
      "Epoch: 490, total loss: 0.0238, edge loss: 0.0147, node loss: 0.0090\n",
      "Epoch: 491, total loss: 0.0238, edge loss: 0.0147, node loss: 0.0091\n",
      "Epoch: 492, total loss: 0.0237, edge loss: 0.0147, node loss: 0.0090\n",
      "Epoch: 493, total loss: 0.0239, edge loss: 0.0147, node loss: 0.0092\n",
      "Epoch: 494, total loss: 0.0238, edge loss: 0.0147, node loss: 0.0091\n",
      "Epoch: 495, total loss: 0.0239, edge loss: 0.0147, node loss: 0.0092\n",
      "Epoch: 496, total loss: 0.0237, edge loss: 0.0147, node loss: 0.0090\n",
      "Epoch: 497, total loss: 0.0234, edge loss: 0.0147, node loss: 0.0087\n",
      "Epoch: 498, total loss: 0.0243, edge loss: 0.0147, node loss: 0.0096\n",
      "Epoch: 499, total loss: 0.0243, edge loss: 0.0147, node loss: 0.0096\n",
      "Epoch: 500, total loss: 0.0237, edge loss: 0.0147, node loss: 0.0090\n",
      "Epoch: 501, total loss: 0.0244, edge loss: 0.0147, node loss: 0.0097\n",
      "Epoch: 502, total loss: 0.0242, edge loss: 0.0147, node loss: 0.0095\n",
      "Epoch: 503, total loss: 0.0236, edge loss: 0.0147, node loss: 0.0089\n",
      "Epoch: 504, total loss: 0.0241, edge loss: 0.0147, node loss: 0.0094\n",
      "Epoch: 505, total loss: 0.0234, edge loss: 0.0147, node loss: 0.0087\n",
      "Epoch: 506, total loss: 0.0239, edge loss: 0.0147, node loss: 0.0092\n",
      "Epoch: 507, total loss: 0.0235, edge loss: 0.0147, node loss: 0.0088\n",
      "Epoch: 508, total loss: 0.0237, edge loss: 0.0147, node loss: 0.0090\n",
      "Epoch: 509, total loss: 0.0233, edge loss: 0.0147, node loss: 0.0086\n",
      "Epoch: 510, total loss: 0.0238, edge loss: 0.0147, node loss: 0.0091\n",
      "Epoch: 511, total loss: 0.0236, edge loss: 0.0147, node loss: 0.0089\n",
      "Epoch: 512, total loss: 0.0235, edge loss: 0.0147, node loss: 0.0087\n",
      "Epoch: 513, total loss: 0.0235, edge loss: 0.0147, node loss: 0.0088\n",
      "Epoch: 514, total loss: 0.0232, edge loss: 0.0147, node loss: 0.0085\n",
      "Epoch: 515, total loss: 0.0239, edge loss: 0.0147, node loss: 0.0092\n",
      "Epoch: 516, total loss: 0.0240, edge loss: 0.0147, node loss: 0.0093\n",
      "Epoch: 517, total loss: 0.0246, edge loss: 0.0147, node loss: 0.0099\n",
      "Epoch: 518, total loss: 0.0242, edge loss: 0.0147, node loss: 0.0095\n",
      "Epoch: 519, total loss: 0.0239, edge loss: 0.0147, node loss: 0.0092\n",
      "Epoch: 520, total loss: 0.0237, edge loss: 0.0147, node loss: 0.0090\n",
      "Epoch: 521, total loss: 0.0239, edge loss: 0.0147, node loss: 0.0092\n",
      "Epoch: 522, total loss: 0.0233, edge loss: 0.0147, node loss: 0.0086\n",
      "Epoch: 523, total loss: 0.0237, edge loss: 0.0147, node loss: 0.0090\n",
      "Epoch: 524, total loss: 0.0233, edge loss: 0.0147, node loss: 0.0086\n",
      "Epoch: 525, total loss: 0.0231, edge loss: 0.0147, node loss: 0.0084\n",
      "Epoch: 526, total loss: 0.0234, edge loss: 0.0147, node loss: 0.0087\n",
      "Epoch: 527, total loss: 0.0240, edge loss: 0.0147, node loss: 0.0094\n",
      "Epoch: 528, total loss: 0.0239, edge loss: 0.0147, node loss: 0.0092\n",
      "Epoch: 529, total loss: 0.0239, edge loss: 0.0147, node loss: 0.0092\n",
      "Epoch: 530, total loss: 0.0250, edge loss: 0.0147, node loss: 0.0103\n",
      "Epoch: 531, total loss: 0.0241, edge loss: 0.0147, node loss: 0.0094\n",
      "Epoch: 532, total loss: 0.0237, edge loss: 0.0147, node loss: 0.0090\n",
      "Epoch: 533, total loss: 0.0250, edge loss: 0.0147, node loss: 0.0103\n",
      "Epoch: 534, total loss: 0.0240, edge loss: 0.0147, node loss: 0.0093\n",
      "Epoch: 535, total loss: 0.0241, edge loss: 0.0147, node loss: 0.0094\n",
      "Epoch: 536, total loss: 0.0234, edge loss: 0.0147, node loss: 0.0087\n",
      "Epoch: 537, total loss: 0.0235, edge loss: 0.0147, node loss: 0.0088\n",
      "Epoch: 538, total loss: 0.0232, edge loss: 0.0147, node loss: 0.0085\n",
      "Epoch: 539, total loss: 0.0231, edge loss: 0.0147, node loss: 0.0084\n",
      "Epoch: 540, total loss: 0.0231, edge loss: 0.0147, node loss: 0.0084\n",
      "Epoch: 541, total loss: 0.0232, edge loss: 0.0147, node loss: 0.0085\n",
      "Epoch: 542, total loss: 0.0234, edge loss: 0.0147, node loss: 0.0087\n",
      "Epoch: 543, total loss: 0.0240, edge loss: 0.0147, node loss: 0.0093\n",
      "Epoch: 544, total loss: 0.0234, edge loss: 0.0147, node loss: 0.0087\n",
      "Epoch: 545, total loss: 0.0242, edge loss: 0.0147, node loss: 0.0095\n",
      "Epoch: 546, total loss: 0.0234, edge loss: 0.0147, node loss: 0.0087\n",
      "Epoch: 547, total loss: 0.0236, edge loss: 0.0147, node loss: 0.0088\n",
      "Epoch: 548, total loss: 0.0233, edge loss: 0.0147, node loss: 0.0086\n",
      "Epoch: 549, total loss: 0.0239, edge loss: 0.0147, node loss: 0.0091\n",
      "Epoch: 550, total loss: 0.0238, edge loss: 0.0147, node loss: 0.0091\n",
      "Epoch: 551, total loss: 0.0252, edge loss: 0.0147, node loss: 0.0105\n",
      "Epoch: 552, total loss: 0.0246, edge loss: 0.0147, node loss: 0.0099\n",
      "Epoch: 553, total loss: 0.0236, edge loss: 0.0147, node loss: 0.0089\n",
      "Epoch: 554, total loss: 0.0248, edge loss: 0.0147, node loss: 0.0101\n",
      "Epoch: 555, total loss: 0.0237, edge loss: 0.0147, node loss: 0.0090\n",
      "Epoch: 556, total loss: 0.0236, edge loss: 0.0147, node loss: 0.0089\n",
      "Epoch: 557, total loss: 0.0234, edge loss: 0.0147, node loss: 0.0087\n",
      "Epoch: 558, total loss: 0.0234, edge loss: 0.0147, node loss: 0.0087\n",
      "Epoch: 559, total loss: 0.0233, edge loss: 0.0147, node loss: 0.0086\n",
      "Epoch: 560, total loss: 0.0233, edge loss: 0.0147, node loss: 0.0086\n",
      "Epoch: 561, total loss: 0.0232, edge loss: 0.0147, node loss: 0.0085\n",
      "Epoch: 562, total loss: 0.0232, edge loss: 0.0147, node loss: 0.0085\n",
      "Epoch: 563, total loss: 0.0243, edge loss: 0.0147, node loss: 0.0096\n",
      "Epoch: 564, total loss: 0.0234, edge loss: 0.0147, node loss: 0.0087\n",
      "Epoch: 565, total loss: 0.0238, edge loss: 0.0147, node loss: 0.0091\n",
      "Epoch: 566, total loss: 0.0238, edge loss: 0.0147, node loss: 0.0092\n",
      "Epoch: 567, total loss: 0.0235, edge loss: 0.0147, node loss: 0.0088\n",
      "Epoch: 568, total loss: 0.0235, edge loss: 0.0147, node loss: 0.0087\n",
      "Epoch: 569, total loss: 0.0237, edge loss: 0.0147, node loss: 0.0090\n",
      "Epoch: 570, total loss: 0.0241, edge loss: 0.0147, node loss: 0.0094\n",
      "Epoch: 571, total loss: 0.0236, edge loss: 0.0147, node loss: 0.0089\n",
      "Epoch: 572, total loss: 0.0241, edge loss: 0.0147, node loss: 0.0094\n",
      "Epoch: 573, total loss: 0.0247, edge loss: 0.0147, node loss: 0.0100\n",
      "Epoch: 574, total loss: 0.0237, edge loss: 0.0147, node loss: 0.0090\n",
      "Epoch: 575, total loss: 0.0231, edge loss: 0.0147, node loss: 0.0084\n",
      "Epoch: 576, total loss: 0.0232, edge loss: 0.0147, node loss: 0.0084\n",
      "Epoch: 577, total loss: 0.0236, edge loss: 0.0147, node loss: 0.0089\n",
      "Epoch: 578, total loss: 0.0229, edge loss: 0.0147, node loss: 0.0082\n",
      "Epoch: 579, total loss: 0.0231, edge loss: 0.0147, node loss: 0.0084\n",
      "Epoch: 580, total loss: 0.0236, edge loss: 0.0147, node loss: 0.0089\n",
      "Epoch: 581, total loss: 0.0236, edge loss: 0.0147, node loss: 0.0089\n",
      "Epoch: 582, total loss: 0.0233, edge loss: 0.0147, node loss: 0.0086\n",
      "Epoch: 583, total loss: 0.0241, edge loss: 0.0147, node loss: 0.0094\n",
      "Epoch: 584, total loss: 0.0235, edge loss: 0.0147, node loss: 0.0088\n",
      "Epoch: 585, total loss: 0.0242, edge loss: 0.0147, node loss: 0.0095\n",
      "Epoch: 586, total loss: 0.0243, edge loss: 0.0147, node loss: 0.0096\n",
      "Epoch: 587, total loss: 0.0240, edge loss: 0.0147, node loss: 0.0092\n",
      "Epoch: 588, total loss: 0.0234, edge loss: 0.0147, node loss: 0.0086\n",
      "Epoch: 589, total loss: 0.0236, edge loss: 0.0147, node loss: 0.0089\n",
      "Epoch: 590, total loss: 0.0237, edge loss: 0.0147, node loss: 0.0090\n",
      "Epoch: 591, total loss: 0.0234, edge loss: 0.0147, node loss: 0.0087\n",
      "Epoch: 592, total loss: 0.0236, edge loss: 0.0147, node loss: 0.0089\n",
      "Epoch: 593, total loss: 0.0234, edge loss: 0.0147, node loss: 0.0087\n",
      "Epoch: 594, total loss: 0.0232, edge loss: 0.0147, node loss: 0.0085\n",
      "Epoch: 595, total loss: 0.0231, edge loss: 0.0147, node loss: 0.0084\n",
      "Epoch: 596, total loss: 0.0232, edge loss: 0.0147, node loss: 0.0085\n",
      "Epoch: 597, total loss: 0.0240, edge loss: 0.0147, node loss: 0.0093\n",
      "Epoch: 598, total loss: 0.0232, edge loss: 0.0147, node loss: 0.0085\n",
      "Epoch: 599, total loss: 0.0241, edge loss: 0.0147, node loss: 0.0094\n",
      "Epoch: 600, total loss: 0.0237, edge loss: 0.0147, node loss: 0.0090\n",
      "Epoch: 601, total loss: 0.0234, edge loss: 0.0147, node loss: 0.0087\n",
      "Epoch: 602, total loss: 0.0238, edge loss: 0.0147, node loss: 0.0091\n",
      "Epoch: 603, total loss: 0.0234, edge loss: 0.0147, node loss: 0.0087\n",
      "Epoch: 604, total loss: 0.0231, edge loss: 0.0147, node loss: 0.0083\n",
      "Epoch: 605, total loss: 0.0241, edge loss: 0.0147, node loss: 0.0094\n",
      "Epoch: 606, total loss: 0.0236, edge loss: 0.0147, node loss: 0.0089\n",
      "Epoch: 607, total loss: 0.0239, edge loss: 0.0147, node loss: 0.0092\n",
      "Epoch: 608, total loss: 0.0243, edge loss: 0.0147, node loss: 0.0096\n",
      "Epoch: 609, total loss: 0.0234, edge loss: 0.0147, node loss: 0.0087\n",
      "Epoch: 610, total loss: 0.0235, edge loss: 0.0147, node loss: 0.0088\n",
      "Epoch: 611, total loss: 0.0236, edge loss: 0.0147, node loss: 0.0089\n",
      "Epoch: 612, total loss: 0.0237, edge loss: 0.0147, node loss: 0.0090\n",
      "Epoch: 613, total loss: 0.0231, edge loss: 0.0147, node loss: 0.0084\n",
      "Epoch: 614, total loss: 0.0234, edge loss: 0.0147, node loss: 0.0087\n",
      "Epoch: 615, total loss: 0.0236, edge loss: 0.0147, node loss: 0.0089\n",
      "Epoch: 616, total loss: 0.0238, edge loss: 0.0147, node loss: 0.0091\n",
      "Epoch: 617, total loss: 0.0252, edge loss: 0.0147, node loss: 0.0105\n",
      "Epoch: 618, total loss: 0.0241, edge loss: 0.0147, node loss: 0.0093\n",
      "Epoch: 619, total loss: 0.0235, edge loss: 0.0147, node loss: 0.0088\n",
      "Epoch: 620, total loss: 0.0236, edge loss: 0.0147, node loss: 0.0089\n",
      "Epoch: 621, total loss: 0.0236, edge loss: 0.0147, node loss: 0.0089\n",
      "Epoch: 622, total loss: 0.0231, edge loss: 0.0147, node loss: 0.0084\n",
      "Epoch: 623, total loss: 0.0227, edge loss: 0.0147, node loss: 0.0080\n",
      "Epoch: 624, total loss: 0.0228, edge loss: 0.0147, node loss: 0.0081\n",
      "Epoch: 625, total loss: 0.0227, edge loss: 0.0147, node loss: 0.0080\n",
      "Epoch: 626, total loss: 0.0233, edge loss: 0.0147, node loss: 0.0086\n",
      "Epoch: 627, total loss: 0.0234, edge loss: 0.0147, node loss: 0.0087\n",
      "Epoch: 628, total loss: 0.0238, edge loss: 0.0147, node loss: 0.0090\n",
      "Epoch: 629, total loss: 0.0238, edge loss: 0.0147, node loss: 0.0091\n",
      "Epoch: 630, total loss: 0.0231, edge loss: 0.0147, node loss: 0.0084\n",
      "Epoch: 631, total loss: 0.0234, edge loss: 0.0147, node loss: 0.0088\n",
      "Epoch: 632, total loss: 0.0242, edge loss: 0.0147, node loss: 0.0095\n",
      "Epoch: 633, total loss: 0.0241, edge loss: 0.0147, node loss: 0.0094\n",
      "Epoch: 634, total loss: 0.0244, edge loss: 0.0147, node loss: 0.0097\n",
      "Epoch: 635, total loss: 0.0239, edge loss: 0.0147, node loss: 0.0092\n",
      "Epoch: 636, total loss: 0.0234, edge loss: 0.0147, node loss: 0.0087\n",
      "Epoch: 637, total loss: 0.0237, edge loss: 0.0147, node loss: 0.0090\n",
      "Epoch: 638, total loss: 0.0231, edge loss: 0.0147, node loss: 0.0084\n",
      "Epoch: 639, total loss: 0.0247, edge loss: 0.0147, node loss: 0.0100\n",
      "Epoch: 640, total loss: 0.0230, edge loss: 0.0147, node loss: 0.0083\n",
      "Epoch: 641, total loss: 0.0239, edge loss: 0.0147, node loss: 0.0092\n",
      "Epoch: 642, total loss: 0.0234, edge loss: 0.0147, node loss: 0.0087\n",
      "Epoch: 643, total loss: 0.0235, edge loss: 0.0147, node loss: 0.0088\n",
      "Epoch: 644, total loss: 0.0232, edge loss: 0.0147, node loss: 0.0085\n",
      "Epoch: 645, total loss: 0.0238, edge loss: 0.0147, node loss: 0.0091\n",
      "Epoch: 646, total loss: 0.0236, edge loss: 0.0147, node loss: 0.0089\n",
      "Epoch: 647, total loss: 0.0238, edge loss: 0.0147, node loss: 0.0091\n",
      "Epoch: 648, total loss: 0.0234, edge loss: 0.0147, node loss: 0.0087\n",
      "Epoch: 649, total loss: 0.0231, edge loss: 0.0147, node loss: 0.0084\n",
      "Epoch: 650, total loss: 0.0232, edge loss: 0.0147, node loss: 0.0085\n",
      "Epoch: 651, total loss: 0.0234, edge loss: 0.0147, node loss: 0.0087\n",
      "Epoch: 652, total loss: 0.0235, edge loss: 0.0147, node loss: 0.0088\n",
      "Epoch: 653, total loss: 0.0239, edge loss: 0.0147, node loss: 0.0092\n",
      "Epoch: 654, total loss: 0.0243, edge loss: 0.0147, node loss: 0.0095\n",
      "Epoch: 655, total loss: 0.0241, edge loss: 0.0147, node loss: 0.0094\n",
      "Epoch: 656, total loss: 0.0239, edge loss: 0.0147, node loss: 0.0092\n",
      "Epoch: 657, total loss: 0.0235, edge loss: 0.0147, node loss: 0.0088\n",
      "Epoch: 658, total loss: 0.0231, edge loss: 0.0147, node loss: 0.0084\n",
      "Epoch: 659, total loss: 0.0235, edge loss: 0.0147, node loss: 0.0088\n",
      "Epoch: 660, total loss: 0.0231, edge loss: 0.0147, node loss: 0.0084\n",
      "Epoch: 661, total loss: 0.0238, edge loss: 0.0147, node loss: 0.0091\n",
      "Epoch: 662, total loss: 0.0229, edge loss: 0.0147, node loss: 0.0082\n",
      "Epoch: 663, total loss: 0.0237, edge loss: 0.0147, node loss: 0.0090\n",
      "Epoch: 664, total loss: 0.0228, edge loss: 0.0147, node loss: 0.0081\n",
      "Epoch: 665, total loss: 0.0233, edge loss: 0.0147, node loss: 0.0085\n",
      "Epoch: 666, total loss: 0.0231, edge loss: 0.0147, node loss: 0.0083\n",
      "Epoch: 667, total loss: 0.0232, edge loss: 0.0147, node loss: 0.0084\n",
      "Epoch: 668, total loss: 0.0230, edge loss: 0.0147, node loss: 0.0083\n",
      "Epoch: 669, total loss: 0.0230, edge loss: 0.0147, node loss: 0.0083\n",
      "Epoch: 670, total loss: 0.0243, edge loss: 0.0147, node loss: 0.0096\n",
      "Epoch: 671, total loss: 0.0239, edge loss: 0.0147, node loss: 0.0092\n",
      "Epoch: 672, total loss: 0.0241, edge loss: 0.0147, node loss: 0.0094\n",
      "Epoch: 673, total loss: 0.0239, edge loss: 0.0147, node loss: 0.0092\n",
      "Epoch: 674, total loss: 0.0234, edge loss: 0.0147, node loss: 0.0087\n",
      "Epoch: 675, total loss: 0.0233, edge loss: 0.0147, node loss: 0.0086\n",
      "Epoch: 676, total loss: 0.0237, edge loss: 0.0147, node loss: 0.0090\n",
      "Epoch: 677, total loss: 0.0244, edge loss: 0.0147, node loss: 0.0097\n",
      "Epoch: 678, total loss: 0.0233, edge loss: 0.0147, node loss: 0.0086\n",
      "Epoch: 679, total loss: 0.0234, edge loss: 0.0147, node loss: 0.0087\n",
      "Epoch: 680, total loss: 0.0232, edge loss: 0.0147, node loss: 0.0085\n",
      "Epoch: 681, total loss: 0.0231, edge loss: 0.0147, node loss: 0.0084\n",
      "Epoch: 682, total loss: 0.0232, edge loss: 0.0147, node loss: 0.0086\n",
      "Epoch: 683, total loss: 0.0239, edge loss: 0.0147, node loss: 0.0092\n",
      "Epoch: 684, total loss: 0.0241, edge loss: 0.0147, node loss: 0.0094\n",
      "Epoch: 685, total loss: 0.0241, edge loss: 0.0147, node loss: 0.0094\n",
      "Epoch: 686, total loss: 0.0247, edge loss: 0.0147, node loss: 0.0100\n",
      "Epoch: 687, total loss: 0.0236, edge loss: 0.0147, node loss: 0.0089\n",
      "Epoch: 688, total loss: 0.0236, edge loss: 0.0147, node loss: 0.0089\n",
      "Epoch: 689, total loss: 0.0233, edge loss: 0.0147, node loss: 0.0086\n",
      "Epoch: 690, total loss: 0.0230, edge loss: 0.0147, node loss: 0.0083\n",
      "Epoch: 691, total loss: 0.0229, edge loss: 0.0147, node loss: 0.0082\n",
      "Epoch: 692, total loss: 0.0229, edge loss: 0.0147, node loss: 0.0082\n",
      "Epoch: 693, total loss: 0.0234, edge loss: 0.0147, node loss: 0.0086\n",
      "Epoch: 694, total loss: 0.0227, edge loss: 0.0147, node loss: 0.0080\n",
      "Epoch: 695, total loss: 0.0230, edge loss: 0.0147, node loss: 0.0083\n",
      "Epoch: 696, total loss: 0.0229, edge loss: 0.0147, node loss: 0.0082\n",
      "Epoch: 697, total loss: 0.0231, edge loss: 0.0147, node loss: 0.0084\n",
      "Epoch: 698, total loss: 0.0232, edge loss: 0.0147, node loss: 0.0085\n",
      "Epoch: 699, total loss: 0.0237, edge loss: 0.0147, node loss: 0.0090\n",
      "Epoch: 700, total loss: 0.0236, edge loss: 0.0147, node loss: 0.0089\n",
      "Epoch: 701, total loss: 0.0244, edge loss: 0.0147, node loss: 0.0097\n",
      "Epoch: 702, total loss: 0.0231, edge loss: 0.0147, node loss: 0.0084\n",
      "Epoch: 703, total loss: 0.0233, edge loss: 0.0147, node loss: 0.0086\n",
      "Epoch: 704, total loss: 0.0235, edge loss: 0.0147, node loss: 0.0088\n",
      "Epoch: 705, total loss: 0.0232, edge loss: 0.0147, node loss: 0.0085\n",
      "Epoch: 706, total loss: 0.0233, edge loss: 0.0147, node loss: 0.0086\n",
      "Epoch: 707, total loss: 0.0235, edge loss: 0.0147, node loss: 0.0088\n",
      "Epoch: 708, total loss: 0.0232, edge loss: 0.0147, node loss: 0.0085\n",
      "Epoch: 709, total loss: 0.0236, edge loss: 0.0147, node loss: 0.0089\n",
      "Epoch: 710, total loss: 0.0233, edge loss: 0.0147, node loss: 0.0086\n",
      "Epoch: 711, total loss: 0.0239, edge loss: 0.0147, node loss: 0.0092\n",
      "Epoch: 712, total loss: 0.0234, edge loss: 0.0147, node loss: 0.0087\n",
      "Epoch: 713, total loss: 0.0234, edge loss: 0.0147, node loss: 0.0087\n",
      "Epoch: 714, total loss: 0.0235, edge loss: 0.0147, node loss: 0.0088\n",
      "Epoch: 715, total loss: 0.0238, edge loss: 0.0147, node loss: 0.0091\n",
      "Epoch: 716, total loss: 0.0232, edge loss: 0.0147, node loss: 0.0085\n",
      "Epoch: 717, total loss: 0.0232, edge loss: 0.0147, node loss: 0.0085\n",
      "Epoch: 718, total loss: 0.0229, edge loss: 0.0147, node loss: 0.0082\n",
      "Epoch: 719, total loss: 0.0234, edge loss: 0.0147, node loss: 0.0087\n",
      "Epoch: 720, total loss: 0.0237, edge loss: 0.0147, node loss: 0.0090\n",
      "Epoch: 721, total loss: 0.0238, edge loss: 0.0147, node loss: 0.0091\n",
      "Epoch: 722, total loss: 0.0242, edge loss: 0.0147, node loss: 0.0095\n",
      "Epoch: 723, total loss: 0.0246, edge loss: 0.0147, node loss: 0.0099\n",
      "Epoch: 724, total loss: 0.0239, edge loss: 0.0147, node loss: 0.0092\n",
      "Epoch: 725, total loss: 0.0230, edge loss: 0.0147, node loss: 0.0083\n",
      "Epoch: 726, total loss: 0.0231, edge loss: 0.0147, node loss: 0.0084\n",
      "Epoch: 727, total loss: 0.0231, edge loss: 0.0147, node loss: 0.0084\n",
      "Epoch: 728, total loss: 0.0235, edge loss: 0.0147, node loss: 0.0088\n",
      "Epoch: 729, total loss: 0.0237, edge loss: 0.0147, node loss: 0.0090\n",
      "Epoch: 730, total loss: 0.0241, edge loss: 0.0147, node loss: 0.0094\n",
      "Epoch: 731, total loss: 0.0240, edge loss: 0.0147, node loss: 0.0093\n",
      "Epoch: 732, total loss: 0.0245, edge loss: 0.0147, node loss: 0.0098\n",
      "Epoch: 733, total loss: 0.0236, edge loss: 0.0147, node loss: 0.0089\n",
      "Epoch: 734, total loss: 0.0233, edge loss: 0.0147, node loss: 0.0086\n",
      "Epoch: 735, total loss: 0.0230, edge loss: 0.0147, node loss: 0.0083\n",
      "Epoch: 736, total loss: 0.0228, edge loss: 0.0147, node loss: 0.0081\n",
      "Epoch: 737, total loss: 0.0229, edge loss: 0.0147, node loss: 0.0082\n",
      "Epoch: 738, total loss: 0.0228, edge loss: 0.0147, node loss: 0.0081\n",
      "Epoch: 739, total loss: 0.0231, edge loss: 0.0147, node loss: 0.0084\n",
      "Epoch: 740, total loss: 0.0232, edge loss: 0.0147, node loss: 0.0085\n",
      "Epoch: 741, total loss: 0.0230, edge loss: 0.0147, node loss: 0.0083\n",
      "Epoch: 742, total loss: 0.0235, edge loss: 0.0147, node loss: 0.0088\n",
      "Epoch: 743, total loss: 0.0232, edge loss: 0.0147, node loss: 0.0085\n",
      "Epoch: 744, total loss: 0.0234, edge loss: 0.0147, node loss: 0.0086\n",
      "Epoch: 745, total loss: 0.0233, edge loss: 0.0147, node loss: 0.0086\n",
      "Epoch: 746, total loss: 0.0231, edge loss: 0.0147, node loss: 0.0084\n",
      "Epoch: 747, total loss: 0.0234, edge loss: 0.0147, node loss: 0.0087\n",
      "Epoch: 748, total loss: 0.0231, edge loss: 0.0147, node loss: 0.0084\n",
      "Epoch: 749, total loss: 0.0230, edge loss: 0.0147, node loss: 0.0083\n",
      "Epoch: 750, total loss: 0.0235, edge loss: 0.0147, node loss: 0.0088\n",
      "Epoch: 751, total loss: 0.0234, edge loss: 0.0147, node loss: 0.0087\n",
      "Epoch: 752, total loss: 0.0239, edge loss: 0.0147, node loss: 0.0092\n",
      "Epoch: 753, total loss: 0.0234, edge loss: 0.0147, node loss: 0.0087\n",
      "Epoch: 754, total loss: 0.0231, edge loss: 0.0147, node loss: 0.0084\n",
      "Epoch: 755, total loss: 0.0230, edge loss: 0.0147, node loss: 0.0083\n",
      "Epoch: 756, total loss: 0.0235, edge loss: 0.0147, node loss: 0.0088\n",
      "Epoch: 757, total loss: 0.0232, edge loss: 0.0147, node loss: 0.0085\n",
      "Epoch: 758, total loss: 0.0234, edge loss: 0.0147, node loss: 0.0087\n",
      "Epoch: 759, total loss: 0.0233, edge loss: 0.0147, node loss: 0.0086\n",
      "Epoch: 760, total loss: 0.0236, edge loss: 0.0147, node loss: 0.0089\n",
      "Epoch: 761, total loss: 0.0232, edge loss: 0.0147, node loss: 0.0085\n",
      "Epoch: 762, total loss: 0.0238, edge loss: 0.0147, node loss: 0.0090\n",
      "Epoch: 763, total loss: 0.0234, edge loss: 0.0147, node loss: 0.0087\n",
      "Epoch: 764, total loss: 0.0243, edge loss: 0.0147, node loss: 0.0096\n",
      "Epoch: 765, total loss: 0.0229, edge loss: 0.0147, node loss: 0.0082\n",
      "Epoch: 766, total loss: 0.0240, edge loss: 0.0147, node loss: 0.0093\n",
      "Epoch: 767, total loss: 0.0240, edge loss: 0.0147, node loss: 0.0093\n",
      "Epoch: 768, total loss: 0.0243, edge loss: 0.0147, node loss: 0.0096\n",
      "Epoch: 769, total loss: 0.0233, edge loss: 0.0147, node loss: 0.0086\n",
      "Epoch: 770, total loss: 0.0233, edge loss: 0.0147, node loss: 0.0086\n",
      "Epoch: 771, total loss: 0.0234, edge loss: 0.0147, node loss: 0.0087\n",
      "Epoch: 772, total loss: 0.0232, edge loss: 0.0147, node loss: 0.0085\n",
      "Epoch: 773, total loss: 0.0232, edge loss: 0.0147, node loss: 0.0085\n",
      "Epoch: 774, total loss: 0.0234, edge loss: 0.0147, node loss: 0.0087\n",
      "Epoch: 775, total loss: 0.0231, edge loss: 0.0147, node loss: 0.0084\n",
      "Epoch: 776, total loss: 0.0231, edge loss: 0.0147, node loss: 0.0084\n",
      "Epoch: 777, total loss: 0.0224, edge loss: 0.0147, node loss: 0.0077\n",
      "Epoch: 778, total loss: 0.0228, edge loss: 0.0147, node loss: 0.0081\n",
      "Epoch: 779, total loss: 0.0224, edge loss: 0.0147, node loss: 0.0077\n",
      "Epoch: 780, total loss: 0.0228, edge loss: 0.0147, node loss: 0.0081\n",
      "Epoch: 781, total loss: 0.0228, edge loss: 0.0147, node loss: 0.0081\n",
      "Epoch: 782, total loss: 0.0233, edge loss: 0.0147, node loss: 0.0086\n",
      "Epoch: 783, total loss: 0.0239, edge loss: 0.0147, node loss: 0.0091\n",
      "Epoch: 784, total loss: 0.0232, edge loss: 0.0147, node loss: 0.0085\n",
      "Epoch: 785, total loss: 0.0238, edge loss: 0.0147, node loss: 0.0091\n",
      "Epoch: 786, total loss: 0.0236, edge loss: 0.0147, node loss: 0.0089\n",
      "Epoch: 787, total loss: 0.0235, edge loss: 0.0147, node loss: 0.0088\n",
      "Epoch: 788, total loss: 0.0235, edge loss: 0.0147, node loss: 0.0087\n",
      "Epoch: 789, total loss: 0.0235, edge loss: 0.0147, node loss: 0.0088\n",
      "Epoch: 790, total loss: 0.0238, edge loss: 0.0147, node loss: 0.0091\n",
      "Epoch: 791, total loss: 0.0243, edge loss: 0.0147, node loss: 0.0095\n",
      "Epoch: 792, total loss: 0.0238, edge loss: 0.0147, node loss: 0.0091\n",
      "Epoch: 793, total loss: 0.0233, edge loss: 0.0147, node loss: 0.0086\n",
      "Epoch: 794, total loss: 0.0237, edge loss: 0.0147, node loss: 0.0090\n",
      "Epoch: 795, total loss: 0.0233, edge loss: 0.0147, node loss: 0.0086\n",
      "Epoch: 796, total loss: 0.0234, edge loss: 0.0147, node loss: 0.0086\n",
      "Epoch: 797, total loss: 0.0234, edge loss: 0.0147, node loss: 0.0086\n",
      "Epoch: 798, total loss: 0.0229, edge loss: 0.0147, node loss: 0.0082\n",
      "Epoch: 799, total loss: 0.0230, edge loss: 0.0147, node loss: 0.0083\n",
      "Epoch: 800, total loss: 0.0229, edge loss: 0.0147, node loss: 0.0082\n",
      "Epoch: 801, total loss: 0.0232, edge loss: 0.0147, node loss: 0.0085\n",
      "Epoch: 802, total loss: 0.0228, edge loss: 0.0147, node loss: 0.0081\n",
      "Epoch: 803, total loss: 0.0227, edge loss: 0.0147, node loss: 0.0081\n",
      "Epoch: 804, total loss: 0.0229, edge loss: 0.0147, node loss: 0.0081\n",
      "Epoch: 805, total loss: 0.0230, edge loss: 0.0147, node loss: 0.0083\n",
      "Epoch: 806, total loss: 0.0232, edge loss: 0.0147, node loss: 0.0085\n",
      "Epoch: 807, total loss: 0.0233, edge loss: 0.0147, node loss: 0.0086\n",
      "Epoch: 808, total loss: 0.0233, edge loss: 0.0147, node loss: 0.0086\n",
      "Epoch: 809, total loss: 0.0239, edge loss: 0.0147, node loss: 0.0092\n",
      "Epoch: 810, total loss: 0.0232, edge loss: 0.0147, node loss: 0.0085\n",
      "Epoch: 811, total loss: 0.0233, edge loss: 0.0147, node loss: 0.0086\n",
      "Epoch: 812, total loss: 0.0233, edge loss: 0.0147, node loss: 0.0086\n",
      "Epoch: 813, total loss: 0.0227, edge loss: 0.0147, node loss: 0.0080\n",
      "Epoch: 814, total loss: 0.0225, edge loss: 0.0147, node loss: 0.0078\n",
      "Epoch: 815, total loss: 0.0226, edge loss: 0.0147, node loss: 0.0079\n",
      "Epoch: 816, total loss: 0.0237, edge loss: 0.0147, node loss: 0.0090\n",
      "Epoch: 817, total loss: 0.0229, edge loss: 0.0147, node loss: 0.0081\n",
      "Epoch: 818, total loss: 0.0239, edge loss: 0.0147, node loss: 0.0092\n",
      "Epoch: 819, total loss: 0.0232, edge loss: 0.0147, node loss: 0.0085\n",
      "Epoch: 820, total loss: 0.0227, edge loss: 0.0147, node loss: 0.0080\n",
      "Epoch: 821, total loss: 0.0229, edge loss: 0.0147, node loss: 0.0082\n",
      "Epoch: 822, total loss: 0.0231, edge loss: 0.0147, node loss: 0.0084\n",
      "Epoch: 823, total loss: 0.0233, edge loss: 0.0147, node loss: 0.0086\n",
      "Epoch: 824, total loss: 0.0247, edge loss: 0.0147, node loss: 0.0100\n",
      "Epoch: 825, total loss: 0.0240, edge loss: 0.0147, node loss: 0.0093\n",
      "Epoch: 826, total loss: 0.0250, edge loss: 0.0147, node loss: 0.0103\n",
      "Epoch: 827, total loss: 0.0234, edge loss: 0.0147, node loss: 0.0087\n",
      "Epoch: 828, total loss: 0.0239, edge loss: 0.0147, node loss: 0.0092\n",
      "Epoch: 829, total loss: 0.0236, edge loss: 0.0147, node loss: 0.0089\n",
      "Epoch: 830, total loss: 0.0235, edge loss: 0.0147, node loss: 0.0088\n",
      "Epoch: 831, total loss: 0.0234, edge loss: 0.0147, node loss: 0.0087\n",
      "Epoch: 832, total loss: 0.0233, edge loss: 0.0147, node loss: 0.0086\n",
      "Epoch: 833, total loss: 0.0230, edge loss: 0.0147, node loss: 0.0083\n",
      "Epoch: 834, total loss: 0.0228, edge loss: 0.0147, node loss: 0.0081\n",
      "Epoch: 835, total loss: 0.0231, edge loss: 0.0147, node loss: 0.0084\n",
      "Epoch: 836, total loss: 0.0233, edge loss: 0.0147, node loss: 0.0086\n",
      "Epoch: 837, total loss: 0.0242, edge loss: 0.0147, node loss: 0.0095\n",
      "Epoch: 838, total loss: 0.0233, edge loss: 0.0147, node loss: 0.0086\n",
      "Epoch: 839, total loss: 0.0230, edge loss: 0.0147, node loss: 0.0083\n",
      "Epoch: 840, total loss: 0.0231, edge loss: 0.0147, node loss: 0.0084\n",
      "Epoch: 841, total loss: 0.0229, edge loss: 0.0147, node loss: 0.0082\n",
      "Epoch: 842, total loss: 0.0233, edge loss: 0.0147, node loss: 0.0086\n",
      "Epoch: 843, total loss: 0.0232, edge loss: 0.0147, node loss: 0.0085\n",
      "Epoch: 844, total loss: 0.0242, edge loss: 0.0147, node loss: 0.0095\n",
      "Epoch: 845, total loss: 0.0235, edge loss: 0.0147, node loss: 0.0088\n",
      "Epoch: 846, total loss: 0.0237, edge loss: 0.0147, node loss: 0.0090\n",
      "Epoch: 847, total loss: 0.0237, edge loss: 0.0147, node loss: 0.0090\n",
      "Epoch: 848, total loss: 0.0233, edge loss: 0.0147, node loss: 0.0086\n",
      "Epoch: 849, total loss: 0.0230, edge loss: 0.0147, node loss: 0.0083\n",
      "Epoch: 850, total loss: 0.0226, edge loss: 0.0147, node loss: 0.0079\n",
      "Epoch: 851, total loss: 0.0229, edge loss: 0.0147, node loss: 0.0082\n",
      "Epoch: 852, total loss: 0.0227, edge loss: 0.0147, node loss: 0.0080\n",
      "Epoch: 853, total loss: 0.0229, edge loss: 0.0147, node loss: 0.0082\n",
      "Epoch: 854, total loss: 0.0231, edge loss: 0.0147, node loss: 0.0084\n",
      "Epoch: 855, total loss: 0.0231, edge loss: 0.0147, node loss: 0.0084\n",
      "Epoch: 856, total loss: 0.0230, edge loss: 0.0147, node loss: 0.0083\n",
      "Epoch: 857, total loss: 0.0228, edge loss: 0.0147, node loss: 0.0081\n",
      "Epoch: 858, total loss: 0.0231, edge loss: 0.0147, node loss: 0.0083\n",
      "Epoch: 859, total loss: 0.0230, edge loss: 0.0147, node loss: 0.0083\n",
      "Epoch: 860, total loss: 0.0235, edge loss: 0.0147, node loss: 0.0088\n",
      "Epoch: 861, total loss: 0.0232, edge loss: 0.0147, node loss: 0.0085\n",
      "Epoch: 862, total loss: 0.0238, edge loss: 0.0147, node loss: 0.0091\n",
      "Epoch: 863, total loss: 0.0239, edge loss: 0.0147, node loss: 0.0092\n",
      "Epoch: 864, total loss: 0.0246, edge loss: 0.0147, node loss: 0.0099\n",
      "Epoch: 865, total loss: 0.0237, edge loss: 0.0147, node loss: 0.0090\n",
      "Epoch: 866, total loss: 0.0237, edge loss: 0.0147, node loss: 0.0090\n",
      "Epoch: 867, total loss: 0.0232, edge loss: 0.0147, node loss: 0.0086\n",
      "Epoch: 868, total loss: 0.0235, edge loss: 0.0147, node loss: 0.0088\n",
      "Epoch: 869, total loss: 0.0230, edge loss: 0.0147, node loss: 0.0083\n",
      "Epoch: 870, total loss: 0.0231, edge loss: 0.0147, node loss: 0.0084\n",
      "Epoch: 871, total loss: 0.0228, edge loss: 0.0147, node loss: 0.0081\n",
      "Epoch: 872, total loss: 0.0230, edge loss: 0.0147, node loss: 0.0083\n",
      "Epoch: 873, total loss: 0.0238, edge loss: 0.0147, node loss: 0.0091\n",
      "Epoch: 874, total loss: 0.0230, edge loss: 0.0147, node loss: 0.0083\n",
      "Epoch: 875, total loss: 0.0236, edge loss: 0.0147, node loss: 0.0089\n",
      "Epoch: 876, total loss: 0.0228, edge loss: 0.0147, node loss: 0.0081\n",
      "Epoch: 877, total loss: 0.0227, edge loss: 0.0147, node loss: 0.0080\n",
      "Epoch: 878, total loss: 0.0230, edge loss: 0.0147, node loss: 0.0083\n",
      "Epoch: 879, total loss: 0.0232, edge loss: 0.0147, node loss: 0.0085\n",
      "Epoch: 880, total loss: 0.0233, edge loss: 0.0147, node loss: 0.0086\n",
      "Epoch: 881, total loss: 0.0232, edge loss: 0.0147, node loss: 0.0085\n",
      "Epoch: 882, total loss: 0.0236, edge loss: 0.0147, node loss: 0.0089\n",
      "Epoch: 883, total loss: 0.0233, edge loss: 0.0147, node loss: 0.0087\n",
      "Epoch: 884, total loss: 0.0237, edge loss: 0.0147, node loss: 0.0090\n",
      "Epoch: 885, total loss: 0.0237, edge loss: 0.0147, node loss: 0.0090\n",
      "Epoch: 886, total loss: 0.0233, edge loss: 0.0147, node loss: 0.0086\n",
      "Epoch: 887, total loss: 0.0233, edge loss: 0.0147, node loss: 0.0086\n",
      "Epoch: 888, total loss: 0.0232, edge loss: 0.0147, node loss: 0.0084\n",
      "Epoch: 889, total loss: 0.0226, edge loss: 0.0147, node loss: 0.0079\n",
      "Epoch: 890, total loss: 0.0226, edge loss: 0.0147, node loss: 0.0079\n",
      "Epoch: 891, total loss: 0.0230, edge loss: 0.0147, node loss: 0.0083\n",
      "Epoch: 892, total loss: 0.0227, edge loss: 0.0147, node loss: 0.0080\n",
      "Epoch: 893, total loss: 0.0231, edge loss: 0.0147, node loss: 0.0084\n",
      "Epoch: 894, total loss: 0.0231, edge loss: 0.0147, node loss: 0.0084\n",
      "Epoch: 895, total loss: 0.0231, edge loss: 0.0147, node loss: 0.0084\n",
      "Epoch: 896, total loss: 0.0229, edge loss: 0.0147, node loss: 0.0082\n",
      "Epoch: 897, total loss: 0.0230, edge loss: 0.0147, node loss: 0.0083\n",
      "Epoch: 898, total loss: 0.0231, edge loss: 0.0147, node loss: 0.0084\n",
      "Epoch: 899, total loss: 0.0232, edge loss: 0.0147, node loss: 0.0085\n",
      "Epoch: 900, total loss: 0.0235, edge loss: 0.0147, node loss: 0.0088\n",
      "Epoch: 901, total loss: 0.0230, edge loss: 0.0147, node loss: 0.0083\n",
      "Epoch: 902, total loss: 0.0231, edge loss: 0.0147, node loss: 0.0084\n",
      "Epoch: 903, total loss: 0.0234, edge loss: 0.0147, node loss: 0.0087\n",
      "Epoch: 904, total loss: 0.0234, edge loss: 0.0147, node loss: 0.0087\n",
      "Epoch: 905, total loss: 0.0231, edge loss: 0.0147, node loss: 0.0084\n",
      "Epoch: 906, total loss: 0.0230, edge loss: 0.0147, node loss: 0.0083\n",
      "Epoch: 907, total loss: 0.0226, edge loss: 0.0147, node loss: 0.0079\n",
      "Epoch: 908, total loss: 0.0226, edge loss: 0.0147, node loss: 0.0079\n",
      "Epoch: 909, total loss: 0.0227, edge loss: 0.0147, node loss: 0.0080\n",
      "Epoch: 910, total loss: 0.0233, edge loss: 0.0147, node loss: 0.0086\n",
      "Epoch: 911, total loss: 0.0229, edge loss: 0.0147, node loss: 0.0082\n",
      "Epoch: 912, total loss: 0.0240, edge loss: 0.0147, node loss: 0.0093\n",
      "Epoch: 913, total loss: 0.0236, edge loss: 0.0147, node loss: 0.0088\n",
      "Epoch: 914, total loss: 0.0226, edge loss: 0.0147, node loss: 0.0079\n",
      "Epoch: 915, total loss: 0.0227, edge loss: 0.0147, node loss: 0.0080\n",
      "Epoch: 916, total loss: 0.0229, edge loss: 0.0147, node loss: 0.0082\n",
      "Epoch: 917, total loss: 0.0227, edge loss: 0.0147, node loss: 0.0080\n",
      "Epoch: 918, total loss: 0.0230, edge loss: 0.0147, node loss: 0.0083\n",
      "Epoch: 919, total loss: 0.0229, edge loss: 0.0147, node loss: 0.0082\n",
      "Epoch: 920, total loss: 0.0232, edge loss: 0.0147, node loss: 0.0085\n",
      "Epoch: 921, total loss: 0.0229, edge loss: 0.0147, node loss: 0.0082\n",
      "Epoch: 922, total loss: 0.0231, edge loss: 0.0147, node loss: 0.0083\n",
      "Epoch: 923, total loss: 0.0233, edge loss: 0.0147, node loss: 0.0086\n",
      "Epoch: 924, total loss: 0.0231, edge loss: 0.0147, node loss: 0.0085\n",
      "Epoch: 925, total loss: 0.0238, edge loss: 0.0147, node loss: 0.0091\n",
      "Epoch: 926, total loss: 0.0231, edge loss: 0.0147, node loss: 0.0084\n",
      "Epoch: 927, total loss: 0.0232, edge loss: 0.0147, node loss: 0.0085\n",
      "Epoch: 928, total loss: 0.0230, edge loss: 0.0147, node loss: 0.0084\n",
      "Epoch: 929, total loss: 0.0234, edge loss: 0.0147, node loss: 0.0087\n",
      "Epoch: 930, total loss: 0.0232, edge loss: 0.0147, node loss: 0.0085\n",
      "Epoch: 931, total loss: 0.0232, edge loss: 0.0147, node loss: 0.0085\n",
      "Epoch: 932, total loss: 0.0227, edge loss: 0.0147, node loss: 0.0080\n",
      "Epoch: 933, total loss: 0.0229, edge loss: 0.0147, node loss: 0.0082\n",
      "Epoch: 934, total loss: 0.0224, edge loss: 0.0147, node loss: 0.0078\n",
      "Epoch: 935, total loss: 0.0228, edge loss: 0.0147, node loss: 0.0081\n",
      "Epoch: 936, total loss: 0.0231, edge loss: 0.0147, node loss: 0.0084\n",
      "Epoch: 937, total loss: 0.0230, edge loss: 0.0147, node loss: 0.0083\n",
      "Epoch: 938, total loss: 0.0234, edge loss: 0.0147, node loss: 0.0087\n",
      "Epoch: 939, total loss: 0.0234, edge loss: 0.0147, node loss: 0.0087\n",
      "Epoch: 940, total loss: 0.0229, edge loss: 0.0147, node loss: 0.0081\n",
      "Epoch: 941, total loss: 0.0228, edge loss: 0.0147, node loss: 0.0081\n",
      "Epoch: 942, total loss: 0.0226, edge loss: 0.0147, node loss: 0.0079\n",
      "Epoch: 943, total loss: 0.0226, edge loss: 0.0147, node loss: 0.0079\n",
      "Epoch: 944, total loss: 0.0226, edge loss: 0.0147, node loss: 0.0079\n",
      "Epoch: 945, total loss: 0.0228, edge loss: 0.0147, node loss: 0.0081\n",
      "Epoch: 946, total loss: 0.0242, edge loss: 0.0147, node loss: 0.0095\n",
      "Epoch: 947, total loss: 0.0232, edge loss: 0.0147, node loss: 0.0085\n",
      "Epoch: 948, total loss: 0.0238, edge loss: 0.0147, node loss: 0.0091\n",
      "Epoch: 949, total loss: 0.0232, edge loss: 0.0147, node loss: 0.0085\n",
      "Epoch: 950, total loss: 0.0227, edge loss: 0.0147, node loss: 0.0080\n",
      "Epoch: 951, total loss: 0.0228, edge loss: 0.0147, node loss: 0.0081\n",
      "Epoch: 952, total loss: 0.0226, edge loss: 0.0147, node loss: 0.0079\n",
      "Epoch: 953, total loss: 0.0228, edge loss: 0.0147, node loss: 0.0080\n",
      "Epoch: 954, total loss: 0.0235, edge loss: 0.0147, node loss: 0.0088\n",
      "Epoch: 955, total loss: 0.0229, edge loss: 0.0147, node loss: 0.0082\n",
      "Epoch: 956, total loss: 0.0233, edge loss: 0.0147, node loss: 0.0086\n",
      "Epoch: 957, total loss: 0.0229, edge loss: 0.0147, node loss: 0.0082\n",
      "Epoch: 958, total loss: 0.0232, edge loss: 0.0147, node loss: 0.0085\n",
      "Epoch: 959, total loss: 0.0235, edge loss: 0.0147, node loss: 0.0088\n",
      "Epoch: 960, total loss: 0.0235, edge loss: 0.0147, node loss: 0.0088\n",
      "Epoch: 961, total loss: 0.0234, edge loss: 0.0147, node loss: 0.0087\n",
      "Epoch: 962, total loss: 0.0230, edge loss: 0.0147, node loss: 0.0083\n",
      "Epoch: 963, total loss: 0.0229, edge loss: 0.0147, node loss: 0.0082\n",
      "Epoch: 964, total loss: 0.0228, edge loss: 0.0147, node loss: 0.0081\n",
      "Epoch: 965, total loss: 0.0232, edge loss: 0.0147, node loss: 0.0085\n",
      "Epoch: 966, total loss: 0.0230, edge loss: 0.0147, node loss: 0.0083\n",
      "Epoch: 967, total loss: 0.0235, edge loss: 0.0147, node loss: 0.0088\n",
      "Epoch: 968, total loss: 0.0223, edge loss: 0.0147, node loss: 0.0076\n",
      "Epoch: 969, total loss: 0.0228, edge loss: 0.0147, node loss: 0.0081\n",
      "Epoch: 970, total loss: 0.0226, edge loss: 0.0147, node loss: 0.0079\n",
      "Epoch: 971, total loss: 0.0226, edge loss: 0.0147, node loss: 0.0079\n",
      "Epoch: 972, total loss: 0.0228, edge loss: 0.0147, node loss: 0.0081\n",
      "Epoch: 973, total loss: 0.0231, edge loss: 0.0147, node loss: 0.0084\n",
      "Epoch: 974, total loss: 0.0230, edge loss: 0.0147, node loss: 0.0083\n",
      "Epoch: 975, total loss: 0.0236, edge loss: 0.0147, node loss: 0.0089\n",
      "Epoch: 976, total loss: 0.0233, edge loss: 0.0147, node loss: 0.0086\n",
      "Epoch: 977, total loss: 0.0230, edge loss: 0.0147, node loss: 0.0083\n",
      "Epoch: 978, total loss: 0.0237, edge loss: 0.0147, node loss: 0.0089\n",
      "Epoch: 979, total loss: 0.0234, edge loss: 0.0147, node loss: 0.0087\n",
      "Epoch: 980, total loss: 0.0233, edge loss: 0.0147, node loss: 0.0085\n",
      "Epoch: 981, total loss: 0.0232, edge loss: 0.0147, node loss: 0.0085\n",
      "Epoch: 982, total loss: 0.0230, edge loss: 0.0147, node loss: 0.0083\n",
      "Epoch: 983, total loss: 0.0232, edge loss: 0.0147, node loss: 0.0084\n",
      "Epoch: 984, total loss: 0.0229, edge loss: 0.0147, node loss: 0.0082\n",
      "Epoch: 985, total loss: 0.0229, edge loss: 0.0147, node loss: 0.0082\n",
      "Epoch: 986, total loss: 0.0230, edge loss: 0.0147, node loss: 0.0083\n",
      "Epoch: 987, total loss: 0.0232, edge loss: 0.0147, node loss: 0.0085\n",
      "Epoch: 988, total loss: 0.0229, edge loss: 0.0147, node loss: 0.0082\n",
      "Epoch: 989, total loss: 0.0231, edge loss: 0.0147, node loss: 0.0084\n",
      "Epoch: 990, total loss: 0.0232, edge loss: 0.0147, node loss: 0.0085\n",
      "Epoch: 991, total loss: 0.0229, edge loss: 0.0147, node loss: 0.0082\n",
      "Epoch: 992, total loss: 0.0234, edge loss: 0.0147, node loss: 0.0087\n",
      "Epoch: 993, total loss: 0.0224, edge loss: 0.0147, node loss: 0.0077\n",
      "Epoch: 994, total loss: 0.0228, edge loss: 0.0147, node loss: 0.0081\n",
      "Epoch: 995, total loss: 0.0224, edge loss: 0.0147, node loss: 0.0077\n",
      "Epoch: 996, total loss: 0.0228, edge loss: 0.0147, node loss: 0.0081\n",
      "Epoch: 997, total loss: 0.0230, edge loss: 0.0147, node loss: 0.0083\n",
      "Epoch: 998, total loss: 0.0228, edge loss: 0.0147, node loss: 0.0081\n",
      "Epoch: 999, total loss: 0.0230, edge loss: 0.0147, node loss: 0.0083\n",
      "Epoch: 1000, total loss: 0.0227, edge loss: 0.0147, node loss: 0.0080\n"
     ]
    }
   ],
   "source": [
    "# Initialize the optimizers\n",
    "node_optimizer = torch.optim.Adam(node_model.parameters(), lr=learning_rate)\n",
    "edge_optimizer = torch.optim.Adam(edge_model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Initialize early stopping\n",
    "node_early_stopping = EarlyStopping(patience=patience, delta=delta, model_name=node_model_name)\n",
    "edge_early_stopping = EarlyStopping(patience=patience, delta=delta, model_name=edge_model_name)\n",
    "\n",
    "# Training loop\n",
    "total_train_losses = []\n",
    "edge_train_losses  = []\n",
    "node_train_losses  = []\n",
    "for epoch in range(n_epochs):\n",
    "    # Initialize train loss variable\n",
    "    total_loss_cum = 0\n",
    "    edge_loss_cum  = 0\n",
    "    node_loss_cum  = 0\n",
    "    for batch_0 in train_loader:\n",
    "        #print()\n",
    "        # Clone batch of graphs\n",
    "        g_batch_0 = batch_0.clone()\n",
    "        \n",
    "        # Move batch data to GPU\n",
    "        g_batch_0 = g_batch_0.to(device)\n",
    "        \n",
    "        # Read number of graphs in batch\n",
    "        batch_size_0 = g_batch_0.num_graphs\n",
    "\n",
    "        # Save graph-level embeddings\n",
    "        embedding_batch_0 = []\n",
    "        for idx in range(batch_size_0):\n",
    "            embedding_batch_0.append(g_batch_0[idx].y.detach().to(device))\n",
    "        \n",
    "        # Initialize the gradient of the optimizers\n",
    "        node_optimizer.zero_grad()\n",
    "        edge_optimizer.zero_grad()\n",
    "        \n",
    "        # Start denoising-diffusing process\n",
    "        t_steps = np.arange(1, n_t_steps+1)\n",
    "        for t_step in t_steps:\n",
    "            # Read time step, which is added to node-level graph embeddings\n",
    "            t_step_std = torch.tensor([t_step / n_t_steps - 0.5], dtype=torch.float).to(device)  # Standard normalization\n",
    "        \n",
    "            # Diffuse the graph with some noise\n",
    "            #print()\n",
    "            #print(f'Step: {t_step}')\n",
    "            #print('Diffusing...')\n",
    "            \n",
    "            g_batch_t = []\n",
    "            e_batch_t = []\n",
    "            for idx in range(batch_size_0):\n",
    "                # Perform a diffusion step at time step t_step for each graph within the batch\n",
    "                graph_t, epsilon_t = diffusion_step(g_batch_0[idx], t_step, n_t_steps, alpha_decay)\n",
    "                \n",
    "                # Append noisy graphs and noises\n",
    "                g_batch_t.append(graph_t)\n",
    "                e_batch_t.append(epsilon_t)\n",
    "        \n",
    "                # Update diffused graph as next one\n",
    "                g_batch_0[idx] = graph_t.clone()\n",
    "            \n",
    "            # Denoise the diffused graph\n",
    "            #print(f'Denoising...')\n",
    "            \n",
    "            # Add embeddings to noisy graphs (t_step information and graph-level embeddings)\n",
    "            for idx in range(batch_size_0):\n",
    "                # Add graph-level embedding to graph_t as node embeddings\n",
    "                g_batch_t[idx] = add_features_to_graph(g_batch_t[idx],\n",
    "                                                       embedding_batch_0[idx])  # To match graph.y shape\n",
    "        \n",
    "                # Add t_step information to graph_t as node embeddings\n",
    "                g_batch_t[idx] = add_features_to_graph(g_batch_t[idx],\n",
    "                                                       t_step_std)  # To match graph.y shape, which is 1D\n",
    "        \n",
    "            # Generate batch objects\n",
    "            g_batch_t = Batch.from_data_list(g_batch_t)\n",
    "            e_batch_t = Batch.from_data_list(e_batch_t)\n",
    "            \n",
    "            # Move data to device\n",
    "            g_batch_t = g_batch_t.to(device)\n",
    "            e_batch_t = e_batch_t.to(device)\n",
    "            \n",
    "            # Predict batch noise at given time step\n",
    "            pred_epsilon_t = predict_noise(g_batch_t, node_model, edge_model)\n",
    "            \n",
    "            # Backpropagation and optimization step\n",
    "            #print('Backpropagating...')\n",
    "\n",
    "            # Calculate the loss for node features and edge attributes\n",
    "            node_loss, edge_loss = get_graph_losses(e_batch_t, pred_epsilon_t, batch_size_0)\n",
    "            \n",
    "            # Backpropagate and optimize node loss\n",
    "            if not node_early_stopping.early_stop:\n",
    "                node_loss.backward(retain_graph=True)\n",
    "                node_optimizer.step()\n",
    "\n",
    "            # Backpropagate and optimize edge loss\n",
    "            if not edge_early_stopping.early_stop:\n",
    "                edge_loss.backward(retain_graph=True)\n",
    "                edge_optimizer.step()\n",
    "\n",
    "            # Accumulate the total training loss\n",
    "            loss = node_loss + edge_loss\n",
    "            \n",
    "            # Get items\n",
    "            total_loss_cum += loss.item()\n",
    "            node_loss_cum  += node_loss.item()\n",
    "            edge_loss_cum  += edge_loss.item()\n",
    "    \n",
    "    # Compute the average train loss over n_t_steps\n",
    "    total_loss_cum /= n_t_steps\n",
    "    node_loss_cum  /= n_t_steps\n",
    "    edge_loss_cum  /= n_t_steps\n",
    "    \n",
    "    # Append average losses\n",
    "    total_train_losses.append(total_loss_cum)\n",
    "    node_train_losses.append(node_loss_cum)\n",
    "    edge_train_losses.append(edge_loss_cum)\n",
    "    \n",
    "    # Check early stopping criteria\n",
    "    node_early_stopping(node_loss_cum, node_model)\n",
    "    edge_early_stopping(edge_loss_cum, edge_model)\n",
    "\n",
    "    if node_early_stopping.early_stop and edge_early_stopping.early_stop:\n",
    "        print('Early stopping')\n",
    "        break\n",
    "    \n",
    "    print(f'Epoch: {epoch+1}, total loss: {total_loss_cum:.4f}, edge loss: {edge_loss_cum:.4f}, node loss: {node_loss_cum:.4f}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-18T14:49:40.143260340Z",
     "start_time": "2024-03-18T13:45:39.911211698Z"
    }
   },
   "id": "5f6c3be11e55a08c",
   "execution_count": 75
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAksAAAGwCAYAAAC5ACFFAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAACzoUlEQVR4nOzdd3wT9RsH8E+SpuneLW2hpbTsWRDLXoIWUAHFrQiKIMpPFFCGTEFAHKi4B3sIyJAhe4+yBMosZXbvmbZp0qzfH0eud8klTdt0P+/Xqy+Su8vd9y4h9+T5LpFer9eDEEIIIYQIEtd0AQghhBBCajMKlgghhBBCLKBgiRBCCCHEAgqWCCGEEEIsoGCJEEIIIcQCCpYIIYQQQiygYIkQQgghxAK7mi5AfaDT6ZCSkgJXV1eIRKKaLg4hhBBCrKDX61FQUIDAwECIxebzRxQs2UBKSgqCgoJquhiEEEIIqYDExEQ0adLE7HoKlmzA1dUVAHOx3dzcarg0hBBCCLGGXC5HUFAQex83h4IlGzBUvbm5uVGwRAghhNQxZTWhoQbehBBCCCEWULBECCGEEGIBBUuEEEIIIRZQmyVCCCGkFtFqtVCr1TVdjHpBKpVCIpFUej8ULBFCCCG1gF6vR1paGvLy8mq6KPWKh4cH/P39KzUOIgVLhBBCSC1gCJT8/Pzg5OREgxxXkl6vh0KhQEZGBgAgICCgwvuiYIkQQgipYVqtlg2UvL29a7o49YajoyMAICMjA35+fhWukqMG3oQQQkgNM7RRcnJyquGS1D+Ga1qZdmAULBFCCCG1BFW92Z4trikFS4QQQgghFlCwRAghhBBiAQVLhBBCCKlTRCIR/vnnn2o7HgVLdYhOp4dSra3pYhBCCCEAmKDF0t/8+fPNvjYuLg4ikQjR0dHVVt6KoqED6pDRqy7gRnI+jn8yAO6O0pouDiGEkAYuNTWVfbx582bMnTsXsbGx7DIXF5eaKJbNUWapjlCqtTh1Nwu5CjX+i8up6eIQQgipYnq9HooSTY386fV6q8ro7+/P/rm7u0MkErHP/fz8sGzZMjRp0gQymQzh4eHYv38/+9pmzZoBADp37gyRSIT+/fsDAC5evIgnn3wSPj4+cHd3R79+/XD58mWbX9/yoMxSHXEvo5B9LBFT11JCCKnvitVatJ17oEaOfWtBJJzsKxcifP/99/jmm2/w22+/oXPnzli5ciWGDRuGmzdvokWLFrhw4QIiIiJw+PBhtGvXDvb29gCAgoICjB49Gj/88AP0ej2++eYbDB06FHfv3oWrq6stTq/cKFiqIx5kFbGP5UpNDZaEEEIIKdvXX3+N6dOn45VXXgEALF26FMeOHcN3332Hn376Cb6+vgAAb29v+Pv7s6974oknePv5/fff4eHhgRMnTuCZZ56pvhPgqDPB0rBhwxAdHY2MjAx4enpi0KBBWLp0KQIDAwW3z8nJwbx583Dw4EEkJCTA19cXI0aMwMKFC+Hu7s5uJzRY1V9//cW+ubVFfrFa8DEhhJD6yVEqwa0FkTV27MqQy+VISUlBr169eMt79eqFq1evWnxteno6Zs+ejePHjyMjIwNarRYKhQIJCQmVKlNl1JlgacCAAfj0008REBCA5ORkfPzxx3jhhRcQFRUluH1KSgpSUlLw9ddfo23btoiPj8eECROQkpKCrVu38rZdtWoVBg8ezD738PCoylOpkEJONklOwRIhhNR7IpGo0lVhddHo0aORnZ2N77//Hk2bNoVMJkOPHj1QUlJSY2WqM+/C5MmT2cdNmzbFjBkzMGLECKjVakilpj3D2rdvj23btrHPw8LCsGjRIrzxxhvQaDSwsys9dQ8PD14KsDYqUJYGSBQsEUIIqc3c3NwQGBiIM2fOoF+/fuzyM2fOICIiAgDYNkpaLX9InDNnzuDnn3/G0KFDAQCJiYnIysqqppILq5O94XJycrBhwwb07NlTMFAyJz8/H25ubrxACQAmTpwIHx8fREREYOXKlWX2AlCpVJDL5by/qrL3eip6Lz2KU3dLPyhUDUcIIaS2++STT7B06VJs3rwZsbGxmDFjBqKjo/Hhhx8CAPz8/ODo6Ij9+/cjPT0d+fn5AIAWLVpg3bp1iImJwfnz5/H666/D0dGxJk+lbgVL06dPh7OzM7y9vZGQkICdO3da/dqsrCwsXLgQ48eP5y1fsGABtmzZgkOHDmHkyJF4//338cMPP1jc15IlS+Du7s7+BQUFVeh8rPH+hstIyi3G9eR8dpmihAamJIQQUrtNmjQJU6ZMwdSpU9GhQwfs378fu3btQosWLQAAdnZ2WL58OX777TcEBgZi+PDhAIAVK1YgNzcXXbp0wahRozBp0iT4+fnV5KlApLd2MIUqMGPGDCxdutTiNjExMWjdujUAJuDJyclBfHw8PvvsM7i7u2PPnj1lzigsl8vx5JNPwsvLC7t27bKYjZo7dy5WrVqFxMREs9uoVCqoVCre/oOCgtjMlS2FzPjXZNlTbRvh9ze72vQ4hBBCao5SqcTDhw/RrFkzODg41HRx6hVL11Yul8Pd3b3M+3eNtlmaOnUqxowZY3Gb0NBQ9rGPjw98fHzQsmVLtGnTBkFBQTh37hx69Ohh9vUFBQUYPHgwXF1dsWPHjjKr7bp164aFCxdCpVJBJpMJbiOTycyuszVXBzsUGA0VoNLoquXYhBBCCKnhYMnX15cdZ6G8dDomYOBmeIzJ5XJERkZCJpNh165dVkXr0dHR8PT0rLZgqCzO9qbBEs0PRwghhFSfOtEb7vz587h48SJ69+4NT09P3L9/H3PmzEFYWBibVUpOTsbAgQOxdu1aREREQC6X46mnnoJCocD69et5DbF9fX0hkUiwe/dupKeno3v37nBwcMChQ4ewePFifPzxxzV5ujxagVpSyiwRQggh1adOBEtOTk7Yvn075s2bh6KiIgQEBGDw4MGYPXs2mwFSq9WIjY2FQqEAAFy+fBnnz58HADRv3py3v4cPHyIkJARSqRQ//fQTJk+eDL1ej+bNm2PZsmUYN25c9Z6gBdwhAwwos0QIIYRUnzoRLHXo0AFHjx61uE1ISAivy3///v3LHAJg8ODBvMEoaxuVRgul2jSLRJklQgghpPrUqaEDGpoilXAGSUWZJUIIIaTaULBUi5WYySApKbNECCGEVBsKlmoxtVY4KKLMEiGEEFJ9KFiqxQxtk5zsJXi9WzAWDG8HgDJLhBBC6jaRSIR//vmnpothNQqWajFDNZyzzA6LnuuAYZ0CAQBand5s1okQQgipTmPGjIFIJDL5q80dqMqrTvSGa6hKHgVE9hImpnWQSth1Ko0OUgnFuoQQQmre4MGDsWrVKt6y2jK4sy3Q3bYWM2SW7O2Yt8leIoZhGjxFicbcywghhJBqJZPJ4O/vz/vz9PQEANy9exd9+/aFg4MD2rZti0OHDpm8PioqCuHh4XBwcEDXrl3xzz//QCQSITo6mt3mxo0bGDJkCFxcXNCoUSOMGjUKWVlZ1XJ+lFmqxdRGmSWxWARXmR3kSg3kxWr4udJki4QQUm/p9YBaUTPHljoBZUxSbw2dTofnn38ejRo1wvnz55Gfn4+PPvqIt41cLsezzz6LoUOHYuPGjYiPjzfZJi8vD0888QTeeecdfPvttyguLsb06dPx0ksvlTkOoy1QsFSLGWeWAMDDyR5ypQb5xaYjexNCCKlH1ApgcWDNHPvTFMDe2erN9+zZAxcXF/4uPv0UXbt2xe3bt3HgwAEEBjLnsnjxYgwZMoTdbuPGjRCJRPjjjz/Y7FNycjJvNo0ff/wRnTt3xuLFi9llK1euRFBQEO7cuYOWLVtW9EytQsFSLaYSCJbcHaUAQMESIYSQWmPAgAH45ZdfeMu8vLywbt06BAUFsYESAHZOV4PY2Fh07NiRN9l9REQEb5urV6/i2LFjJgEZANy/f5+CpYbM0MBbKilNhVKwRAghDYTUicnw1NSxy8HZ2dlkHlZbKiwsxLPPPoulS5earAsICKiy4xpQsFSLlVbDlfaCMwRLeQoKlgghpF4TicpVFVYbtWnTBomJiUhNTWWDmnPnzvG2adWqFdavXw+VSsX2oLt48SJvmy5dumDbtm0ICQmBnV31hy7UG64WK340Urc9Z4gAN8osEUIIqWVUKhXS0tJ4f1lZWRg0aBBatmyJ0aNH4+rVqzh16hRmzZrFe+1rr70GnU6H8ePHIyYmBgcOHMDXX38NgBm8EgAmTpyInJwcvPrqq7h48SLu37+PAwcO4K233oJWW/WzWlCwVEspSjSY888NAIBKU/pBoGo4Qgghtc3+/fsREBDA++vduzfEYjF27NiB4uJiRERE4J133sGiRYt4r3Vzc8Pu3bsRHR2N8PBwzJo1C3PnzgUAth1TYGAgzpw5A61Wi6eeegodOnTARx99BA8PD4jFVR/KUDVcLeVkX/rWpOYr2cceThQsEUIIqT1Wr16N1atXm13fsmVLnDp1irdMr9fznvfs2RNXr15ln2/YsAFSqRTBwcHsshYtWmD79u22KXQ5UbBUB6TmFbOPDZklOQVLhBBC6om1a9ciNDQUjRs3xtWrV9kxlBwdHWu6aAAoWKoTikqoGo4QQkj9lZaWhrlz5yItLQ0BAQF48cUXTarrahK1WarFZg5pDQD4dGhrdhkFS4QQQuqbadOmIS4uDkqlEg8fPsS3334LJ6fyDV9QlSizVIuN7xuKpzsGoLFHaRqShg4ghBBCqhdllmoxkUiEJp5ObNdJoDRYyihQ4W56QU0VjRBCCGkwKFiqY5p4OqK1vysAYNfVGhrZlRBCCGlAKFiqY0QiEV54rAkA4F5GYQ2XhhBCCKn/KFiqg1o0YjJLsWlUDUcIIYRUNQqW6qBOTdwhEYvwIKsIDzIpu0QIIYRUJQqW6iAPJ3s81tQTAHA5Ia9mC0MIIYRUkZCQEHz33Xc1XQwKluqqYC9m/ImEHAVSOCN8E0IIIdVpzJgxEIlE+OKLL3jL//nnH15v7rqMgqU6KsCdmVxw+ZG76PnFUaw9G1ezBSKEENJgOTg4YOnSpcjNza3polQJCpbqKP9HwZLBgZtpNVQSQgghDd2gQYPg7++PJUuWmN1m27ZtaNeuHWQyGUJCQvDNN9/w1mdkZODZZ5+Fo6MjmjVrhg0bNpjsIy8vD++88w58fX3h5uaGJ554gjcBb1WhEbzrqCae/GHgU/OUNVQSQgghVUGv16NYUzPNLBztHMtVhSaRSLB48WK89tprmDRpEpo0acJbf+nSJbz00kuYP38+Xn75ZURFReH999+Ht7c3xowZA4CpzktJScGxY8cglUoxadIkZGRk8Pbz4osvwtHREfv27YO7uzt+++03DBw4EHfu3IGXl1elz9scCpbqqO6hXnBzsINcqQEAxOcooNbqIJVQspAQQuqDYk0xum3sViPHPv/aeThJyzc323PPPYfw8HDMmzcPK1as4K1btmwZBg4ciDlz5gAAWrZsiVu3buGrr77CmDFjcOfOHezbtw8XLlzA448/DgBYsWIF2rRpw+7j9OnTuHDhAjIyMiCTyQAAX3/9Nf755x9s3boV48ePr8wpW0R31jpKZifBxnHd8UlkKwCAVqen7BIhhJAatXTpUqxZswYxMTG85TExMejVqxdvWa9evXD37l1otVrExMTAzs4Ojz32GLu+devW8PDwYJ9fvXoVhYWF8Pb2houLC/v38OFD3L9/v0rPizJLdVj7xu5o39gd2y8n4X5mERJzFQj2rj2zNBNCCKk4RztHnH/tfI0duyL69u2LyMhIzJw5k61es5XCwkIEBATg+PHjJuu4QVVVoGCpHmji6cQESzmKmi4KIYQQGxGJROWuCqsNvvjiC4SHh6NVq1bssjZt2uDMmTO87c6cOYOWLVtCIpGgdevW0Gg0uHTpElsNFxsbi7y8PHb7Ll26IC0tDXZ2dggJCamOU2FRNVw9EOTF/AJIyqXxlgghhNSsDh064PXXX8fy5cvZZVOnTsWRI0ewcOFC3LlzB2vWrMGPP/6Ijz/+GADQqlUrDB48GO+++y7Onz+PS5cu4Z133oGjY2mGa9CgQejRowdGjBiBgwcPIi4uDlFRUZg1axb++++/Kj0nCpbqAUPPuMRcyiwRQgipeQsWLIBOp2Ofd+nSBVu2bMGmTZvQvn17zJ07FwsWLOBV1a1atQqBgYHo168fnn/+eYwfPx5+fn7sepFIhL1796Jv375466230LJlS7zyyiuIj49Ho0aNqvR8RHq9Xl+lR2gA5HI53N3dkZ+fDzc3t2o//r/XUjFx42V0CfbA9vd7Wdz2YVYRdkWnYGAbP7Rv7F5NJSSEEGKJUqnEw4cP0axZMzg4OJT9AmI1S9fW2vs3ZZbqgSaeTJoyIafsargP/rqMbw/fwZhVF1Gk0lR10QghhJA6j4KleiDMzwViEZBVqEJyXjFO3MlEnqLEZLsTdzJxI1kOgNn23IPs6i4qIYQQUudQsFQPuMjs2Cq1yG9PYvTKC3j2x9MmmaPVZx7ynsekyqutjIQQQkhdRcFSPfF0hwAAQOGjACkxpxjbLyex6/V6PaIT83jbxqQWVG8hCSGEkDqozgRLw4YNQ3BwMBwcHBAQEIBRo0YhJSXF4mv69+8PkUjE+5swYQJvm4SEBDz99NNwcnKCn58fPvnkE2g0da8tz6geTeEi4w+btf1KMvs4Nr0AuQo17O3EeL5LYwCUWSKEkNqG+lzZni2uaZ0JlgYMGIAtW7YgNjYW27Ztw/379/HCCy+U+bpx48YhNTWV/fvyyy/ZdVqtFk8//TRKSkoQFRWFNWvWYPXq1Zg7d25VnkqVcLK3w+q3HseUJ1vi1LQBEIuAKwl57ECV+66nAQD6tvBFxyYeAICH2UVQlNS9wJAQQuobqVQKAFAoaAgYWzNcU8M1rog6M4L35MmT2cdNmzbFjBkzMGLECKjVaosXwMnJCf7+/oLrDh48iFu3buHw4cNo1KgRwsPDsXDhQkyfPh3z58+Hvb294OtUKhVUKhX7XC6vHRmariFe6BrCzLrcPdQbUfez8dvJ+1g4vD32Xk8FAAxp7w9fVxl8XWXILFDhdloBugR71mSxCSGkwZNIJPDw8EBGRgYA5t4lEolquFR1m16vh0KhQEZGBjw8PCCRSCq8rzoTLHHl5ORgw4YN6NmzZ5mR4oYNG7B+/Xr4+/vj2WefxZw5c+DkxAziePbsWXTo0IE3mFVkZCTee+893Lx5E507dxbc55IlS/DZZ5/Z7oSqwPv9myPqfjbWn0vA/htpyCosgcxOjEFtmHNtE+CGzIJMxKTKBYMlRYkG2YUlCPKqe0PtE0JIXWT4YW8ImIhteHh4mE2aWKtOBUvTp0/Hjz/+CIVCge7du2PPnj0Wt3/ttdfQtGlTBAYG4tq1a5g+fTpiY2Oxfft2AEBaWprJqJ+G52lpaWb3O3PmTEyZMoV9LpfLERQUVNHTqhK9W/hgQr8w/HriPrIKmWEEZgxpDXcnJrhsF+iGk3cyse1SEl7uGgQ7SWmN7LWkPIxfewnpBUp893I4hoc3rpFzIISQhkQkEiEgIAB+fn5Qq9U1XZx6QSqVViqjZFCjI3jPmDEDS5cutbhNTEwMWrduDQDIyspCTk4O4uPj8dlnn8Hd3R179uyxOlV59OhRDBw4EPfu3UNYWBjGjx+P+Ph4HDhwgN1GoVDA2dkZe/fuxZAhQ6zab02P4G3Jxbgc3E0vRJ8WPrws0cOsIkR+dxIlGmY4+qEd/PHhwJYoVGkwZuUFFDzqVefjYo+T0wbAyb5OxdWEEEJImay9f9foHXDq1Km8eWGEhIaGso99fHzg4+ODli1bok2bNggKCsK5c+fQo0cPq47XrVs3AGCDJX9/f1y4cIG3TXp6OgBUOmVXWzwe4oXHH7Vj4mrm44xpka3w+b8xAIC919Ow93ppNq2JpyMUJVpkFZZgTVQ83usfVm1lJoQQQmqTGg2WfH194evrW6HXGibo4za0Lkt0dDQAICCAGWeoR48eWLRoETIyMtjJ+g4dOgQ3Nze0bdu2QuWqS97pE4rXugXjtxMP8P2Ru+zyyHaNsOT5jjgem4EpW67i5+P3UKTSIMDDAUPbB8DTWbjhOyGEEFIf1YmJdM+fP4+LFy+id+/e8PT0xP379zFnzhykp6fj5s2bkMlkSE5OxsCBA7F27VpERETg/v372LhxI4YOHQpvb29cu3YNkydPRpMmTXDixAkAzNAB4eHhCAwMxJdffom0tDSMGjUK77zzDhYvXmx1+WpzNZy1SjQ6XIzLgZO9BJ0fNfjW6vR4/pcoXH00mKVBnxY+GNMzBLfTClCo0qBnmDf6tKhY0EsIIYTUFGvv33UiWLp+/To+/PBDXL16FUVFRQgICMDgwYMxe/ZsNG7MND6Oi4tDs2bNcOzYMfTv3x+JiYl44403cOPGDRQVFSEoKAjPPfccZs+ezbsg8fHxeO+993D8+HE4Oztj9OjR+OKLL2BnZ33SrT4ES+bkFJXgnTUXcTkhz+J2g9r44dOhbRDq61I9BSOEEEIqqV4FS7VdfQ6WAGasCpVGh+ISLb48cBubLibCxd4OBSoNPJykyFMwvTZEIuCNbk3xvyeao5GbQw2XmhBCCLGMgqVqVN+DpbKcvZ+NH4/dxZl72QCYoKlnmDcWP9cBTb2dAQA3U/Kx51oqxvQMoUCKEEJIrUDBUjVq6MESwGSfdl9LxbqzcbgYlwsAEIuATyJbQyQCvth3GwDT3mnd2G41WVRCCCEEAAVL1YqCJb6bKfn4bNctXIjLEVwf98XT1VwiQgghxJS19+86M5EuqTvaBbpj87vdMWtoGzjZm46cmpxXXAOlIoQQQiqGMks2QJkl8wqUahSrtfBzdcBLv57FhbgcuDnYYepTrdCnhQ8c7SVIy1ciyMsJPi6ymi4uIYSQBoSq4aoRBUvWuZmSj/9tvIKHWUUm6xq5ybB+bDc093OhmbYJIYRUC6qGI7VOu0B3HJnSD2N6hpisS5er8OS3J9Fs5l78dSGh+gtHCCGEmEGZJRugzFL5KdVa2EvEuJdZiOTcYry1+iJv/Y3PIuEio8l7CSGEVB3KLJFazUEqgVgsQstGrhjQ2g+dgz14699ZcxEPMguh0+kxZXM0eiw5gj9OPsDBm2nCOySEEEKqCGWWbIAyS5WXU1SCzAIVClVqvPL7Oai1zMeymY+zSRun9WO7oXcLn5ooJiGEkHqEMkukTvFytkcrf1c81tQLn49ozy4XagzOHb9JUaLB1wdicTtNXi3lJIQQ0vBQsERqnZcfD8a9RUMw/9m26N/K12T98iN3oVRrAQDbLyfjx2P3MPi7U4hOzKuyMmXIldh6KQkqjbbKjkEIIaR2omo4G6BquOrx+8n7WLyXmTbFQSqGUq3jrX++S2Mseym8So7de+lRJOUWY+KAMHwS2bpKjkEIIaR6UTUcqXfG9QnF8PBAADAJlAAmy6TV6XErRY6ejxqEFyjVNjl2Ui4z6vjBm+k22R8hhJC6g4IlUmeIRCJ8/0pn7P5fbzzdMUBwm40XErAmKg4p+Uos2huDQctOQKM1DawqitKwhBDS8FCwROqcDk3c8dNrXXDh04Ho0Ngdge4O7LqN5xMg52ST0uUq3Eq1XeNvqrUmhJCGh4IlUmf5uTlg9we9ETVzIKYPZtoRxaTKse8GfyymE7GZWH7kLs4/yEZ2oUpwX2n5SoxacR47o5MtHpNCJUIIaXhoiGRSL7zTpxl2XEnCnfRCk3XfHLrDez776TYQiUQ4fTcTv7zxGPIUanRfcgQAcOpuFhQlWrwaEVwt5SaEEFL7UWaJ1AtSiRibxveAt7M9AODZToE48FFfwW0//zcGC/fcwrHYTOy6moJNF/lz0c3cfh1ZZjJQlFoihJCGhzJLpN7wcrbHpTlPIiWvGN4u9pDZSbD81c6Y9NcVs68pUmmg05lGQNmFJfBxkQEAbiTns8t11GaJEEIaHMoskXon0MMRMjsJAGBYp0D88noXDA8PhNejrBPXZ7tvoajEdKDJ/OLSRuKv/3mefUyhEiGENDyUWSL13pAOARjSIQA6nR4rzzzE5//G8NavOP3Q5DV5ihL2MTdwosQSIYQ0PJRZIg2GWCzCO31CEffF05j3bFvBbdo3ZkZwzXsUIKmtGKPpWlIe9lxLsV1BCSGE1CoULJEG6a1ezfDlyI68ZXFfPI3mvi4AgHwFEyxtusBv/J2cV4yfj99DQraCXTbsxzP438YruJaUBwDILlTho01XcOpuZhWeQf1VqNIgp6ik7A0JIaSaULBEGqyXHg9CeJAHAODFx5oAADycmHZNZx9kAwBuJPMHtNTq9Phyfyz6fnUMGXIlL6MUm1YAvV6PJ789iX+iUzBqxQV8fSCWBrIsp1d/P4cBXx8XHBOrQKnGmFUX8JdREGutWylyDP/pDAWyhJByoWCJNGi/v/kYpg9ujfnD2gEAnmrXCABw9HYGPvn7Kjb/lwgAGN2jKZp6O/FeG7H4CP63sbSn3a6rKTh4K52XFfnx2D00m7mXzTrtvZ6KPl8exbkH2fjx6F3cTrNudHG9Xt8ggq7cohJcT85HfrEax2NNA5ofjt7D8dhMzNx+vUL7f3v1RVxNzMOYVRcrW1RCSANCwVIdklSQhOiM6JouRr3i5+qA9/qHwVnG9HXoGeaDkV2YLNPfl5LY7Z7r0gRD2gvPR2dw6m4Wtl9OElxn6FH3/obLSMwpxiu/n8PXB+9g8HenAAAn7mRi0b+3kFtUYlIFpdHq8NzPUXhz5QXo9XrIlWr8cfIBUvKKK3bStdj9zNJBRe+kF5isvxSfW6n9p8mVAJgMISGEWIt6w9UhQ7YPAQDseW4Pmro1reHS1F9Lnu+ApFwFzj/MAQBEtmuEDo3d8TDLdHTwnmHeyC9W42YKkyE6cDNdcJ8FSg2iE/ME1yVkKzB65QUAwB+nmJ55V+Y8CaVGC3dHKRJyFOxr84vV+GLfbWy6mIiNFxJw7OP+JvvLKlRhzj838MJjTTCwTaMyzzcxRwGRCGji6VTmtuZkFCiRU1SC1v5uFd4HADzIKmIfC7VbslWAKBLZZDd1UkaBEvJiNZr7udZ0UQipMyhYqiM0Og37+GH+QwqWqpC9nRjr3+mG5NxiNPV2gujRnTWynT9GdsnGgNa+CPVxgVKjRZdgTwDAK7+fxbkHORb3e/Gh8PrJW6JNlnVeeAgA0K+lL0b3LH2vU/OVOByTAQB4yAksdDo9xGIRUvKK0fOLowCAfTfSEPfF0yb7LlCqYScWw9FeAqVaiz5fHgMA3F00BFJJxZLNEYuY6WJOfjIAwd7WB10qjRbHbmegR5gP3B2lkHOGaShWm45/xR0UVK/Xs++NNWpbNebqMw/x+8kH2DCuO5r5OFfbcQ3vVdSMJxDo4VhtxyWkLqNquDoiqziLfexoR19wVU0qESPEx5l3M3ayt8M3L3XCMx0D0TbQjQ2UACDYix8gdAn2wK0FkVj+amdENPMCAFx91G7JmKWqpRN3MhGbVprRSs0vhqN96X/bB5mFuJ6Uj46fHcTkzdFsoGROkUqDvl8ew6BlJ5CSV8zL3uQqSrDlYiJm/3NdcFRzANh8MQEv/XoWuZzXcYOQK4n8c1l3Lh5rz8aZLc83B+9gwvrLmLw5GgCTgTNQqi0P2/DpjvK1W1JwBh/V66sueNLq9Ji+9Rq+O3wHZ+9nm91u/u5bSMlXYu7OG1VSjrJc54xMT6qeUq3FhYc50FgxHAmpfShYqiPSFaXVOyqtmXnLSI0ZEd4YjT0c0dzPBfs/6oPt7/eCk70dhnUKxNjezQAAe66lstt7C4wmbs4PR++yjx9kFiExp7Qq6sv9sZj9z3UUqjTYcSXZ5LVqrQ5KTobmYVYRchVqJOcVY9JfV6AoKQ1OjsdmYtq2a1h/LgHHYjMEyzJ923VciMvBd4dLJyeWF5fug5uZyikqwZx/bmDuzpu8gT0NNFodfj/5AADToB5ghg0wUApklrjxzV8XEgXLaA43EDMuty0dupWGzf8l4rvDd/HqH+dwMc5yxjEuu8jielviBsG1LdNW332y9Rpe+u0slh+9V9NFIRVAwVIdkaEovXkVa+pfw966rmdzH5yZ8QQOT+ln0m6nR5g3pJLSDFULPxf8N3sQb5vnOzc2u29uRsR49PH8YrVgdRUAuMjs8MQ3xzHipzNsg+ZMTnf8/+Jz2SAFAKZtvcbbr7GMAiX7ODG39DO4/nw8+5gb4ExYf4l9/OuJ+yb7M/Q05CrkBDRC51VSiV/lBUr+OSXmKsxsWTl5Cv5xou6Zzy4BQGJOMZbsjTG7XqPVIbPANj+QlJrSa1pWG/eHWUVW99a0VlxWEXZGJ5vNXNZnu68yw4z8eepBDZeEVAQFS3VEYUlpVYxSo7SwJalt3BykeK9fGPs8o0AFkUiEzsEe7LJZT7eBh5PU7D5ejQhmRxfn0kNv9qZXqNIgMacYt9MKcDUpD7dS5Lhr1MNs8d7bgq81bgokV6rxBmeOvEIlM3BkblEJvjoQyy7PL1YjQ65EgVKNC5w2Wr8cv2/SA+1hpmlGhZtZKhaYs0+hEg4MrVGg4meSkmwQLAldU4mYf/G0urIDvN9Omr+BvrX6Ih5fdNgmgQv3mlrqEajX6zHg6+MY/N0pwcC5ovp/fRwfborG3hupZW9soWx1LSt2K6X0vatou0ADa2YVILZHwVIdodSWBkiUWap7pjzVCo3cZACANgFML6R1Y7vh30m98XDJUHi7yLBgeHsAQHiQB+4uGsIOYQAALzzWBIMEerZlFKis+pU+eXM0hi4/ZTY4Mt3+KntDmrvzBjrOP4g76aUBe1aRCo8vOsw2RDeITStAxOIj6GK0HAAScvjBidSu9Oun8aOGxrxqOA0/MCrR6Mxmlko0Ony64zo+2nTF7PUwrobjVmdWRKFKg6HLT+HJb0+iRGP+Bqat5I391F2mveLmi+WrdhTCzdaZy0gCgIpzPpkFtv9xdiUhr0KvU2t1GLr8NN5YURq4ZxQokS6v3T8gJ268zD6uTLB07kE22s87YLEdIKkaFCzVESXa0ga1lFmqm7a/3wuvPB6EL55npllxkdmhXaA724j82Y4BODi5L7a82wNSiZgNqgCmwfio7k3RvrEbPhrUAoen9APAtGHidrc3Jz6bH6i82y+0zNfcyyjENwdjsfZsvMm6B5lFgpkJQ9WaWmu6bsDXx7Fkbwz7upzC0s+04dcyL1gyyixx21cZ2xmdjI3nE/BPdIrZ63HDqEGzNdVwSrUWs3Zcx5EY0yEh0vJL/x9yA0HjIKQyiQBuBsXJXlKhfeh0evb6cqtJi1Sm17O4RItxa//DOoH33FoZciWSHw3xkJxXjKh7TLBX1rnM23kD07ZetZg1upUiR0yqHGfuZUNRooFaq0PEoiPotviIYBu3suRW07Q6WZxqVHtJxcet+HDTFag0OszdedMWxSLlQMFSHcENkIq1lFmqixp7OOKLkR0RYqabuEgkQstGrrB/lHF5o3tTjO3dDFve7QGRSARvFxn2fNAHHw1qiWY+zmjtX7Fxch4P8cSEvmFldld/8tuT+MHKxqgzh7QGwG+ADQDORjfF304+wJxHvb9yFKU3KkOQZKnNUqHRzZ2773sZpVkvc9VV3Ab2ABPg6PV6TNkcjVd+P2tS7bczOhmt5+zHhvMJGLvmP5P9cadj4Q6mWaQyDpb40ZKlTKBKo8UX+26zVZjcqkMn+9KRXnSPety9+vs5qDTmgwS9Xo/nf4nCk8tOoESjQ3FJaVkUAtWca8/G4dCtdCzitKESCvZ2X01BTKrpddbp9IhYfAS9vjiKAqUavb44itf+PI9L8bmQK4XPBWACtzVn47HlvySky823z8rgBB3ZhSW8jFKuonyBz8/H76HzwkP4+O+rWLI3psxgS65UY9G/t0yCbms4cj6rdkaZJcPnoUilwaYLCcgSmObHoKweojVBq9Pjv7gcwWrz+oSCpTqC2wOOquEaBgepBHOeacsOPcAlEYuw+d0eaObjDBeZHdaNjcCVOU9iy7s9cHhKP5OpWQBgYGs/bBrfHRve6Q5PZ3sEuDvYpJwSsQjPdgoUXPdsp0BcnfcUb9nG8wn489QDHLpVmq1RlGih0ep4NzzjG4NxNVpRiRZR95msRRJnsMr/bbzCds/mZikMwY0hq5aYo8DNFDm2X0nGuQc5+PLAbd72xhm12DR+26RMs8ESv5zc87iSkItOCw5i9ZmHELLubDx+PXEfL/12FgDT1svAkJHT6fR4a/VFbP4vEWcfZONakvDNW1GiwdS/ryI6MQ9x2Qok5Sp4AahxOVUaLZbsM62mNa5ivBiXgw/+uoIh358yyQJxq07P3Csd7uRKQi6vkbrO6HXcdlEaC228uBm8zEIVdkaXzs1YqCxf78Yv9zNt7bZeSsJvJx9g6yXh0fcNvtofiz9OPcQzP5wu13EAsDMEAOB19th0IQEdPzuICw9zsGhvDGZsv463LEzFUxvbK62OisMLv57Fexsulb1xHUbBUh3BDZaoGo4AgLujFMc+7o8bn0WiTwtfeDrbI6KZF5r7ueCrFzrh+S6N0TbADRve6YYzM57Az290QfdQbzZzZRx8AMCqMY+XuxxBno4I9HBEN4Ggzt1JCndHKZ5o7cdbbtyrD2CyBtmcapFitZZ3MzZkj0I5GbHX/jiPQpUGSbn8HxD5xWpcis9Fx/kH8dOxe+wyAOjbwhcAkJRbjC2cHnmrzsThn+jS4ReMfylHfncS+ZyebtyqlfsZTNVfbFoBfjzGz8atOxcP5aNzee7nKBQoNZi/+5bJ+ev1el7QdStFzguWDJm13ddScOJO6bx5DzivuZ6Uj5AZ/2LUivP49cQDbL9cej5KtY4XLBlnloyDQQPjzBV3u5hU/mu412zC+tJ2OjI7MfZzGnUbB2rcHoSWMjwJnGEWsgv5nQvk5QyWjJVVJXf+oeVejZY4SEszS9w2SzO2M8N+fLTpCv59lPm0NP6VRqB62xZupcix4vTDCk0DZGg/JTSXY31CI3jXcnH5cdh+bztSi0q/aCizRMoS0cxLMCPF9b8nmuPddZfQv5UvriTkoYmnI/q38sWdz4eg5ex97HavdwuGSqPD1ktJeL1bMDacT2DXNfF0xPJXOwMAWvu7slPEGHg6MeNJffdKOOKyivD6n+d5Qdr6sd3wxf4Y3EiWY8+1FJMva3mxBgk5Cjz7Y+mv+S5NPXntkiasu4SrRlPJ5Berse1yEgpUGnx1IBYlGh3baLmVvytEIqYRsyF7FOrjjAdZRdh9NRX3Mgrx0zHToQ4AYO+NVLwaEQwAvOlrtl1OQp8WPmYb3j7ILMLdDOFgxKBYrYWY0w0xNp1fzWW4btyeVQC/CtJwnU7dzTIJhgqUal4wY9zLzdy4U3uupaJrSOlniVv1dfR2OtoGlvbSFKraA5iqJ+64WMbbcctiqCpUabSIup+Nbs282Gq7eE5mKc6obZrx0BBcWYUqqLU6BLibH9DX1cH0dphVqIJWp0cjNwfBdnjGYlLlCPRwhLujFFqdHrP/uY4uwZ5wkZUGS7fTCqDV6Xm9JtU6PS/jZI7aip6VFTF0OTNHpVQiwps9Qsr1WuPen/VVncksDRs2DMHBwXBwcEBAQABGjRqFlJQUs9vHxcVBJBIJ/v3999/sdkLrN23aVB2nZJX3Dr+HVTdW4VB8ae8ibmNvQioqsp0/9nzQG7++8RhOThvAto2ytxNj8/ju7HZ5xWp8NqwdfnqtC+Y92w7c78bT059AxyYeAIDXujVls1YG9o9+Rbs5SNGxiQevR5+7oxS9mnujd3Mm07PvRhoAZsBOw4joF+JyeIESwFQncp3mVPcYXEvKx0ZOUPf9EWZgT7EI8HKyh6+LjF0X4O6AKU+1BMAMjmkuUAKAmduvI2LRYXxzMJYtr8FHm6ORqxC+YecUlWDf9TTBdQaFKg3vxjN581XeekM2xs7oppryqKG5cQbIeGR4uVLDy9pw28ZceJjD62HGtToqDnN33kDEosM4dTeTVxV25l42fj95H6vPPIRerzebFYpNK2AbfXPPxSBfYJqbbw7ewVurLuK1P87jz1MPoFRreR0Vbhm1mTKXWdLp9Oj6+WH0WHKUzc4JjaJdZBTAGV7XbfER/HUhgVcFJtQ4/lJ8DoZ8fwojfjoDADh4Mw1/XUjEJ1uv8YJggLmmxsrqJZdVqOK1CdTqmOu9+sxDxBsNbHovoxAZFeghePou///S/cxCi6PQA4CEc277rld8SIjars4ESwMGDMCWLVsQGxuLbdu24f79+3jhhRfMbh8UFITU1FTe32effQYXFxcMGTKEt+2qVat4240YMaKKz8Z6SYWm9ejceeIIqYz2jd3hIJXA3VHKa1fRLdQbz3QMAAC83asZnGV2eLpjAOztxBj2qH2Sr6uMt69W/q44NLkvzs58gl1m3NX/zR7MPHcyOzG+eqEjRCIROjR2B1DandzHRcZmxcatLW1YHerjjKNT+2FIhwDBc+EO7PnRo+lTjLk5SiEWi8DNEcx6ug06c6auKUtGgQo/HL3H615vkGVm8MjsIhX0sJyZKFRqLP5KzypUIaeoBHfT+RM6/3stFV/su13miOTj1v7Huy7JecXsmEWGNlLmrD0bj4wCFUatuMALWM4+yMbivbcxf/ctjFt7yexwBMY387MP+Ddg7ij1ihINb3T36MQ8fP5vDCb9dYU3H+Jto2pDc5klbkcCQzbqz9OmbcaMq6W5r5u5/TqvqnfkL1Em7bV2X2UChYdZRdDp9HhvQ2k1pPF12XDetLchNwg+ece0SuuM0Y+Ca0l5+OX4fczffQv9vjrOLj92OwODlp3AwG9OQG4h2yYkzyjbOPCbE3j1j3O4ZyEryv3Mcs+5LHfTC/D7yfv4kfPe12Z1phpu8uTJ7OOmTZtixowZGDFiBNRqNaRS08H8JBIJ/P39ect27NiBl156CS4uLrzlHh4eJtvWZhQskerw7cvh+HRoG5PJVhc/3wGBHo54TmDU8abe/B527QPdec87B3uaTO7LHSLB8LxNgOkAnLs+6A2XRwFd7+Y+vIzSO72bYdbTbXA3o9Bimw93R+a7YlAbP/x1IRFPdwzAMx2Z4G/92G5msyvmONlLMOvpNpi1g+nhZ+i99vWLnfDz8Xt48GjgzezCsrPBF+NyTHoTckXdzxYcvwpgRkj3cjY/qKmQB5lFeHv1RXz5QqdyvS4xR3jIhcMx6XinTzPh1xi1KUvKLUZ8dhH7ebnJqVq8k17Ae25w8BZ/+Abj3niGYIdp+1WEZj7OkIhF7HsAAPtupCJPocYXAg3ZC1X8QCHDQq+822kFyCxQwc+ttJMEt2G6cfmNx4HKN8pAisDPLL258gIeLB4KMScQMR7FfWd0Cm++yTVRcRgeHoi3VjMNxAtUGtzLKOTNYVkW7kTW3F6bt1IL0NxPuPetcaZTpdEip6gEAe6OOHU3E55O9mjf2B3XkvKQU1SC/q38cPpuFu//2qC2jUxmPqht6kxmiSsnJwcbNmxAz549BQMlIZcuXUJ0dDTGjh1rsm7ixInw8fFBREQEVq5cWebosCqVCnK5nPdXVYQmzdXoKVgiVU8qEQvOSu9kb4dpg1ujRSPzQxccmtwXP7zaGb2ae5d5HOMAa0Tnxmjhx/9Bs2J0VzZQAoDVb/Ebos8Y0hoikajMyWEN1W8zBrfB6rcex/cvh7PrerfwQdwXT2PLuz3w2bB27PL1Y7uZ3Z9Gq8fLXYNMlrdq5IqjU/uzAeWCPbcEG8++0T2YfTx3503exMblZe2Ao1zHYjNNRiAvS7aFMgpVTwGl7aocpKW3nJspcuj1epOM0OK9t3kNt401N/psGBiCifXn4jFo2Ql8/2j+Qm7W7Kdj980GxDlFJfjz1AOsP8dkfTLKGIwzJZ+/Xq0pfX+NB1Q1Hg4hu6iENwSBHqVV1gZpnACrSKVhO0XYPQqgVkfF8fYxb9dN/HqCPxK8cWArV6ox8JvjiFh0GPN33TQZpoCbXeNWjW69lISDN0urkQ/eTMPWS0nQ6vSwE/PL/crv59BjyVEs+vcWRq24gFf/OIfiEi2G/XgGY1ZdRFKuAn9dSOC9htvuDmAC4UX/3jIJKmtSnQqWpk+fDmdnZ3h7eyMhIQE7d+60+rUrVqxAmzZt0LNnT97yBQsWYMuWLTh06BBGjhyJ999/Hz/88IPFfS1ZsgTu7u7sX1CQ6ZelrbhKTW9IlFkitV2LRq54tlMgO+CmJcZVT/1b+T2qHmS+nt7tF2rSm447Vo2jVMI+F8pIcTV6lAlwd5Kifys/kzFvAKZx/JD2pZnmXs1LqySNlWh1gvvwfJTladGo9MZ+VaCL/4R+YTj+cX8ATIPzXVf57TB9XWW89mO20pgTBK80Gsagiaf5RtAGoT7O7Ij0XIabr5tAY2kAGNo+gJ3W5+uDsQhfcIjtBWatx0P4mZJXI5jvX8P4WnMeDdi4/Og9hMz41+r97r2ehs//jcHsf26gUKXhjekkZMRPZ9jG9lqdnjfX4WGjLJiQHzljmClLtCbVitwJlrdfLm2O0bFJabbWuNG58RyMu6L5n6e//0vC/cwiZBSosDoqDlO3XOVV1XEDem4nipN3MjF+3SUoSjQoUmkwYf0lfPz3Vaw/F2/y/9dQnf7HKeZzVaDUYC+nLVN2YQnvhw8A3EjmJxyGfH8Kf5x6iKUHyv8DoKrUaLA0Y8YMs42wDX+3b5derE8++QRXrlzBwYMHIZFI8Oabb1o1R1BxcTE2btwomFWaM2cOevXqhc6dO2P69OmYNm0avvrqK4v7mzlzJvLz89m/xMTKT0NgjlRimjlT62pPtE2ILSwc0R7O9hL8M7EXAMDL2R5HpvZH9NwnMXNIG8Gga8M73dCykQvWjY1gl333cjg7hMHQDv749mV+FdOYXiFWlcfPzQH7PuyDI1P7QSQSYcnzHfD5iPZWn4/PowzWaxGlmSOhyXB9XGQI8XHGu335I6oPauOH/2YPwv4P+6BNoHAA+ONrnRHqa3lgUQD4cGALfDiwBfvcRWaHg5P7ssHo4ZgM3vbTBrcuc58TBzQ3abQMANO3XQcAhJup+vFytseYniEAmGrA/GI1Zmy/XubxuFoZZTQHt2cC2ZjUArOZrfJKzFGYvF/rxkbgpa5NeMtmbr+GL/ffxj9XknnLzc3190lkKywczmQt93MyNdzBRw1tAbnts7i9B5t4mo6hZs6R2xm8ORCNexBGJ+Zh7OrScZ0M419tvZSEkb9Emezvp2P3kJJXzM5H+TCryKrecNzOEHqAV70IAJsuJiAxRwGVRssbPkNo4NOaUqNtlqZOnYoxY8ZY3CY0tPRLxMfHBz4+PmjZsiXatGmDoKAgnDt3Dj169LC4j61bt0KhUODNN98ss0zdunXDwoULoVKpIJOZ/nICAJlMZnadrUlEptMCUGaJ1DejujfFqO5NecsaC1QBcvVq7oODk/vxlrXyd8Xmd3sgT1ECR3sJZHYSDGrTCEUqLbR6fZn75OJmqVwdpHije1P0au6D/TfSEOLthPc2XGaDkI+faomvD95htzeMq+PhZI8R4YH459Ev/AB3Bxz/pD9+OnoPTjI7druZQ9vAw8keS/ffhkgEfBzZig24hH4QfvNiJwxtH8D2Lvz7UhLm/HODXS8Ri9gsgZO9BO/2C2N7BAa4O8BZZofmfi4mv+gBoI0/M4q8pfnuerfwwXdH7phd7ySVYMf7PbHragpWnYljlwd7O7HnZY3ZT7fBY0098dzPpTfupkYjz3dr5gWxiKlGK2+bM4PuoV4496B02It5O2+iNact3ROt/dCnhS8ea+qJdLmKHefqalI+riblw5re864OdpjQLwwSsQjbLifzhp7gGtzOH+vOxeNmihyJOQrcSS/gDeAa5itcDcm19u0ILN1/GzdT5Fh5Og4HbqYh2MuJl60CmEbxF+NKe02qNDr8F5eDj/++arxLAExmijtYa7pciTL6LQBg2rMZKEo0JtVweQo1+nx5DI5SCa8xvLN97WlWXaMl8fX1ha+vb4Veq3vUmE6lspwqBZgquGHDhll1rOjoaHh6elZbMFQWoSwSBUuEWObxaHwngAl0XB3K1/jZnGY+znivfxgAIHruk2yD8f890QLpchXWnYvHY035WZU3ujfF3htpkIpFWPRce8jsJJjyVCuTfb/XPwyvPB4EnV4Pb05AIRKJ0DbAjddV/vkujSESieAgZoKtJ9s0wtcHYpFfrIarzA4bxnXDsB+ZLuyG4RxcHexQoNSwDdp9zQQtwd5OeC0imNe9fVAbP/QI88HCPbcwsksTNHJzwOLnOmDUiguC+3CQitE52BOdgz0xcUBzDPzmBEQiYFinQMHBUAGmh6RKo0NjD0e82y8UMakFGNMzxCRz4cqpwmnZyAUOUgma+TjjfmaRVRP09m7ug+WvdsbhmHRM23oNALByzOPQ6vToMP8gAGbICi9n5jMU6uOMb15kMpRO9nZY83YE/rqQgJmcjJgh0zK0gz/2mhkiomtTT/Zcuod6CwZLU59siWa+zlh3Lh7XkvLwwq9RJu2d3uzRFJ2C3DHGzEjfv416DH1b+uLU3UwmWHpUzcodusG43AZFKg1etNAz0rhqMl2uhKacA1meMhqegMu416BOr8eQ708hJlWO30c9hqfa1VxHrNoTtllw/vx5XLx4Eb1794anpyfu37+POXPmICwsjM0qJScnY+DAgVi7di0iIkrT8vfu3cPJkyexd+9ek/3u3r0b6enp6N69OxwcHHDo0CEsXrwYH3/8cbWdW1m4I3cbULBESM3jBmQAMPuZNmjRyAWD2/O/0LuGeOH09AGQ2UnY4MocT2d7weV/ju6Knl8cZZ8bV0v6uzvg6NR+yCosQatHcwZ+/0o4DtxMw0uPGqBve68njsdm4K1eTI81bnWOs70Em9/tATuJCDI7CWYMaY3/4nNwI1mOT4e2xvi+YdDp9BjQypedU7BPC1+c+KQ/r9s6wARlw8NLe0r6uMhw4KO+7DVzd5TCz1VmcuM9NW0A9t1Iw3NdGsPNKLjt08KHvcm2C3RHy0YuSJersPLRiPPtAt1xn9PrzdXBDns+6I0Fu2/hyO0MvNYtGGn5Shy9nYFXIoLg5WyPJpwso4OdBGKxCKvfepwNQpLymOqrTyJbmbwvTb1Mq8Ls7cRY9lI4RKKrgu2wIpp5cx574tcTzOPW/q5seyVnmR1aPqpmFMr6rRsbAU9ne7M9x2R2YnYcMnMZPCd7Cdo9qtrlZpUAmAQ+vq4yfDSoBf66kCBYnoQchcn/g7IcNar2HdMzRHDcKYDpAWowft0lk5601alOBEtOTk7Yvn075s2bh6KiIgQEBGDw4MGYPXs2mwFSq9WIjY2FQsFv/b9y5Uo0adIETz31lMl+pVIpfvrpJ0yePBl6vR7NmzfHsmXLMG7cuGo5L2sITW1CbZYIqX1kdhKzox/7uVZuHr5AD0fMGNIaX+y7jXd6C3fP93aR8TJSw8Mb84KWlo1c2RsxAN5EykUlWrRvXNpw2EEqwZ4P+iBdrmQbxYvFIoQaVQE19XbGwNZ+OHKbuQE+3SEAP73exaRs/px5CEUiEWY93QYfbopml4X6OsPPzQGjH7VnMjbnmbYY/uMZvN07BI72EpPq14Ft/HiN48/NHAhnmR1WjHkcaflK+LjYQ6vX43pSPtuVnhssGtrQ9GlRWvtgCA78BBqyRzTzQs8wb97NfFinQDhIJWYzdtwR9R9rWvr4h1c7Y9za/xCXrUDflj7wtzDKeO/mPgCY6zlxQJjJAKrNfJzZDgfG46ABTGAy6+k2kErE2Hs91SRYMjZjcGuMfKwJXu/WVLCxfFZhCbIsDIux7b2emLolGnGcsbliH/W+nDa4FV55PBieTlK88FiTCs25V53qRLDUoUMHHD161OI2ISEhgnX7ixcvxuLFiwVfM3jwYAwePNgmZawKer0eSq1psESZJUIannF9QtEzzLvMHn/WCvEpDRYcpaZtI4HS3oOWLH+1Mz7/9xbuphdi3rNtrTr28HCmGnHSX1cAAHs+6G1x+5aNXHFt/lNmR7l+ukMA/v4vCafvZeGN7sG8AVYNgZodwJu2JdjbCavGPM5WtwHCU3cIZXHsJGJsHNcdyXnF6PvlMWh1erz1qPOAUHAFAJ04vdjcHaX49uVOkBdr0KKRK/6Z2AsZBSrBsYw6NXGHSqN7lLUqLd+UJ1vBXiJBt1AvvPL7OQD8YRWMM0uLn+uA17qVdjgQGhaEa+uEHrzrxfVc58bwdrbnDe5p3O4rZsFgONpLsPW9nvjm4B2TdkrtA93Za9++sTtOTx/A9GwVi7HjSpLg/IlFKg3vva1OdSJYaqg0Og10etNGlpRZIqThkYhF7NQyttAj1IetAlr2UvkGpuRyltlhyfMdy/26fi194e4oRbtAN3buN0ssTQdiJxFj/TvdUKjSwMlM4CdkgNGQFMZe6xZs8ebc2MMRm8d3R4FKg3aPBmDlDsT6Zo+m+C8uF891bmwyxMRznUt71nk42Zutzvr+lc4I8THt9SgRi/DhIKaDwaoxj+O7I3fxbt8wdj030BWJgBce4/fkC+Rk+4wHeV015nGTQGn+s23ZAMbPVYYhHQJ4wdKyl8LZquJPh7aGoz3zPvi4yLDk+Q449yCb18OvnVEvT26mz9coEzsiPBBhvi7lbh9lSxQs1WJCWSWAMkuEkMpztJdg/6O2RDXB3VGKszOfgMzO+uCmLMbj91SW1IpubsZBRXiwB/v45ceDsGC49UNOGCwc0R6rzjzE9y8LB0rGBrT2Mwn8Wvi54PVuwbjwMAd/vNnVZN5GX1cZejX3RqFKi+9fCcd/8bm4npSPSQNbmGwLAGN6NWODJZlUgvAgD3zzYifM23UTb3RvikAPR0TNeAL/xefiGYEpibiDj3Zs4s6rMjamNpom6btXOpd5DaoaBUu1mLmgiIIlQkh9YE1GqbpxG1y/YTSchTXcHKRYMborVBodm20qL6GhNMpLLBZh0XMdzK4XiUTY8E536PV6iEQiRLbzR2QZvc0imnnhwsMcdh7GkY81wfDwQDZrFujhiGFmqve4Ex3/PcHycD9lTSpcE2rfJ5WwtHrhSSlpuhNCCKka69/phvMPctClqQcCLDS2tmTgo/Gv6gJrRtk3WPt2BPKL1bwqPqER7IUYhqMY2NqvzGziU+0aYVAbPxyOyahUFbEtUbBUi5nLIKm11GaJEEKqgo+LDE+bmd6moXOQStiBVMtrxpDW6B7qjd4tfMrcVioR48/Rj5e5XXWqfbkuwuJmljr5dsLrbV4HQNVwhBBC6hYHqQSD2/vbvF1ZdaFgqRYzjFLuLHXG+qHrMbY9M7cdVcMRQggh1YeCpVrMEBSJRczbZCdmInKdXic4pAAhhBBCbI+CpVpMq2Oq4exETJBkCJYAqoojhBBCqkuFKg91Oh3u3buHjIwMtqrIoG/fmhu3o74xtFmSPJosUyounS9JrVPDXlK+OXkIIYQQUn7lDpbOnTuH1157DfHx8SbTi4hEImi1wt3dSfmxwZKICZYos0QIIYRUv3IHSxMmTEDXrl3x77//IiAgoFxjNJDyMVTDGYIliUgCiUgCrV4LlVZl6aWEEEIIsZFyB0t3797F1q1b0bx586ooD+EwroYTiURwsHNAkboIKg0FS4QQQkh1KHcD727duuHevXtVURZixLgaDgAcJMzIqcXa4hopEyGEENLQlDuz9MEHH2Dq1KlIS0tDhw4dIJVKees7diz/7NNEmHE1HAA42DHBklIjPMkuIYQQQmyr3MHSyJEjAQBvv/02u0wkErGT8VEDb9sxjLNkqIYDAEc7Zq4iCpYIIYSQ6lHuYOnhw4dVUQ4iwDDwpFA1nFJLwRIhhBBSHcodLDVt2rQqykEEsINScoYMkNnJAADFGmqzRAghhFSHCg1Kef/+fXz33XeIiYkBALRt2xYffvghwsLCbFq4hs54uhOA2iwRQggh1a3cveEOHDiAtm3b4sKFC+jYsSM6duyI8+fPo127djh06FBVlLHBEqqGc5RQmyVCCCGkOpU7szRjxgxMnjwZX3zxhcny6dOn48knn7RZ4Ro6oWo4NrNEbZYIIYSQalHuzFJMTAzGjh1rsvztt9/GrVu3bFIowrBUDUdtlgghhJDqUe5gydfXF9HR0SbLo6Oj4efnZ4sykUfYcZbEAr3hqBqOEEIIqRblroYbN24cxo8fjwcPHqBnz54AgDNnzmDp0qWYMmWKzQvYkBnaLNmJSt8mdpwlqoYjhBBCqkW5g6U5c+bA1dUV33zzDWbOnAkACAwMxPz58zFp0iSbF7Aho95whBBCSM0rd7AkEokwefJkTJ48GQUFBQAAV1dXmxeMmGngLaE2S4QQQkh1qtA4SwYUJFUtwYl0KbNECCGEVCurgqUuXbrgyJEj8PT0ROfOnSESicxue/nyZZsVrqETauBNbZYIIYSQ6mVVsDR8+HDIZDL2saVgidgOZZYIIYSQmmdVsDRv3jz28fz586uqLMSIYLBEbZYIIYSQalXucZZCQ0ORnZ1tsjwvLw+hoaE2KRRhCI6zRCN4E0IIIdWq3MFSXFwctFqtyXKVSoWkpCSbFIowhDJLhjZLKo2qRspECCGENDRW94bbtWsX+/jAgQNwd3dnn2u1Whw5cgTNmjWzbekaOI2OGWdJqBqOMkuEEEJI9bA6WBoxYgQAZpyl0aNH89ZJpVKEhITgm2++sWnhGrpsJVPd6eHgwS4zVMPlKHOg0qogk8hqomiEEEJIg2F1sKTTMVNvNGvWDBcvXoSPj0+VFYowUgpTAACBzoHsMh9HHzhLnVGkLsLeB3vxXIvnaqp4hBBCSINQ7jZLDx8+pECpmqQWpQIAAl1KgyUHOwdEhkQCABILEmukXIQQQkhDUu5gadKkSVi+fLnJ8h9//BEfffSRLcpEAOj1eqQWMsGSv7M/b12AcwCA0mo6QgghhFSdcgdL27ZtQ69evUyW9+zZE1u3brVJoQhQoivBi61exBNBT8DfiR8seTt6AwByinNqomiEEEJIg1LuueGys7N5PeEM3NzckJWVZZNCEUAmkWFGxAzBdd4OTLBEmSVCCCGk6pU7s9S8eXPs37/fZPm+fftoUMpq4uPItBlLV6TXcEkIIYSQ+q/cwdKUKVMwbdo0zJs3DydOnMCJEycwd+5czJgxA5MnT66KMvKoVCqEh4dDJBIhOjra4rZKpRITJ06Et7c3XFxcMHLkSKSn8wOMhIQEPP3003BycoKfnx8++eQTaDSaKjyDymvmzoxnlaHIQJ4yr2YLQwghhNRz5a6Ge/vtt6FSqbBo0SIsXLgQABASEoJffvkFb775ps0LaGzatGkIDAzE1atXy9x28uTJ+Pfff/H333/D3d0d//vf//D888/jzJkzAJjBNJ9++mn4+/sjKioKqampePPNNyGVSrF48eKqPpUKc7V3RZBrEBILEnE79za6B3Sv6SIRQggh9ZZIr9frK/rizMxMODo6wsXFxZZlMmvfvn2YMmUKtm3bhnbt2uHKlSsIDw8X3DY/Px++vr7YuHEjXnjhBQDA7du30aZNG5w9exbdu3fHvn378MwzzyAlJQWNGjUCAPz666+YPn06MjMzYW9vL7hvlUoFlap0uhG5XI6goCDk5+fDzc3NtidtxruH3kVUShQ+7/U5hjcfXi3HJIQQQuoTuVwOd3f3Mu/f5a6G4/L19a22QCk9PR3jxo3DunXr4OTkVOb2ly5dglqtxqBBg9hlrVu3RnBwMM6ePQsAOHv2LDp06MAGSgAQGRkJuVyOmzdvmt33kiVL4O7uzv4FBQVV4swqxtXeFQBQqC6s9mMTQgghDUm5g6X09HSMGjUKgYGBsLOzg0Qi4f1VBb1ejzFjxmDChAno2rWrVa9JS0uDvb09PDw8eMsbNWqEtLQ0dhtuoGRYb1hnzsyZM5Gfn8/+JSZW/+CQLlImSC0oKaj2YxNCCCENSbnbLI0ZMwYJCQmYM2cOAgICIBKJKnzwGTNmYOnSpRa3iYmJwcGDB1FQUICZM2dW+Fi2JJPJIJPV7JxshsxSVEoUQt1D8WTTJyv1XhBCCCFEWLmDpdOnT+PUqVNm2wqVx9SpUzFmzBiL24SGhuLo0aM4e/asSYDStWtXvP7661izZo3J6/z9/VFSUoK8vDxedik9PR3+/v7sNhcuXOC9ztBbzrBNbWXILF3JuIIrGVfwcdePMbrd6DJeRQghhJDyKnewFBQUhEq0Cefx9fWFr69vmdstX74cn3/+Ofs8JSUFkZGR2Lx5M7p16yb4msceewxSqRRHjhzByJEjAQCxsbFISEhAjx49AAA9evTAokWLkJGRAT8/PwDAoUOH4ObmhrZt21b29KqUIbNkcD71PAVLhBBCSBUod5ul7777DjNmzEBcXFwVFEdYcHAw2rdvz/61bNkSABAWFoYmTZoAAJKTk9G6dWs2U+Tu7o6xY8diypQpOHbsGC5duoS33noLPXr0QPfuTFf7p556Cm3btsWoUaNw9epVHDhwALNnz8bEiRNrvJqtLMbBUom2pIZKQgghhNRv5c4svfzyy1AoFAgLC4OTkxOkUilvfU5OzcxXplarERsbC4VCwS779ttvIRaLMXLkSKhUKkRGRuLnn39m10skEuzZswfvvfceevToAWdnZ4wePRoLFiyoiVMoFzd7fhfHHBXNE0cIIYRUhXKPsyTUPohr9OiGVxVk7TgNtpRSmILIbZHscy8HL5x4+US1HJsQQgipD6y9f5c7s9QQg6HaKMA5AG72bpCXyAEAeao8aHVaSMRVM3wDIYQQ0lCVO1hKSEiwuD44OLjChSHWE4lE+KLPFzidfBobb2+ETq9DQUkBPBw8arpohBBCSL1S7mApJCTE4ng+Wq22UgUi1uvTpA/6NOmDf+79A4VGAXmJnIIlQgghxMbKHSxduXKF91ytVuPKlStYtmwZFi1aZLOCEeu5ydyg0CiQr8qv6aIQQggh9U65g6VOnTqZLOvatSsCAwPx1Vdf4fnnn7dJwYj13O3dkVaUxrZfIoQQQojtVGoiXa5WrVrh4sWLttodKQc3GdOCnzJLhBBCiO2VO7Mkl/OzF3q9HqmpqZg/fz5atGhhs4IR67nbuwMAZZYIIYSQKlDuYMnDw8Okgbder0dQUBA2bdpks4IR6xkySxQsEUIIIbZX7mDp2LFjvOdisRi+vr5o3rw57OzKvTtiA4bRvKkajhBCCLE9q6KbLl264MiRI/D09MSJEyfw8ccfw8nJqarLRqzkLqNqOEIIIaSqWNXAOyYmBkVFRQCAzz77jH1MagdDZkmuomCJEEIIsTWrMkvh4eF466230Lt3b+j1enz11VdwcXER3Hbu3Lk2LSApG9sbroSq4QghhBBbsypYWr16NebNm4c9e/ZAJBJh3759gu2TRCIRBUs1gM0sWVENdzHtIv66/ReGhw1Hv6B+VV00QgghpM6zKlhq1aoV29NNLBbjyJEj8PPzq9KCEesZhg6wpoH3grMLECePw6mkUzj/+nmIRTYbaosQQgipl8p9p9TpdBQo1TKG+eDylHnQ6XVmt1NpVYiTxwEAlFolbufcrobSEUIIIXUbpRXqAT8nP4hFYpToSpBVnGV2u2uZ13jPUwtTq7pohBBCSJ1HwVI9IBVL4e/kDwC4nXMbX138Creyb5lsdzThKO+5pcCKEEIIIQwKluqJxq6NAQDzo+Zj7a21eHnPy1CoFbxt7uXdAwA42jkCADKLM6u3kIQQQkgdRMFSPdHGqw0AfgB0M/smb5u0ojQAQAefDgAos0QIIYRYo9zBUmJiIpKSktjnFy5cwEcffYTff//dpgVr8PR64IumwAIfoCC9zM17Ne5lsuxG1g3O7vQULBFCCCEVUO5g6bXXXmPnh0tLS8OTTz6JCxcuYNasWViwYIHNC9hgiUSAtgTQqQFNcZmbP9boMZNlhmo3AMhV5UKpVQIA2vm0A0DVcIQQQog1yh0s3bhxAxEREQCALVu2oH379oiKisKGDRuwevVqW5evYZMybYugLjtYkklkGNliJBztHPFux3cBAPHyeHb9w/yHAIBA50AEOgcCoMwSIYQQYo1yB0tqtRoymQwAcPjwYQwbNgwA0Lp1a6SmUld0m5I+mqzYqKG2OXN7zMWpV05hUNNBAPjB0v28+wCAMI8w+Dj6AAByinMsjstECCGEkAoES+3atcOvv/6KU6dO4dChQxg8eDAAICUlBd7e3jYvYINWjswSAIhFYsgkMgS7BkMikiBPlYfkwmQApVVyYR5h8HL0gggiaPQa5KnyqqLkhBBCSL1R7mBp6dKl+O2339C/f3+8+uqr6NSpEwBg165dbPUcsRE2WFKW62VOUie082baJV1MuwiAHyxJxVJ4OngCADIV1G6JEEIIscSqueG4+vfvj6ysLMjlcnh6erLLx48fDycnJ5sWrsGzMwRL1lXDcT3u/ziuZV3DxbSLGNF8BFsN19yjOQDA29EbOcocZBdn26y4hBBCSH1U7sxScXExVCoVGyjFx8fju+++Q2xsLM0ZZ2vlrIbjivBnsnxnU87iXu495ChzYCeyQ6h7KADA19EXAPWII4QQQspS7mBp+PDhWLt2LQAgLy8P3bp1wzfffIMRI0bgl19+sXkBG7RyNvDmesz/MXg7eCOzOBPP7XqOXeb0aJ+GRt7UI44QQgixrNzB0uXLl9GnTx8AwNatW9GoUSPEx8dj7dq1WL58uc0L2KBVIrMkk8gwPWI6b9mrrV9lHxuCJUMDcGN/Xv8T7xx4B7nK3HIfmxBCCKlPyh0sKRQKuLq6AgAOHjyI559/HmKxGN27d0d8fHwZryblYgiWrBiUUsiQZkPwSqtX4CJ1wYyIGRgYPJBd18WvCwDgSMIRaHVa3uuuZl7F95e/x/m081h5Y2XFyk4IIYTUE+UOlpo3b45//vkHiYmJOHDgAJ566ikAQEZGBtzc3GxewAaNrYarWLAEALO6z8LZ187i9Tav85b3bNwTzlJn5ChzTAKiHy7/wD4+nni8wscmhBBC6oNyB0tz587Fxx9/jJCQEERERKBHjx4AmCxT586dbV7ABk3qwPxbUv42S2XuWixFZz/m/Vp+ZTmWXVoGtVaNW9m3cCHtArtdnDyOhhcghBDSoJV76IAXXngBvXv3RmpqKjvGEgAMHDgQzz33nE0L1+C5MtOSIK9qqjfHdRiHW9m3kKPMwaobq5BckIwMRQb00GNg8ECkFKYgJicG/6X/hyHNhlRJGQghhJDartyZJQDw9/dH586dkZKSgqSkJABAREQEWrdubdPCNXi+rZh/M2OrZPddGnXBsZeOoWujrgCAg/EHEZ0ZDTuxHWZGzERXf2a5YWBLQgghpCEqd7Ck0+mwYMECuLu7o2nTpmjatCk8PDywcOFC6HQ0z5hN+bVh/s2+B6REA6oC5rlGZbNDiEVirIhcgRdbvsgumxkxE42cG+HxRo8DoGCJEEJIw1buarhZs2ZhxYoV+OKLL9CrVy8AwOnTpzF//nwolUosWrTI5oVssFz9gaa9gPgzwO/9mGV2jkzvOLcmgMwVUOYxveb82gI6DaDIAYIigPwk4NY/QNsRQPIlIOwJIKAT01jcyQvISwTURYBIArGzD+YWixHh2hFFyjw8f/8SkJOFLi4+EEOEOHkcNu4ei1ZiR3R2DYE4+TIgsQPcgwB5MuDeBHDwYPYrdQIK0gA7GXNcnRZw8mbK6OAOlBQy07fYOwGFGYBPC+Y8Uq8BWXeB1kOZfakVQFEmkH4TKM5jytr4McAzBCgpAnIeMtfDLRDIjWOukbMfc45ezQBtCRAfBTTpChRmAjo1kH0f8GwKOPkALn7MNrd2AW2eAcRSJjgtKQROf8uUt80wQCIF7F2YbTNiAL0WkLkz56xWMOfo1wZIu85cU5/mgE9LACLApRFQnMMEuaoC5rXOfoCdA/NaZx9AInt0DGdAmQ+o5Mz10qiAnAfMNfBry7yf3s0BrQpw8We2ub2bub4aFdCsL7O/4jwg8zaz3DOEOaZOy1zHa5uYa9bhReZapt8A9ACa9gTuHmA+W8HdmPLlJQBeYcx7JhYD8WeZsniGABJ7oCCVeY89mgLOvsxnMj8ZSDzPvH8hvZn9Z8YCgZ2Z80u/yXymC9IAjyDmeHnxgCKbKWNQBHOt3QKYHwhS59LPTGEGU3ZHD+bYTj7MPgszAPfGQFEWAD1TdqkTIBIDd/aXfgaa9WPKr8hhttdpmGuvLQFcAwBVPiBPYc6lpAiQuTGfZzsZ8/nKjWfOo6SI+Sym32TK2qwvIJYAaTeYbV39mdeKJcx1KEwDkv5jPuMO7sxnIucBELuXeQ9bRDLn5xrAfEYz7zDXxr0Jc11EYub9zb7PHDcvEWg5mHlNSRFQnMtsp9cx/x+bD2SuUeYd5rMitgOUcuZ7QilnzsnehSmLvTNTzqy7zL7uHwHkqcz7IHViyleQAvi0Ahq1A+4eZN5739bMeWXGAo27MGUXSZjPWkEqc5z8JGZdzgPmvew3HWjUHsi5z3y2MmIAvZ4pn3cYsy97Z8AjmDl23Cnms+EZAjTqwFxbZ1/m/4hWxVxTiT3g6An4d2COl3qVuf4q+aPvhibMZ6kgjTlnv9bMZypmF3N8eyem3N7Nme8DjYr5DMlTmeskc2M+w76tme+ZrLvM953Mhfm+UmQz//edvJnPnZMX8/2q1wPyJOaa+rVj3o+sO0xNgcOjz29xLnM+hu82eQqgVQNeoaXvvYM74NaYuV6ZMcz/NTsH5v+3Vs18z7g3Zr6rch4w36vKfOazEdiZOc+se8yx+k1jzi8vHggIZz4v+YmARsm8v9oS5hrrtMw5Gt7/B8cAz2ZAwlnm/3TzgUDCOSBmN/Mdp9cCrZ9h3odrm5n3r2kv5j3PjWOuiXcL5n2ROjLvRcxuptyezZgyXP8baPfco//rCubzL09lyubsy/y/zbwNdH8f6DLK9vdZK4n0er2+PC8IDAzEr7/+imHDhvGW79y5E++//z6Sk4XH7anP5HI53N3dkZ+fb/segdn3gR0TgOT/mA94NfvAzwfHnUunsRlaWISlmTRFCiGEkGr24TXmB68NWXv/LndmKScnR7BtUuvWrZGTk1Pe3ZGyeIcB7xxifhVoS5jIXCwB0m8xz5X5zC8ejyCgMJ2JyBXZzC8imdujbEMu88tILGUyACIJ87rCDMDFl/lV7uRd+qtOJWezIRNkUpzSp0IrYoqz18UZjfRiTPbvh3+1uWgsz0BLB184O/sxv1q0auYXokbJ/Mpyb8I8N/zi0qqYX4FeYYBvS+YXe1488yss8zbza9DBnfn1JrFnMgEZN5mDS52Y85G5M7947Z2ZzEh+AvOLUV0EBPdgtnt4kvml3rgr88sksDOTaWsSwWQaMmOZ7IBey/wq0mlKh2rQaZlfcoYsnkQGhPZnfnlJHZlyKfOZX1hFGcyvY2df5vVNezC/BPMSmF/6Mjcmq5B4jskIeTdn9qlRMb+8HD2Za6WUM79uM28z27s1Zn4hplxh9u/bhvmS0OuZX/VFWY+yR02ZLFX2feYXvqs/k60rTGc+K2ol8+taowIenmDOz5CVzIxhnts5ACHMQLNQ5jPZDJGIKZPh2jfuyvwaVOQwv4YNmbnEC0yvTa9QJmuWfoN5nbMPcw4qOXOOKjlzLjI35jqKxMx+3Jsw56LKZzJoePRBkzoy769IzLw24zbzfjp4MBkBzxDm/Yk7zWzn3pj5186R+RVvyDJl3mbeh6AIZl3aVea1zn7Me5RwjnmtoyeTtXELZDIVynzmcylzY65/zn0mQ6nXMVlVw3VzD3qUJc1k9pOXyByzSVdmW72eeW9CepVmcURiIOMWkwV19GKuoXcY8/9UrWAyBlo1k4FwDwIc3Jj/j84+TEbFNYC5/sp8IHQA82/yf0xWr8njzOepIJ35TPq1Zt4PjRII6sb8X8iLBzQlTMajpJD5ha/MZ/5/CJE6PzpfGZMpbdyVKWvOfebaNO5a+l55BDHXVadl3sPMWGY7exfmWI5ezD4M3IOY7AIAuAezbz/yEpgOLmEDmCyOnf2jLLXXowyQiPlc6/XMuYulTPZLp2E++2Ip8x1SkMY89whm9lmcx1z3kkLmmuQ8YMrk2ZT53nH2ZT5rmkf/b7ybM98TSjnz2SgpfPQ9oS/9zhFJmHMM6MQ8vrm99PxCBzDfMarCR9njPOYz7NaYeX8TzjL/Z+1dmfL5NC/9P+/gwZTJM4TJYBmyZ9Az5XENYK5xSSHzOfUKZa5tyhXmPc26w5TByZv5/y5PYb6vfFsz378Fqcz749f6UTY5kdlf7kPm/7Z3c+b7wyOYOYa2hCmjWsG8bx1eZJ7nxjHX+sFx5ntE6si8P3GnSj/PAPN6Ry/m8+fXlnm/Mm8DSZeY7yyAKZNG+ai8qUBwd2b/+YlA5zeY5TWk3Jmlbt26oVu3biajdX/wwQe4ePEizp07Z9MC1gVVmlmqBW5m30R6QQpWx6zDlYwrJutdpa7YPnw7/J39a6B0Fuj1zE2/svvQ65mqKCFaTenNs6rodOaPb2CLc63I8bVq5ou9IseuyjLXJHVx6YCydY2599qaz6Alej1zXezNTLaulDNBoS2PKVQGoPZ/5mr7/4vylM9W51KF18Ta+3e5P4lffvklVq5cibZt22Ls2LEYO3Ys2rZti9WrV+Orr76qVKGtoVKpEB4eDpFIhOjoaLPb5eTk4IMPPkCrVq3g6OiI4OBgTJo0Cfn5+bztRCKRyd+mTZuq+Czqlnbe7fBEyJNYM3gN23OOq0BdgKknpkKtU9dA6SywxX8ukcjyF3ZVB0qAdTeMqvxytXj+0oofuzbfECqjrgZKgPn3urJBi0hkPlACTAMlWxxTqAx14TNX28tYnvLZ6lxqwTUp96exX79+uHPnDp577jnk5eUhLy8Pzz//PGJjY9k546rStGnTEBgYWOZ2KSkpSElJwddff40bN25g9erV2L9/P8aOHWuy7apVq5Camsr+jRgxogpKXveJRCKsGrwKfzz1B8Z1GIeXW72MJX2WQCwS41rmNXx66lMoKjDpLyGEEFKblbsazpykpCQsWLAAv//+uy12J2jfvn2YMmUKtm3bhnbt2uHKlSsIDw+3+vV///033njjDRQVFcHOjskIiEQi7Nixo1IBUn2vhivL/rj9mHZiGvTQY0DQAHzT/xtIxdKaLhYhhBBiUZVVw5mTnZ2NFStW2Gp3JtLT0zFu3DisW7cOTk4W0rkWGC6GIVAymDhxInx8fBAREYGVK1eirPhRpVJBLpfz/hqywSGD8XnvzwEAxxKPYdbpWchT5tVsoQghhBAbsXGlcNXQ6/UYM2YMJkyYgK5dTdvMWCMrKwsLFy7E+PHjecsXLFiALVu24NChQxg5ciTef/99/PDDD2b2wliyZAnc3d3Zv6CgoAqVqT4ZFjYMi3svhggi7Hu4D0O2D0FWcRa7XqlR4kj8EaqmI4QQUufYrBru6tWr6NKlC7RardWvmTFjBpYuXWpxm5iYGBw8eBBbtmzBiRMnIJFIEBcXh2bNmlldDSeXy/Hkk0/Cy8sLu3btglRqvopo7ty5WLVqFRITE81uo1KpoFKVjqItl8sRFBTUYKvhuHbe24nZZ2YDAJ4IegLL+i9Dfkk++m1mBtUc0XwEFvZaWJNFJIQQQgBYXw1Xo8FSZmYmsrMtD3AYGhqKl156Cbt374aI0yJeq9VCIpHg9ddfx5o1a8y+vqCgAJGRkXBycsKePXvg4OBg8Xj//vsvnnnmGSiVSshkMqvOo6G3WTJ2MukkPjj6AXR6HT7t9ilOJp3E6eTT7Prro6/XYOkIIYQQhs0HpXz++ectrs/Ly7O6cAa+vr7w9fUtc7vly5fj888/Z5+npKQgMjISmzdvRrdu3cy+Ti6XIzIyEjKZDLt27SozUAKA6OhoeHp6Wh0oEVN9m/TF5C6T8c2lb7D4/OKaLg4hhBBSKVYHS+7u7mWuf/PNNytdICHBwcG85y4uLgCAsLAwNGnSBACQnJyMgQMHYu3atYiIiIBcLsdTTz0FhUKB9evX8xpi+/r6QiKRYPfu3UhPT0f37t3h4OCAQ4cOYfHixfj444+r5DwakmHNh+Hby99CZzRFi524GsYlIoQQQmzI6jvXqlWrqrIclaZWqxEbGwuFgmlAfPnyZZw/fx4A0Lx5c962Dx8+REhICKRSKX766SdMnjwZer0ezZs3x7JlyzBu3LhqL3994+XghS3PbMGko5OQUZyBkS1GYnPsZuj0Oqi1akglNLQAIYSQusFmbZYaMmqzZJ5Or4NSo4SjnSN6/tUThepCbBu2DS09W9Z00QghhDRw1T7OEiFCxCIxnKROEIlEaOHJTJZ4NOFoDZeKEEIIsR4FS6TaGOaV+yn6J17vOEIIIaQ2o2CJVJvxHcejlWcrAMDcM3NxN/cujsQfwZTjU7DmpvnhHwghhJCaRG2WbIDaLFkvR5nDDlBpLOrVKLjau1ZziQghhDRU1GaJ1EpeDl6Y22Ou4Lptd7ahoKSgzLn5CCGEkOpEmSUboMxS+SUXJsPJzgnHE49j38N9OJt6ll03q9ssvNL6lZorHCGEkAah2qc7acgoWKqceHk8ntnxDG8ZTYlCCCGkqlE1HKkzAp0DTZZRDE8IIaS2oGCJ1Dih0bxjcmJqoCSEEEKIKQqWSK3w4xM/Ymz7sXiy6ZMAgO13t7PrFGoFlBplTRWNEEJIA0fBEqkV+gX1w0ePfYQXW74IANj7cC/UOjVKtCV49p9n8fiGx7HtzjasuL4CWp22hktLCCGkIaEp4EmtEuEfAS8HL+Qoc9BlXRd82/9bZCgyAADzz84HAAS6BGJIsyE1WEpCCCENCWWWSK0iEUswtNlQ9vnk45NNtkmQJ1RnkQghhDRwFCyRWueTxz/B6Lajza53tHOsxtIQQghp6ChYIrWOWCTGlK5T0N67veD6InUR+1iv1+NB/gNodJrqKh4hhJAGhtoskVpJLBLjr2f+ws3sm3CUOKKRcyN039gdADO/nMG51HMYf2g8+jTug58H/VxTxSWEEFKPUWaJ1GrtvNsh1CMUzlJnfNTlIwDApthNkJfIAQAX0i4AAE4ln0J0RnQNlZIQQkh9RsESqTMCXUpH+r6cfhkAIBFJ2GV7HuypsmPvur8Lg7cNxt3cu1V2DEIIIbUTVcOROuOJ4CfYxx+f+BjNPZojtSiVXZarzK2yY886PQsAMOfMHGx6ZlOVHYcQQkjtQ5klUmfIJDJ81e8rAIBKq8LN7Ju89kuGqrmqpNKqqvwYhBBCahcKlkidEtk0EsPChgmuMwRLSQVJmHBoAqJSomx+fJrglxBCGh4KlkidIhKJML/HfCzuvdhkXb4qHwDw/eXvcSblDN499C4NKUAIIaTSKFgidY5UIsWzYc9iQc8FvOXJhcl4mP8QBeoCdtmr/75q02yQHpRZIoSQhoaCJVJnRYZEopNvJ96yX67+Al9HX/b57ZzbyFPlVXPJCCGE1CcULJE6y0nqhHVD1uHi6xfZZcXqYt4I3wCQVpRW3UUjhBBSj1CwROo0kUgEBzsHtg1TgboAchW/V1y6It1mx6NqOEIIaXhonCVSLzR2aQwAuJR+CYHOgbx1lFkihBBSGZRZIvVCM/dm7OOUohTeurSiNCQVJEGtU5t9fVpRGl7c/SI23bY84CQNHUAIIQ0PBUukXvB08MQLLV/gLXunwzsAgBU3VmDI9iHosq4Lpp+cLhjwLL+8HLdzbmPR+UUUEBFCCOGhYInUG30a9+E9b+HRwmSbvQ/34mrmVSz7bxmG/zMchSWFuJN7B7sf7Ga3SShIqPKyEkIIqTuozRKpN3o17gVPmSdyVbkYHjYc3o7egtuN2jeKfbzz/k6TaVJe3/s6Tr18CiKRqErLSwghpG6gYInUGzKJDCdfOYnkwmR4O3hbFezo9DoYd3DLV+UjsSARwW7BJttTbzhCCGl4qBqO1DuNXRrDwc4BMokMx186bnFbsUgsGACJQFklQgghDAqWSL1mrirOQCKSCC4v0ZUILqfG34QQ0vBQsETqvXEdxsFOJFzjrNKqBDNLKq2KfXwi8USVlY0QQkjtR8ESqfcmdZmEK29ewU8DfzJZp9AooNQoTZaXaEszS/87+j/2MbVZIoSQhoeCJdJg9G3SF8+GPstbtuL6CpO55AB+ZokQQkjDRsESaVAmdp6Izn6d2ecqrQo3sm6YbEfBEiGEEAMKlkiD0tilMdYMXgNHO0d2WUxOjMl2aq3w1CjUwJsQQhoeCpZIgyMSiTCvxzyT5Y1dGqOjT0cA5jNL1GaJEEIanjoXLKlUKoSHh0MkEiE6Otritv3794dIJOL9TZgwgbdNQkICnn76aTg5OcHPzw+ffPIJNBpNFZ4BqQ2GNBuCFp6l06E42jni3+f+hbvMHQBVwxFCCClV54KladOmITAw0Ortx40bh9TUVPbvyy+/ZNdptVo8/fTTKCkpQVRUFNasWYPVq1dj7ty5VVF0UouIRWJM6jyJfS4VSyERSyCTyADwe8NxCVXDpRSm4Grm1aopKCGEkBpXp4Klffv24eDBg/j666+tfo2TkxP8/f3ZPzc3N3bdwYMHcevWLaxfvx7h4eEYMmQIFi5ciJ9++gklJcI3S4DJbsnlct4fqXv6B/VnH+v0OgCAvcQeQGlm6UDcAd5rjOeRA4DIbZF4Y+8beJD3oIpKSgghpCbVmWApPT0d48aNw7p16+Dk5GT16zZs2AAfHx+0b98eM2fOhEKhYNedPXsWHTp0QKNGjdhlkZGRkMvluHnzptl9LlmyBO7u7uxfUFBQxU6K1BpavRYASjNLj0bwvpnF/xwUqgtRWFIomGG6kc30qlNqlFhzcw3i5fFVWWRCCCHVpE4ES3q9HmPGjMGECRPQtWtXq1/32muvYf369Th27BhmzpyJdevW4Y033mDXp6Wl8QIlAOzztLQ0s/udOXMm8vPz2b/ExMRynhGpbfyc/ACUZpYM1XBCYzD1+KsHVt1cBYDfa84wn9zv137H1/99jWd2PENtnyrgl+hfMP3kdDbbRwghNa1Gg6UZM2aYNMA2/rt9+zZ++OEHFBQUYObMmeXa//jx4xEZGYkOHTrg9ddfx9q1a7Fjxw7cv3+/UuWWyWRwc3Pj/ZG66eeBP6OVZyss7bsUQGlmKbGACYAN1W5h7mG813176VtodVpetZyhp9yl9EvssnlRpr3uiHl6vR4/X/0Zex/u5V1Hg3xVPl7a/RJW3VhVof2nFaVhXtQ8xObEVraohJAGpEaDpalTpyImJsbiX2hoKI4ePYqzZ89CJpPBzs4OzZs3BwB07doVo0ePtvp43bp1AwDcu3cPAODv74/09HTeNobn/v7+tjhFUsv1adIHW4dtRTvvdgCAcL9wAMCh+ENQa9VsMPR2h7fRtRE/q/lj9I/ov6U/+1yhVqBYU4zLGZfZZf8++LdqT6CeUWpLp54pKCkwWb/i+grE5MRg2aVlFdr/xyc+xva72zFm/5iKFpEQ0gAJzy5aTXx9feHr61vmdsuXL8fnn3/OPk9JSUFkZCQ2b97MBkDWMAw1EBAQAADo0aMHFi1ahIyMDPj5MdUwhw4dgpubG9q2bVuOMyH1xaDgQXC0c0SxphgJBQl4kM802naVusJD5sHb9s/rf/KeF6oLsSFmg8k++2/uj50jdsJd5o58VT7OppzFgOABsBfbQyQSVdm51EVyVWmmrlhTbLI+szizUvs39FosVBdWaj+EkIalRoMlawUHB/Oeu7i4AADCwsLQpEkTAEBycjIGDhyItWvXIiIiAvfv38fGjRsxdOhQeHt749q1a5g8eTL69u2Ljh2ZgQefeuoptG3bFqNGjcKXX36JtLQ0zJ49GxMnToRMJqvekyS1gkgkQph7GG5k38CInSPY5W4yN3YMJnMyFZlsQ3GubGU2vrz4JRb1XoRJRyfhcsZl9GncB7E5sRjTfgxGtR1l69Oos7jVmjnKHJP1QtkmQgipanWigbc11Go1YmNj2d5u9vb2OHz4MJ566im0bt0aU6dOxciRI7F79272NRKJBHv27IFEIkGPHj3wxhtv4M0338SCBQtq6jRILdDKq5XJMk+ZJ9xkltumbby9EWqd8DQpF9MuAgBbRXcq+RQyijPw5cUvBbc3Fi+PR3JhslXb1mXcYCm7ONtkPQVLhJCaUCcyS8ZCQkJMum4bLwsKCsKJEyfK3FfTpk2xd+9em5eR1F2TH5uMbXe3sc/HdRiHZu7N4G5vmllyljrzesxlKoSricqq9skqzsK1zGsYEDTApGquSF2EZ3Y8AwC4+uZVqHVqHEs8hh4BPcrMdtU13Go4oTGtqPqMEFIT6k1miRBbcZe5Y92Qdeji1wWfdvsUk7pMgkgkgp3Y9LfFrG6zED0qmn1u7mZeUFIg2AYHYIYpGLBlAD489iG2392Om9n8sZ3SikqHsVBqlFh+eTk+OfEJ/nfkfxU4u9qNGyAJVWkWltgmWJKKpTbZDyGkYaiTmSVCqlq4XzjWDFnDW+brWNoZ4bdBvwEAejbuCQAIcQtBnDzOYlVZVHKU4PJb2bfYx/PPzgcAHBx5EAEuTEcEja50rkKFRoHd95mq5OjMaMH96fV6XEy7iFZerepc5kmpKe0Nxz1vdpneNvM2SkQSm+yHENIwULBEiJUiQyKRpkhDz8CeaO3VmrfORcp0OshQZJh9fY7KtMEyAKQpTAdAvZt3lw2WuNV8xepiSMSWb/R7HuzBp6c/Rah7KHaO2GlxWwA4k3wGYpEYPQJ7lLmtOcWaYhSpi+Dj6FPhfQDgtfkSyizZSlXuu7bT6/XQ6DWUXSOkHKgajhArScQSvN3+bZNACQBc7V1Nlr3V7i3e83xVvuB+M4pMA6yLaRfx4dEPsfn2Zl7VnkKjgFhk/r+tXq/Hp6c/BQB22ANLCksKMeHwBIw/NN7s5MHWGLxtMAZsGYD0ovSyN7aAm03S6Ww7gje3TWNtGB08R5mDE4knoNVVb+D27qF3MejvQVCoFWVvTAgBQMESITbhYu/Ce/58i+cxqcskzIiYgSYuzPAWeco8wdfuebDHZNnqm6txNPEoPj//Oa+djkKjgJ3IfEL4RFLZnRq4uIEYd0DI8jJ08/8v/b8K7wPgZ5bKqnITmp/PEm42qTZkll7d8yr+d/R/2Hpna7Ue92zqWeQoc3A+9Xy1HpeQuoyCJUJsgJtZGtliJD7r+RnsxHZ4vc3rGNlyJAAgV5Ur+NqYnBiL++ZlltQKk2q4XGUu5kfNx9XMq4jLjyuzrBtiNmDvA6YHqGE+O4A/z50lloIUS1kvIYnyREw8MhGX05khFbiZpbIyLuUdSsHcsA41JaUoBQCwP25/jRzfMD0PIaRsFCwRYgOGiXgBoJEzf3JmQyPrlMKUCu3buBqO2zg5OiMaX178EtvubsMbe9/AihsrLO4rvSgdX1z4AtNPTUdWcRYve1OiLUFUchTW3FxjNiD6JfoXDNgyAKmFqewybpWW8bAHyYXJSCpIMlueqSem4mTSSYzez0xbVJ42S8P+GWZxvTHjYKm8mSlr6fV6bIzZyI6tVZYSXcWrPyuDgiVCrEfBEiE28HKrl/FYo8cQ6ByIJ4Ke4K3zlHkCAJIKmaBBIpLgzbZvWr1vbmCiUPODpU9Pf4p7effY53mqPIv74g7quPfBXl42qURXgncPv4uv//va7I3+56s/I1uZjR+jf2SXqbQq9jG3bGqtGoO3DcaQ7UPMtofilh3gZ5bKqoYrb6bIOHNWVZmm82nnseTCErx94G1MODSB18NPSGXailUKxUrVKq0oDX9e/9NsdTyp3ShYIsQGfBx9sHrwahx44YDJCOCGrJNhvCQnqRM+7PIhbxtLXdl33d/FPlZo+NVwKq3KbIbEz9HPZBm3XdL+uP28gIEb9Aj10OPi3uBVmtLXiTlfKdzAzdzI28YBCy+zJFQNV4kbvPGxzI17VVmJBYns4zMpZ3gDnAqpzmCJmwWkzFL1GrN/DL6//D3mRM2p6aKQCqBgiZAq5u/sz3vuZOdk0m3bUpWTQlPaaym1MJUXWDVyamT2pie0nBsgJBYk8gIIw/hNAL8tkxBuBogbgHGzQdzqQ24gZsAdEsGgrGo4HSrei626giXja1fWQJrVGSxxrykFS9XL0MbuXMq5Gi4JqQgKlgipYt4O3rwebM5SZ5O2PU82fdKqfa26uYrXILyJSxOz3eA1Og32PdyHk0kn2WXcKqF8VT4viFl9czX72Lh8xriBB3ef3Bs/dzRuocCEezxumQ2EMktCA1VayzhYEgrWbME4WCorKEkqTBKcNLgqcK9fVbXZIpaV9X+L1E4ULBFSxSRiCQJdAtnnTnZOJtvM7j5bcDoVg/be7QV7mlnq7p+rysW0k9Mw8chEtr0ON2jRQ48LqRcEX1uezNL6mPXsY25A8vu139nHQo28hRq8lzV0QKWCJW31BEvG75M1GZxX9rxSJWUxxg1AKbNUM8rbY5TUDvSuEVINJj82mX1s6P3Uxa8LAOC9Tu/By8ELbvZu7DZh7mHwcvBin4f7haO9T3uT/ZbVeNggo5gZ+NI4uOI21C4LN0PFDWQ2x25mH3MzS9zt/3fUdB47odG+y2qzVJlgyTj44lZvViVrMjipRalm16UUpuBI/BGbZILKM77U/Kj5mHxssk0zUCuur8CzO55FVnGWzfZZ11CwVDfRu0ZINRjUdBD72DAlyh9P/YHtw7ZjQqcJAMALljY/uxmtPEsbijdzb4ZQ91CT/Vpq4M1l6FFnbXAlVLU38chE9rEhaDHezhDsCAU1xtsKjXrOq4YTuLHX18ySJZHbIvHR8Y9wKP5QpfYDWF8Np9PrsO3uNhxOOIx4eXylj2vw3eXvECePw8obK222z7qAm9GlYKluoneNkGpm6CVmL7FHC88W7Jfnm+2Y4QR6BPSATCKDh4MH+5pm7s14mSaDYk2xVY2eDb3brG3ULNQgm8sQFBm3tSnRlkCj0wgGItwG39x9AMxExMbLjIMlw5xmFWXcZskW030UlBSY7Me4TYqtpla5lH6p0vvgXlNLQydwt6uKqWFqw3Qz1WnphaXsY5rEuW6iiXQJqSVGthiJFh4t0NKzJQB+pqmJSxNeJmBl5Eq8feDtMoMag7SiNMyPms92Y3eVuqJALdydH+BnoBLkCVh+ZTlvvUanwfST03E18ypvea4yF5FbI3lttAwKSwp558StsjMEGJaq4SoTKBnvG6h8ZqlEW4Kef/WEndgOl964ZDZjYKtqLEtt2qzFvaaWsnRVPV+dpSl7ynIy6SQc7RzxuP/jNixR1dpxbwf7uKz2gJYoNUociDuAXo17VXrSalI+lFkipJr8OuhXeMg88N2A7wTXi0VihPuFw0nKNADn/vr2dfLFY40eY587SBwAMF+e1tyM19xcwxvvp2fjnha3X3pxKRtcPLfzORyIO8Bbn1iQiL0P95pMObL7wW5kFGcgOjPaZJ/GYy1xAz3DjVujNV8NZ+nmrtfrMffMXLx3+D2zN3rj11e2zVJmcSa7X27gZXx8WzWkNp7mpiK4Aael4JOX+amCzlsVDfyyirMw8chEvH3g7TrVm4+bTapMZunbS99i9pnZGHdwnC2KRcqBMkuEVJNejXvh5Msnre46zM3u2Int0LdJX3zZ90u08WrDBjJKrRL2Evsy92U8sjd3ehZz4vLjEOIWIjgdB3cgSgBo7NIYyYXJFjNdt7Jv8Qbs5GaWDOfD6w1nFNxYCpYupF1gf70nFSahqVtTk21s3WaJG1AUlhSybbCqalqVymRjDKzOLFXxRMMVDZbSFensY7VODXuJPeZFzYNKq8KS3ktqbbd8O7Ed+7moTBkNP1qMR74nVY8yS4RUo/J8UYa4h5i8dkizIQhxD2EzSznKHMTJ48pdjiebPllmdYAeerONe7kBlJ3IDkObDWWWWxhgcW7UXMTmxLLPuYGVIZCx1MDb0s39bu5dwf1y2brNEjdg5I4pZVzOygykyWWLajjedDJmruexhGNIkCdU+ljGuEGj0Ln8l/YfzqactbgP48FQC0sKsf3udvz74N9a3cOOe76VySzRcA81hzJLhNRSo9qOQr4qHwODB5qs83b0tvhamURmMcsT7hsOZ6mzSaNrrqziLHx49EOz61kisNkt44DEz8mP7f0HAC/sfgE7h+9EqEdomZklkzZLRjd3w5x7AD9LZJz1MriVc4v33JrMkkKtwOwzszEoeBCGhg7lreMOw8C9jsblrExmibsvWzQM5gagQsHS6eTTmHRsEn9hBYqv1+shEomQXpSO5MJkdGnUhR9gGwVLap0abx14CwBw5tUzvLZtXNzPjHFgXluzSgB4I/ZXppxVnfEj5lFmiZBaytHOEZ88/gm6NOpiss5J6oSXW73MW7akzxI0c2+GyJDIMht+i0QiOEudLW6z6fYmi4NesvuCCDKJTHBdO+92mBg+kbfsXCoz3UOZwVIZmSVum5siDSdYMnPuZ5LP8J4b2izFy+NxM+umyfY6vQ5fXvwSh+IPYfqp6SbrudWk3PZYxm2BKhMs8SYprmCbpZU3VmLZpWUmZRO68QoNUlrenmsTj0zEmP1joNPrMGjrIIzePxpXM6/yrpfxdD/cz4Kl6WG4Aa5So+T17izvsBI6vQ4P8h9US9snbnBYmaEDdLqG1YuwNqFgiZA66tNun7KPu/h1wTOhz2Dn8J34ut/XZl/Tq3EvrIpcBUB4nCOuY4nHrCqHWCRGhH+E4DqZRIax7ccKruNVwwmMz2R88zPOWnEzT9wqNXPBkuFmbZhapkhdBL1ej2d2PINX/n2FlwEDgJ+if7I4CS43kOQFS5WohtPpdTgYd5BtOM8NBowzS6turML8qPkWgxmtTotvL32LVTdWIbEgkXfNhIYOEGr0XZ5shlqnxsmkk7iccRkP8x+yyy+nX7Y4xhf3mlkKJoznG+ReH0tDIQj54sIXGP7PcCw6vwjHEo5VadDEDQ4rkyG0VZUuKT8Klgipo8QiMV5o+QLsxHaYFjENgOUUf2e/zvh10K/o6t8VAOAuc7dJOUQQoZ1POzjaOZqss5fYQyrhZxGWXFgCjU7DyyZodBro9XpeoFNWZom7nptx4LZf4jJUAwW7BgNgAixugBSTHcPb/lTSKd5z45sxt7rPUrAk1DvPXICz9+FeTD0xFYO3DWaOYeZ65ChzsOzSMmy7uw23c24L7gvgZ9x0el2Z1XBCZTV+H9Q6NWadnoVd93eZbMs9L27ZxSIxL7g0vpbWTiZsHBRzn5c3WPrr9l8AmBHoJx2bVOagnw/yHmDItiHYcXeHxe2EcAMkc+NwpRelY37UfNzJvWN2P7VxfCq1To1TSadMervWNxQsEVKHfdrtUxx98SjaebfjLf+wS2lbox4BPbAyciW+7PslbxuhX/C9AntVuCweMg+TZeZ66v0c/TPOp53nLdPoNPzgQGd6k+birucGS99c+kbwxmloRG4oZ5G6iNc43rihvPE+cor5A3AWa0uzGtwbhfHruM/j5fEYtXcUjiYcNSkfYFoNxs3GcPdzPrX02lkaaLSopPS6iCAqs4H3lYwrJsuMb9AH4g5g1/1dmHV6lsm23PeEGwBJRBLeuVjKGlrKZFnMLGnLFywZ+y/9P4vrF5xbgKTCJMyNmlvufZtr4L3j7g70+qsXLqdfxoxTM7Dt7ja8tPsls/upjcHSn9f/xPtH3seEQxNquihVioIlQuowqVgKTwdPk+XvdHgHx146honhE7Go9yI87v84/J39edsI3VxGthxpsuzZ0GctlsHwS1moUa6hLZOfI3+ogj+u/2GyrVqn5t1QjW+a+ap8AKUZMY1ew45qbdyzTaiRtyGzZHi9QqPg9faLSonibW8cTBr3tuIew1IDb24g8OnpTxGdGY3JxydDiPExf7v6W+l+OO8Xt42VuV/08hI5Pjr+Ea9cljJLaUVpiMnhZ9cA0/fBUjshbjWe8aCj3MyS8T6521oaEJPbnkmlVfGqiiszFQ6AMtvwVWaoCW6wxM0szY2ai0J1IaaemMpmCC0Fi7UxWNp5bycA4FrWtRouSdWiYImQesrH0QcTOk2Ar5Ov4Hqh7EugcyDeav8Wb5mDnQPvufEN3TAEgZvMNFiyFzOZpVndZ5lt12Sg0qos3lBzVbkAAB+H0pGLx+wfgyJ1kcmNTLA9zqObqbnMUlRKFJIKktjnxm1LNsRs4D0XarOk0WkQnRHN2y67OJt9bJyd4jL0IDO4mXUT++L2lZb/USByLfMa1txaY3Jsg3u59/Ag7wF+if4Ft7JLewCqdWqL4yylFaUJlsv4Bm0YtgIwDSC5++dOsCwRSXhtmIyPze0pZ2mwTO5AoiqNiq1KA8pfDWesrGCpMm2ayho6QK/XW9XwuzYGS5UZkbwuoWCJkAZKqAebv7M/Pgj/oMztuPo26QtAOLNkqIZ7IvgJrIhcgTZebXjr/3r6L7hIXQAwN17uzUCn1/Ge5ynzAMBkmgeFWsFrmwMwN860ojRMPDKRrbIyZC8MmTiFWmEyjtSRhCPsY+Ob2u4Hu3ntSYR6wy2/stxk9PJTyaesykpo9VrejYc7ACNQGmDsj9vPW87NahVrivHcrucwfOdwk3NT69QWM0vmbtbGmR5uZsk4wOLu/2D8QfaxRCzhVTGaZN84WbPyZJZ4+6hksORk52Rxva267ZsLLmoyWNLr9VbPG2msoUwM3DDOkhBi4tNun8LP0Q/Dwoaxy7wcvEwaZBvfJLhf2JMfm4w5PeYAsBwsGRimcjFwt3dnx4wynjrF+NhsZsmJHyypdWq2is6gRFuC9bfW42TSSbxz8B1eoGCohlNqlbifdx8A2DZfmYpMdh9CjeXTi0oDGKHM0qobq0xeAzBBRVpRGpIKkwTXA0wAwb3xGN8YDQGG2OhrmxtAfHb2M/ax8c1PrVPzAgrjkdnN9SI0Lgc38DMOlsxVhUlEEjzIf2B2O2vbLHEzS9ZkE8ujrF5qlcosWTH6ujVBR1UNSjkvah4iNkSw/x/KozaPb2VLFCwR0kC18mqFIy8dwcJeCzGyxUhMe3ya4BdfibaEbTA+u9ts3rq327/NBkleDl4mrzXOShlXdbjJ3ODtYD5YUmvVuJl1EwO2DMBP0T8B4FfDAUyj5Bwlv3qrRFfCCwZSC1PZx9yG6IZjhvuFA2ACsnxVPuLl8YI3fu4NLaUwhX18NvUs0orS2GpHYyXaEvxw5QfBdQaWevtx14vF/K9tbjXcvw/+5R2TS63lV8OZZGbMNJA2Lgc3k2Ups8QlgogXKJpUw3HbLFlq4M0JDA3Bs7l9lldZEzVXptu+q6x0mA7jam2DmszQGKYKWnljZblf21Cq4WgEb0IaOLFIjPk95/OWrRm8BqP3jwbA/GIf234shoUNg5+TH5ZcWCJ4Q2vh2cJkmfFIzca/sF3tXU0yS452jtDqtCjRlSBHmYPvL3/PaxsT6hHK28eMUzNMjqvWqnmNvr/67yv2sbPUGXYiO/bm6GjniJaeLQEAucpcvLT7JaQUpUAI94ZmPETBsH+GwcvRS7Dtj3HPLSEanYZ34zHXG9A4A1KgZoIl48wHt7eeYf/c9824EbzQHICAaWaJe13TFEbBkpkqNEMQypZFb77NkqVqOG51q6Fa1qCyveHKCrbKm1nS6DSYFzUPXfy6WAxSDYwzhjWhItk5qoYjhDRY3FHDS7QlEIlE7OS75oYDEAqWjG8wxu1oxCIxm1kyZGpkEhnbKD2zOJMXcAU6B+LZMMu98wDTqrnjicfZx1KxlFcd2NStKTt1yqnkU2YDJQBYfH4xitRF0Ol1JkMNFGuKBbNrhvKURaPnV8NxG0gDnMyS0c3J0HbKOAAxDobUOjUvIDC+aZsb6+iTE5/wnlvKLJnLznCrLwGBQFBrWg2Xo8zBL1d/4R2DOxRCfgm/6tXSNV56YSlmnpppMeARen1sTiyuZ14HwA8ahQKrEm0J5p6Zi8PxhwEAh+MPY9f9XZh/dj4vSL2VfYvX8N7AOGMotP+qVpHsHAVLhBAC0+CI2xuKq4VHC4zrMA6fdC29uQoNaGhg6HVnyCwZgiUHOwc2MMtQZMDF3oV9zZoha0ymyhCi1qlNqmkAJlAynuqlk28neDh4lLlPgBmLqfvG7nj30LuCmSJDuY2VNf0M8CizxKkGvZxx2WQ9YJpZMuzbOLMi1GaJl1nilCk2JxZTT0wVLFeBugCZikz8HP0z7ube5bUVyirOQqI8kX3vzGWFjNsXWewN92jdp6c+xc/RP2P8ofHsOm6gZtwL0FywpNFpsD5mPfY82GNx0mnj1+v0Oryw+wW8tvc13My6ybt2Qu/9ptubsOPeDnZYCO7kysbX5fNzn5u8vqw2U6lFqbznVdHYu7LZuVyl6f+5+oKCJUKIoNndZiPUPdRkbjeZnXDvOJFIhEldJuHNdm+yy4x/yc/tMRdeDl4Y12EcJndhbiqGYMnQpsVB4gBfRyazdDPrJvY9ZLrPf9rtU5Oxorgc7RzR3KM5ACAuPw5XM6+abGMItLjBUs/Anmjs0tjsfoUY5rczZu5mY02wpNapLbb/MAQRxu3K2GDJ6GafWZzJe67Wqc1OC/PyHv48g8ae+PsJ/HL1F7yw+wVe4JOpyMTQHUMRuS3SZIRwLm7DbO65GAi1WTqTwszl9zD/IRadWwR5iZxXfrlKztuHuWDJ0mCYlsrEvT6v/PsK770VCpaMqyS5wU9Zo9EDZbf9SS7gt+lT69RILUzFm/vexMG4g7x1Wp22Qg3Sjatic5Q5vCEfhHAzS1OOTyn3MesKarNECBH0cuuX8XJr05toB58OZsfkMWZ8k+gW0A0nXj7BW2aohjNkCmQSGRtArbpZ2rsswDnA4rG2PrsVH5/4GADMjrJsyJJxfwFH+EfAxd4FI1uMtDgXnDUMNxsHiQOvt5w1VSjGmSWh9YCFzFIZVX1qnRrZytIxnyyNaWWOTq/jBUvcKsvojGizw0wYDxpqXF3HDR6EslObYjchW5nNyyxxMzfG++DinqchG3MswXTeQ+PXG89ll1FcOjWOULBkHJxwgwjjcxKqriyrOov73gFMYL74/GJcybiCKxlXcD2EqS6MzYnF2INj4W7vjh3Dd5itNhdi/Dntt7kfAGD/yP1mf1Bwg7yyRkGvyyizRAgpl9ndZ2Nki5HYOHRjmdta09XZEBgZOEudBSf5berW1Ow+PGWeCHYLNhn2wJihtxr3xmOo5vtf5/+VWVYhhnGmgNKbzdgO/MmDrQmWFBqFxeyC0GTDADP1yWdnPyuzCmXW6Vn4/drv7HNDm6byVueYGzNq9P7RZtsslVUNxx2J21zgdij+EO/zZBwsmQsWuYGN4fEnJz8x2c5k7j8L2cBX9rxiEhxxy6bT63gBu3HGpqyelnsf7DVZb1yehIIEwarm86nnka/KR0JBgknVXVnMXUNDuy0h1GaJEEIEeDl4YX7P+ejg26HMbS1VmxkYMksGjZwbmYzZ1NqrNZq5N2Ofv9WOP8q4oerPXNd9A0MwZWhb1KdxH3adj6MPngl9pszycskkMszvMZ99bqj6a+fdDmdePYMBQQMAWFcNl1aYZjG41Og0yFXmst28ubbe2WrVMbgM2xtnfcpiaYBNc22WjKvhjiUe421rPG2JcSAkxKQazkywyM0QGbJMxr00Dcc19zpjhepCk0CFGzwZN+A2zkQZXyeRSMQLOqafmm5yTOP319zEv9weg+V9b80G9TYeHUCj02DH3R14a/9beP/w+7VyZHJjFCwRQmzul0G/4J0O72BIyJAytzWegNffyd8kWIoMieQ9n9KV3zZiTLsxAJiRoi0xtFla/sRyvNzqZSzps4S3ftrj09CvST909O3ILgtyDTK7P3uJvWA1h73EHm72bmxjeGsySylFKRbb1JxPO4++m/uarQLNU+WVeQyudEU6vr30La9qyxoWgyUzWSGh1xjm9RPax7eXvi2zHIYhEwysabNUrC6GRqcRLI9JsKQ1HywBpu8p94ZvfB2Mgxah62ScoTE+H+PjGQeL/z74F3q9HlfSSydDNg5Sy8I9Jvd8LGU8K5JZ2hy7GXOj5uK/9P9wKvkUOy9ebUbBEiHE5no37o0Pu3xYZvACmA5UWaQuMqmGszT2DlCaKYjLj7O4nSGz1M67HWZ3n82O5m3g6eCJHwf+iBHNR7DL3u34rtn9ySQys8ES919zWZ8v+36Jzn6dATC9nSozsOKK6yvK/ZqVN1aWe4JYS9ubK79QhsNwYzZ+b7U6rWDXegPDMA/GzI0Txc3qXM+6juVXlgtuV57MkvF+AX41nPGYSWU1cAdMgw6TyaGNPkMKjYJ3zBmnZuBs6lmcTT3LLivve2tuaAlLwZKlddxsW1RyFHbd3wUAuJh2kbddZSYpri4ULBFCapRxo+YXW71oEixZyu5wGY/kbczRztGq/XAzW0+FPGV2O5lEJlj1Z1hmaPBsPF+cQYBzAJs1Sy2sXLB0POl4hV5n3AW/LJYag5srv+Fm2MWvdPwuQ2bIOIPzyclPeHPwGTNu42ZQrGaCl6SCJMw9MxcP8pjpVbjBwx/X/zA7JU152iwBpgEQb15Do9G+jQOrzOJMk2tl3HDfOONnyCwZPlNCASh3BHehMgLM+23ufeJNh2PluE7G/3/v5N7Bjrs7UFhSiBE7R+C9w+8BAN49/C5mnZ6FuPw4k+E/KjovXXWqc8GSSqVCeHg4RCIRoqOjzW4XFxcHkUgk+Pf333+z2wmt37RpUzWcCSHEmFgkRmuv1ryxlVp6trQYsHCV1SPM3KCRxrjBmlQsNTsjvUanEcyeGTJKhmzH8cTjgjc3BzsHBDoHAjBfDfdV369MltlSdnF22RsJELqW5m6whuvg4+iD/k36AyidukToRmkpaDQOlsLcwwCUNviecnwKdtzbwY5A/+f1Py2dBu+Y+ap8dj9lZpbU5jNLZTW21+l1iMmOsbgNN9ui0+vwx/U/AJRWWx9NPGqyD+Msp3EZMxWZ6PlXT7x94G3BY3IzQdzzt9SmyDhYGrlrJOZGzcXEIxPxIP8BTief5n32c5Q5Jm3Gyhuw14Q6FyxNmzYNgYGBZW4XFBSE1NRU3t9nn30GFxcXDBnCb0exatUq3nYjRoyootITQixp5NQIADNSt+ELdd2QdYINcivCuH2UOf5OpQ3TJSIJWy5j6Yp0weWGmxZ3YlJu13MDmUSGQBfm++xW9i2T7uGA+Uby5W2Mbo7QMcviZu8mOIiiYYoVcwMsyiQyNhC2FCxZYtwhwNDw33DDjclhAojytuEqVBei96be6P1Xb+j0ujLbLJlUw3ECDWuyMoZyGhgH+twA40DcAfaxp4On2dcYD91gnFkyNAq/knEFT29/Greyb/HKzQ34uOfw5/U/sfv+bt5+DGM7mauG4w6q+lBeOlaTVCw1+f9s/F6dTz2PD49+aDLye02qU8HSvn37cPDgQXz99ddlbiuRSODv78/727FjB1566SW4uLjwtvXw8OBt5+AgPEIxIaRqGdpteDp4YvMzm3Fw5EHe1CRCuCn9J5s+aXFba6u5Qj1C8b/w/2F2t9kQiURY1n8ZIvwjrHotUFoNxy27UAbHQeKAAJfS8aOiUqLYxx93/Rhzus8xG+BZW01iyFxxrRuyjn3MnXcPgMkgpEK6B3QXHBPKMByBuQDPXmIPFynz/VugLoBOryt3sMQNFgCwwaYhI8T9PMyPmm/1fk8nnwbABAzFmmKTariBwQN5z4VGSDcw17A6xC2EfWxc1Wj82eRWwyUWJLKPLQX8xkGqcTaT+5lJKEjA9JPTedWq3GCJN8J7biw+Pf0p+35NOT4FU09MxZ3cO1Y18DZUiQJM+0LjYIk7NREAvHPwHRxNPCo40nlNqTPBUnp6OsaNG4d169bBycnyl6eQS5cuITo6GmPHjjVZN3HiRPj4+CAiIgIrV64sc+RTlUoFuVzO+yOEVFwTlyYA+Deklp4teYGEsT+e+gPNPZpjRWRpw+aFvRby2sUYK8+N+d1O77KDcoZ5hPGOUxZDQ/KZETPZZULtqWR2MrjZu5ncPOb1mIfR7UbjpVYvmR3o0VyDZmOvtXkNqyJL2+mIRWKE+4WzQcv51PO87a0Z7qGjb0fBm6QhG2MpWDJUca67tQ49/+qJM8lnrDoPA0O5DQyDlQoFSxUdZLRIXWRSDffdgO9479O0k9N4N3lD42XA/Ofs+ye+x6LeiwCAV4Wm1WnZqVgMx+BWw3HPyThY5DLuKbnlzhbec+NsWb4qnxekce99Qm225Co5r1wnEk+UOfI4AN4o4CKRyGRC7QyFadYVMJ+5rQl1IljS6/UYM2YMJkyYgK5du1ZoHytWrECbNm3Qs2dP3vIFCxZgy5YtOHToEEaOHIn3338fP/zwg8V9LVmyBO7u7uxfUJB1jU8JIcJWDV6F2d1ml2tgyO4B3bFj+A62NxnA9Kz7aeBPaO/dHh90/gCf9fyM95qhzYbarMyWGG7oYR5hJhMMc+ePMwwtsGv4Lt423JuyuellDAEmAAwKHmS2LI52jujqX/q9aTimIQgznoPOXPssLl9HX8GbpCHAMDfeFbcarlhTjCJ1EZZdWmbxWMaBl3HjfzZYetSVvqyBSa2hUCsE2yy18mzFPtbqteykucZZIuMA1MBOZIcWHszn4VZOaY8/7phN7vbubBkMuMGSk535ZMHBeP60J2lFabzAzTgbqYcemQr+tDgGQtmxHFUOrx1UobrQ4qjzBtzspVDPVm7mjKus+fKqU40GSzNmzDDbCNvwd/v2bfzwww8oKCjAzJkzy96pgOLiYmzcuFEwqzRnzhz06tULnTt3xvTp0zFt2jR89ZXlBpUzZ85Efn4++5eYKPxGE0Ks4+/sj5dbv2x1bzVLXOxd8Nczf2F8x/F4vsXzOPfaORx58QhWRa4qs5quLGPbm36HCHGwK63Kd5Xyb+4/D/yZfWwIWILcgtDSsyW7nBssCU1c3Na7LSZ0moCjLx7FoRcOWcwGGd9wDNeYW0YuZ7uygyUfRx/BYOla5jXmmGIJQt1DTdZzq+Gs0cm3E2ZEzOAtM8ksuZjPLFVUkaZIMLPydT9+ExBDOynjoQ523t8puF+ZRIZQj1CIRWKzVcKGYJBbDccNSKypfn0//H32MTcYEhru4PW9r/OeG0w9bjqxck5xDi+IUmlVVmWWuO3iNHqNSVsrs8GSFUOPVJcaDZamTp2KmJgYi3+hoaE4evQozp49C5lMBjs7OzRvzkyW2bVrV4wePbrM42zduhUKhQJvvvlmmdt269YNSUlJUKnMdxuVyWRwc3Pj/RFCaidnqTP8nPzQ1b+rVb+CLfnosY9w7rVzmNR5EgCgayMmY8Nti2KM27PPTmyHFp4t8E2/b/DTwJ94N4NXWr9Suh2nmkJoHKdv+38Ld5k7fJ184e/sb7FqxrirvyFYMle9V1YbMeBRsCRwLY8mHmXLv3bIWvz+5O+89a5SV8GpbMwZ0myISfDjbF8azIkgYjN1hepCaHXaMnuxCfmoy0e85wq1QrCBdxPXJux7DwB7H+7FL9G/WBzqgMvLwQsyicziPIeGXobc6i5u4GZNNWmIWwg7PRC3Ksu4IbVer+dltfR6PTQ6DT448oHgVCrfXv6WF3ApNUqr/k/lFJdWQQs1nk8tSmXHSDubUjrUQ23KLNXoRLq+vr7w9fUtc7vly5fj889LG3qlpKQgMjISmzdvRrdu3cp8/YoVKzBs2DCrjhUdHQ1PT0/IZMJfJISQhs1Z6oy32r+FNt5t0Mm3EwBg8zOb0W2j8HcRNxPi5+gHsUgsOBTCiOYjcC7lHM6nnUdb77bscqGegMaBjqVGv8bBgyGjZClYkoqlFodh8Hb0tphRkIglcJe5o0dgDyzouYCdJ62pW9Ny9Wxs7NLYZIwt7vV0ljqz1VYAsC9uX7lHJAeA4c2H43rWdRxJOALAtBruiaAn2MdjO4zF5YzLOJ18GjE5MYjJibEqI+pm78ZWEfo6+iK5MFlwu/Y+7XE54zKvGo5bFo1Og3k95uGzs58JvRzNPZpjUNNB2BK7BfHyeGQqMlGsKYaDxMGkbZDxZ0Oj0+Bk0kmzY3Zdy7xmklkqq40vANzIvsE7hlB27GjiUbRXtMf4Q+PZZbbIEtpKjQZL1goODuY9N/RmCwsLQ5MmTL198v/bu/eoKOv8D+DvZxgYZsAZbnITEBAFRC0ERcQ0hQK1vKZppLj1y6NportabWaWrZetzbX2mOXuaqeT6WbHW2V5TEvT9Z54SSM9tWuropUp4BWY7+8PmsfnmcvDxWEG9P06h3Nmnuc7z3znO8jz8Xv5fE+fRm5uLt599110735z1crJkyexfft2bNzouDHhRx99hHPnzqFHjx7w9/fH5s2bMW/ePEyfPr0JPw0RtXR6nR692vSSn5t8TTDpTU7neSjzAt0dfrfLa/rqfPHava/BKqx1rjCyvznbL6d/IfsFzNk1B4DjRF3bnBeXw3C+AdDr9KpgKTcuFyXnS+ThFIvBotmjoOwR6BByc3ixrbltvfZ9W5a/DN/8/A36xPRxeB/lDbSyqhK+Pr4w6o24Wn0Vf/yq7qkao1NGY2zHsdh6aite3V875UIv6fFan9eQ9X4Wrtdcx5XqK3K7RQVE4U+9bv5nXSfp0KV1F3n1HFC/hQPKvFRhxjCnZcZ2HCvPGVMGfcqgJj08XXMbk2kZ0+Cr85V73Hae2YmZO2bigXYPOGys62yD37qyadv2PwRqf7e0kpQ6UyNqnA5xOtvihsNwTaCqqgqlpaW4ckX9S7Rs2TLExMTg/vsd/yfn6+uLxYsXIzs7G3fffTfefvttLFy4ELNnz/ZUtYnoNuHqD7uyV2JQu0F1Xqc+S7Hte4WUE7j/fM+fMaLDCPm5/Y28zmE4vclhtdKivoswrP0wAECXsNp984a3H+6yfsq2SApKgq+uNqCJbRVbrzlL3SK7YVyncXKgpOxpc9bb0JChvcoblYhpFePQe+ej80HnsNrNoefsmiMHKA8nP+xwfVeTrO2H85SUwZKrLOT+en85WLpcdRk11hr8eu1X+TtMCUnBvbH3ugx0le9ja+cdp3egWlRj3cl1LucG2VSLas30GgYfA94suTnn7mr11YYHS9YafPtL/faCc1d+NXdoPjVpgPj4eIeuP2fHAGDevHmYN2+e0+sUFBSgoKCgSepIRHeWwe0G473j78k3XJuMiAxMz5yOEP8Q5LTJadS1+8X2k+cDAY6BmcVgwUs9X8Lhnw7jvnj1JHb7/8Xberdc3XBNviZ0i+ymej8A+L/O/4c4c5ycgbsorQiLvl5UZ90NPgZsGl6bVNHXx1c1h0tVr9Z3o+SnEjyS8ojDOWWApOxpsg2Dmv3MDkNMw9oPw5oTaxyuZUsOqpzMbGtP28rAyqpKeV6Ns3ZyNa8rp00Odpzegf3n9jucUwZIroIlo94oB0tXqq5g7Gdj5UnzAFAQXwBJkpxO+pev/Vsvo20VZUPSZVTVVGlOILf/Xbpec73OfRvt/XDpB6cJWp3xkXxQeqEUr+5/FU+lPyV/397QIoMlIqLmprhrMVJDU5ETrQ6IJElCUVrdC1G0LOq7CH0/6KuZbXtY+2Fy7w8A9Inpg23/24bhHWp7gD544AN8+b8v8Vin2q0u7IfyZmbNhL/eHwYfA17q+RK2/ksdLJl8TaoNhvU6PbY9vA19/tXHoS72c6ham27OF3XVC/Rqn1fxv4r/Ob0hKnsYlD0ftvxRyr38bB5JeQS7z+zGmctnVMcv33AcZrJdf0r6FDkAtCXYdBaYuOpZCjIEuUz1oOpZ8nfRs+Rzs2fpl2u/4MjPR1TnbUNzWj0utsn+tp7DhgRL1aJaNbHbqDfiTzl/woztM5xueXK9+rrmVijOnLx4st5l9To9Jn4+ET9d/QkHzh3AwTEHG/Re7nTbDMMREXmTv94fg9oNctlrcCskSapz3zt7b/R7AztH75SX8KeGpmLiXRPlm6gyn5Jep8eolFFyMBTkHySnSXii8xMu38PZ/nAPJD6A4q7FLl/jbJgPqJ30nBmZ6TRPkjI46BreFUOThuL5rOflss6CJQD4R/4/kBqSijk95+C5rOdg1Bsxo9sMAOoEjLb6PNjuQQC1PRq2niVnwY+rCd1BhiCXvT6u5iyN7DBSfqwchlNulWPT2lgbdLoaqjXqjXJPmLNVlEDtUOH6wevxhwzH1AAAsLhksfw40DcQ98ffj/2POvaUAbVJLqtFwzZ//vWaepVdj6geLsse++UYfrpam/rgVjaZdgf2LBERtQAN3WxUJ+lcBhGAOp+Ss/lLxV2LMShpEBLMCfV+z9SQVMy/Z75mGUmSkBCUgBO/nlAd15rMqwyWfHQ+mJMzR3U+zKSeMP1w8sPoENwBkiThgwdvZrEe2WGk0/exDe3ZhvtqRI28Gs1Z8ONsno7FYJF75pxxNWcpIyJDzrQtIG4OwzmZxG2bi5YRkeH0PZS9dq7q0aV1FyQGJWJf2T6n55VsQ6a+Ol9IkFRDl0DtMJyzwFeLLX3BfW3vw+OdHkf74PZ499i7eP3r1x3Kulox6A3sWSIiagFse6C5yo7dUMqeJWc3VkmSkGhJbFBuqvou9c6KrDvli1LHkI6a55VZ0QHg+R7PO623MlCyv/ED6t6Yiqra4NTZnKWe0T0djtkyqruaC+aqZ6lNqzby4ytVV1xmUDfqjXJPmk7SOU2QqgyOnX2nAb4BSAtN06ynkjKhqrP2qmuCt3IPQhvbtj8WgwVpYWnw8/FDsMF1nrDmgsESEVEL8Hrf19GrTS+8N+A9t1xPOUn5VvLZKG/89V29NKXrFNV2LYv6LtIsP77LeDze6XG8P+B9p+ddzQHSYp+/CVAHorb9zFwFHYfGHlJdo01gG5flAddzlpQ9VzWipl7bzQDOh+KUKw3t6/FYp8ewcdhG+XuvT7Dkaq6d7Xu+Vn1NDpbsv/vUkFTcHX63Q8+crWdJ2Qvm7LtobhgsERG1AMkhyViStwSpoaluuV5dPUv1pew9SApKqtdrjHojnst6Tn7eIaiDRunaG/vUjKno3Lqz0/ONWWIeHRiNZfnLsGbQzRVzzq7jag6STtJhXNo4+bktY7ar8qo9AfX+6BvbF53DOqNdUDs80fkJxJvjMbz98HoHS6NTRiMqIAqjkm9mflfOpbL/Tv31/qqAra5Emh8++KHL7YESLYnQS3qU3yiX0xHYB9zL8pcBAP7c+8+q47ZgSdkL1i2yG17OeRnrh6zH5w99jqFJQzXr5g0MloiI7kDKXohTFacafZ2YVjF4p+AdjOgwAlMzptb7dcohMVfpBOqrsXv+dYvsptro2NnQXZB/kMvXp4Wl3Xz82/CWq9Vw9kOFb/R7AysGrIBep8eUrlPw0dCPYDFYXAZLfWP7qp63NrXGpuGbMC1jmnxM2VtkP8G7qka9QKCuYCk5JNnlEGxkQKQqtxegXnWXaEmUv9N+cf3wydBPkBqiDvKVQ3ySJGFI0hAkWhIRERCBTmGdNOvmDZzgTUR0B3K26qyxMiIyXE46dkV5877VYKmVXyvsGLUDM7bNwKCkuhN/1pez7VaUkoOT5czt6RHpAFz3LDkb9nIWjNjPSSvqWIQwYxiGdRjmUFaSJFUP0qXrl+TH9j1L9qvJtHI11SXANwCxrWKx++xup+ftczXFmeMcft+09jN0NSxcZa3y2hYoDJaIiO5ADV3F5G7KzVTdcQO0GCxYev/Sugs2QF0BoF6nx/oh63G95ro8xGUxWDRfUxf7AKq1qbVmni5lD50yILIPlvIT8lXPlcFbXXsB2gv0DXTYDHhWj1l4effLAJynLbAP1pylnbCxX7EYYYpAUnASqmq8FyxxGI6I6A6U0yYHg9oNgklvwtt5b3v8/VNCUjz+ng1Vnw1yIwMi5flKgLrHZHC7wciMyMSL2S82ug5xreLqLLM4dzESLYlyDilAHSyN7DBSHia0UQZL9kOEi3MXw55tDpLt2rbVmUBt7qyRyTfzRTnb0sY+WNLKR2YfyH/44Id4K+8tl5nTPYE9S0REdyC9To+5veZibq+5Xnn/tua2WPXAqkatZPMU5YbA9aXsMQkxhqg24W2Me2PvrbNM75je6B3TW3VMGSwp52XZKAPBh5MfxsIDCwEAc3rOcbgWAFVmdb1Oj+TgZPm5LSdUz+ie+PeZf2Ns2liH199Kz5KreWCexGCJiIi8wr63o7lpSI4pG2XOIK2koPUxPXN6o+oAqIMhZS+QjXLOUveo7lh07yIcu3AMg5MGO72ecvjLR/JBnDkOwYZg1fYoC+9diBO/nnC6ZY39MJ9W29j3LN3Kak13YbBERETkhIRGBEuKYbiOodrJNF351wP/ws7TO/FIquOmwvWVYEnAqORRCDWG4p429zicD/QLRP+E/hBCIDUkFWmhachtm+vyesqgzdbz827/dzHty2lyZvEA3wB5o2Z7ymDpvrb3aQaB9luouNrexZMYLBEREbmJ2c+Mtua2qLxRifTw9EZdo2Nox0YHWjaSJGFmj5maZV7p/Uqjrm3r+Ym3xGPt4LX1eo1yGO61Pq9plrVfTdccMFgiIiJyojFDYJIk4YMHavd6q88E8ZaoMUlAlcFSXe3a0E2jPcH7fVtERETNUEZ4w3JH2Zh8TV5dudVURnQYgVD/UDzU4aEGv9Z+greW6zXXG3z9psZgiYiI6Dd/6fMXhJvC8XS3p9Evrp+3q9OsvJD9AraM2KKZUNKVhvQWNce94jgMR0RE9Jv8+Hzkx+fXXfAOZb+sv74a0rOUE52DqIAonL18tlHv1RQYLBEREVGT8tf743LV5XqVlSQJHw/9GEsPL8U9MY4r+byBw3BERETUpN7MfRMxgTFOs4M74+fjh8npk53mbPIGSQghvF2Jlq68vBwWiwWXLl2C2XxrSciIiIjIM+p7/2bPEhEREZEGBktEREREGhgsEREREWlgsERERESkgcESERERkQYGS0REREQaGCwRERERaWCwRERERKSBwRIRERGRBgZLRERERBoYLBERERFpYLBEREREpIHBEhEREZEGBktEREREGvTersDtQAgBACgvL/dyTYiIiKi+bPdt233cFQZLblBRUQEAiI2N9XJNiIiIqKEqKipgsVhcnpdEXeEU1clqteLMmTNo1aoVJEly23XLy8sRGxuLH3/8EWaz2W3XJTW2s+ewrT2D7ewZbGfPaMp2FkKgoqIC0dHR0Olcz0xiz5Ib6HQ6xMTENNn1zWYz/yF6ANvZc9jWnsF29gy2s2c0VTtr9SjZcII3ERERkQYGS0REREQaGCw1YwaDAbNnz4bBYPB2VW5rbGfPYVt7BtvZM9jOntEc2pkTvImIiIg0sGeJiIiISAODJSIiIiINDJaIiIiINDBYIiIiItLAYKkZW7x4MeLj4+Hv74+srCzs3bvX21VqMebPn49u3bqhVatWCA8Px5AhQ1BaWqoqc+3aNUyaNAmhoaEIDAzE8OHDce7cOVWZU6dOYeDAgTCZTAgPD8eMGTNQXV3tyY/SoixYsACSJGHq1KnyMbaz+5w+fRqPPvooQkNDYTQa0blzZ+zfv18+L4TACy+8gKioKBiNRuTl5eHEiROqa1y4cAGFhYUwm80ICgrC448/jsrKSk9/lGarpqYGs2bNQkJCAoxGI9q1a4eXX35ZtXcY27nhtm/fjgcffBDR0dGQJAnr1q1TnXdXmx4+fBj33HMP/P39ERsbi1deecU9H0BQs7Rq1Srh5+cnli1bJr755hvxxBNPiKCgIHHu3DlvV61FyM/PF8uXLxdHjx4VJSUlYsCAASIuLk5UVlbKZSZMmCBiY2PFli1bxP79+0WPHj1Ez5495fPV1dWiU6dOIi8vTxw8eFBs3LhRhIWFiT/+8Y/e+EjN3t69e0V8fLzo0qWLKC4ulo+znd3jwoULom3btmLcuHFiz5494vvvvxebNm0SJ0+elMssWLBAWCwWsW7dOnHo0CExaNAgkZCQIK5evSqXKSgoEHfddZfYvXu3+Oqrr0RSUpIYPXq0Nz5SszR37lwRGhoqPv74Y/HDDz+I1atXi8DAQPH666/LZdjODbdx40Yxc+ZMsWbNGgFArF27VnXeHW166dIlERERIQoLC8XRo0fFypUrhdFoFG+//fYt15/BUjPVvXt3MWnSJPl5TU2NiI6OFvPnz/dirVqu8+fPCwBi27ZtQgghLl68KHx9fcXq1avlMsePHxcAxK5du4QQtf+4dTqdKCsrk8ssWbJEmM1mcf36dc9+gGauoqJCtG/fXmzevFn06dNHDpbYzu7zzDPPiF69erk8b7VaRWRkpHj11VflYxcvXhQGg0GsXLlSCCHEsWPHBACxb98+ucynn34qJEkSp0+fbrrKtyADBw4Ujz32mOrYsGHDRGFhoRCC7ewO9sGSu9r0zTffFMHBwaq/G88884xITk6+5TpzGK4ZunHjBg4cOIC8vDz5mE6nQ15eHnbt2uXFmrVcly5dAgCEhIQAAA4cOICqqipVG6ekpCAuLk5u4127dqFz586IiIiQy+Tn56O8vBzffPONB2vf/E2aNAkDBw5UtSfAdnanDRs2IDMzEyNGjEB4eDjS09Px97//XT7/ww8/oKysTNXWFosFWVlZqrYOCgpCZmamXCYvLw86nQ579uzx3Idpxnr27IktW7bgu+++AwAcOnQIO3bsQP/+/QGwnZuCu9p0165d6N27N/z8/OQy+fn5KC0txa+//npLdeRGus3Qzz//jJqaGtXNAwAiIiLw7bffeqlWLZfVasXUqVORk5ODTp06AQDKysrg5+eHoKAgVdmIiAiUlZXJZZx9B7ZzVGvVqlX4+uuvsW/fPodzbGf3+f7777FkyRL8/ve/x3PPPYd9+/ZhypQp8PPzQ1FRkdxWztpS2dbh4eGq83q9HiEhIWzr3zz77LMoLy9HSkoKfHx8UFNTg7lz56KwsBAA2M5NwF1tWlZWhoSEBIdr2M4FBwc3uo4Mlui2N2nSJBw9ehQ7duzwdlVuOz/++COKi4uxefNm+Pv7e7s6tzWr1YrMzEzMmzcPAJCeno6jR4/irbfeQlFRkZdrd/v44IMPsGLFCrz//vtIS0tDSUkJpk6diujoaLbzHYzDcM1QWFgYfHx8HFYMnTt3DpGRkV6qVcs0efJkfPzxx/jiiy8QExMjH4+MjMSNGzdw8eJFVXllG0dGRjr9DmznqHaY7fz58+jatSv0ej30ej22bduGN954A3q9HhEREWxnN4mKikLHjh1Vx1JTU3Hq1CkAN9tK6+9GZGQkzp8/rzpfXV2NCxcusK1/M2PGDDz77LMYNWoUOnfujDFjxmDatGmYP38+ALZzU3BXmzbl3xIGS82Qn58fMjIysGXLFvmY1WrFli1bkJ2d7cWatRxCCEyePBlr167F1q1bHbpmMzIy4Ovrq2rj0tJSnDp1Sm7j7OxsHDlyRPUPdPPmzTCbzQ43rTtVbm4ujhw5gpKSEvknMzMThYWF8mO2s3vk5OQ4pL/47rvv0LZtWwBAQkICIiMjVW1dXl6OPXv2qNr64sWLOHDggFxm69atsFqtyMrK8sCnaP6uXLkCnU59a/Tx8YHVagXAdm4K7mrT7OxsbN++HVVVVXKZzZs3Izk5+ZaG4AAwdUBztWrVKmEwGMQ777wjjh07JsaPHy+CgoJUK4bItYkTJwqLxSK+/PJLcfbsWfnnypUrcpkJEyaIuLg4sXXrVrF//36RnZ0tsrOz5fO2Je3333+/KCkpEZ999plo3bo1l7TXQbkaTgi2s7vs3btX6PV6MXfuXHHixAmxYsUKYTKZxHvvvSeXWbBggQgKChLr168Xhw8fFoMHD3a6/Do9PV3s2bNH7NixQ7Rv3/6OXtJur6ioSLRp00ZOHbBmzRoRFhYmnn76abkM27nhKioqxMGDB8XBgwcFALFw4UJx8OBB8d///lcI4Z42vXjxooiIiBBjxowRR48eFatWrRImk4mpA253f/vb30RcXJzw8/MT3bt3F7t37/Z2lVoMAE5/li9fLpe5evWqePLJJ0VwcLAwmUxi6NCh4uzZs6rr/Oc//xH9+/cXRqNRhIWFiT/84Q+iqqrKw5+mZbEPltjO7vPRRx+JTp06CYPBIFJSUsTSpUtV561Wq5g1a5aIiIgQBoNB5ObmitLSUlWZX375RYwePVoEBgYKs9ksfve734mKigpPfoxmrby8XBQXF4u4uDjh7+8vEhMTxcyZM1XL0dnODffFF184/ZtcVFQkhHBfmx46dEj06tVLGAwG0aZNG7FgwQK31F8SQpGWlIiIiIhUOGeJiIiISAODJSIiIiINDJaIiIiINDBYIiIiItLAYImIiIhIA4MlIiIiIg0MloiIiIg0MFgiIiIi0sBgiYioCUiShHXr1nm7GkTkBgyWiOi2M27cOEiS5PBTUFDg7aoRUQuk93YFiIiaQkFBAZYvX646ZjAYvFQbImrJ2LNERLclg8GAyMhI1U9wcDCA2iGyJUuWoH///jAajUhMTMSHH36oev2RI0fQr18/GI1GhIaGYvz48aisrFSVWbZsGdLS0mAwGBAVFYXJkyerzv/8888YOnQoTCYT2rdvjw0bNjTthyaiJsFgiYjuSLNmzcLw4cNx6NAhFBYWYtSoUTh+/DgA4PLly8jPz0dwcDD27duH1atX4/PPP1cFQ0uWLMGkSZMwfvx4HDlyBBs2bEBSUpLqPV566SWMHDkShw8fxoABA1BYWIgLFy549HMSkRsIIqLbTFFRkfDx8REBAQGqn7lz5wohhAAgJkyYoHpNVlaWmDhxohBCiKVLl4rg4GBRWVkpn//kk0+ETqcTZWVlQgghoqOjxcyZM13WAYB4/vnn5eeVlZUCgPj000/d9jmJyDM4Z4mIbkt9+/bFkiVLVMdCQkLkx9nZ2apz2dnZKCkpAQAcP34cd911FwICAuTzOTk5sFqtKC0thSRJOHPmDHJzczXr0KVLF/lxQEAAzGYzzp8/39iPRERewmCJiG5LAQEBDsNi7mI0GutVztfXV/VckiRYrdamqBIRNSHOWSKiO9Lu3bsdnqempgIAUlNTcejQIVy+fFk+v3PnTuh0OiQnJ6NVq1aIj4/Hli1bPFpnIvIO9iwR0W3p+vXrKCsrUx3T6/UICwsDAKxevRqZmZno1asXVqxYgb179+Kf//wnAKCwsBCzZ89GUVERXnzxRfz000946qmnMGbMGERERAAAXnzxRUyYMAHh4eHo378/KioqsHPnTjz11FOe/aBE1OQYLBHRbemzzz5DVFSU6lhycjK+/fZbALUr1VatWoUnn3wSUVFRWLlyJTp27AgAMJlM2LRpE4qLi9GtWzeYTCYMHz4cCxculK9VVFSEa9eu4a9//SumT5+OsLAwPPTQQ577gETkMZIQQni7EkREniRJEtauXYshQ4Z4uypE1AJwzhIRERGRBgZLRERERBo4Z4mI7jicfUBEDcGeJSIiIiINDJaIiIiINDBYIiIiItLAYImIiIhIA4MlIiIiIg0MloiIiIg0MFgiIiIi0sBgiYiIiEjD/wPDYG3MknQKTQAAAABJRU5ErkJggg=="
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.log(total_train_losses), label='Total')\n",
    "plt.plot(np.log(edge_train_losses),  label='Edge')\n",
    "plt.plot(np.log(node_train_losses),  label='Node')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss function')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-18T14:49:40.218954782Z",
     "start_time": "2024-03-18T14:49:40.143267694Z"
    }
   },
   "id": "921aa5cf0aef59a3",
   "execution_count": 76
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Test of the model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "aeebf15173f65e29"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Training loop\n",
    "total_test_losses = 0\n",
    "edge_test_losses  = 0\n",
    "node_test_losses  = 0\n",
    "idx = 0\n",
    "for batch_0 in test_loader:\n",
    "    # Move batch data to GPU\n",
    "    batch_0 = batch_0.to(device)\n",
    "    \n",
    "    # Read number of graphs in batch\n",
    "    batch_size = batch_0.num_graphs\n",
    "    \n",
    "    # Diffuse batch\n",
    "    g_batch_t = diffuse(batch_0, n_t_steps, s=alpha_decay)\n",
    "    \n",
    "    # Denoise batch\n",
    "    g_batch_0 = denoise(g_batch_t, n_t_steps, node_model, edge_model, n_graph_features,\n",
    "                        s=alpha_decay, sigma=sigma)\n",
    "    \n",
    "    # Calculate the loss for node features and edge attributes\n",
    "    node_loss, edge_loss = get_graph_losses(batch_0, g_batch_0, batch_size)\n",
    "    \n",
    "    # Accumulate the total training loss\n",
    "    loss = node_loss + edge_loss\n",
    "    \n",
    "    # Get items\n",
    "    total_loss_cum = loss.item()\n",
    "    edge_loss_cum  = edge_loss.item()\n",
    "    node_loss_cum  = node_loss.item()\n",
    "    \n",
    "    # Append average losses\n",
    "    total_test_losses += total_loss_cum\n",
    "    edge_test_losses  += edge_loss_cum\n",
    "    node_test_losses  += node_loss_cum\n",
    "    \n",
    "    print(f'Batch: {idx}, total loss: {total_loss_cum:.4f}, edge loss: {edge_loss_cum:.4f}, node loss: {node_loss_cum:.4f}')\n",
    "    idx += 1"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-08T10:40:58.236320900Z"
    }
   },
   "id": "2fe8468fc69b364a",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "total_test_losses, edge_test_losses, node_test_losses"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-08T10:40:58.236362208Z"
    }
   },
   "id": "d196836e36b58174",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Save results"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4dde0d0d42345dcb"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Create and save as a dictionary\n",
    "model_performance = {\n",
    "    'total_train_losses': total_train_losses,\n",
    "    'edge_train_losses':  edge_train_losses,\n",
    "    'node_train_losses':  node_train_losses,\n",
    "    'total_test_losses':  total_test_losses,\n",
    "    'edge_test_losses':   edge_test_losses,\n",
    "    'node_test_losses':   node_test_losses\n",
    "}\n",
    "\n",
    "# Write the dictionary to the file in JSON format\n",
    "with open(f'{target_folder}/model_performance.json', 'w') as json_file:\n",
    "    json.dump(model_performance, json_file)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-08T10:40:58.236393277Z"
    }
   },
   "id": "a348bc7a734b98db",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
