{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a69f99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn   as nn\n",
    "import GM_library as GML\n",
    "import numpy      as np\n",
    "import torch\n",
    "import json\n",
    "\n",
    "from os                   import path, listdir\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "import MP.MP_library as MPL\n",
    "\n",
    "# Checking if pytorch can run in GPU, else CPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d83ca3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target to generate new crystals\n",
    "target = 'GM_BiSI'\n",
    "\n",
    "input_folder    = 'models'\n",
    "target_folder   = f'{input_folder}/{target}'\n",
    "edge_model_name = f'{target_folder}/edge_model.pt'\n",
    "node_model_name = f'{target_folder}/node_model.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24741239",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the file in JSON format to a dictionary\n",
    "with open(f'{target_folder}/model_parameters.json', 'r') as json_file:\n",
    "    model_parameters = json.load(json_file)\n",
    "\n",
    "# Number of graphs to predict\n",
    "N_predictions = 10\n",
    "\n",
    "# Number of diffusing and denoising steps\n",
    "n_t_steps = model_parameters['n_t_steps']\n",
    "\n",
    "# Decay of parameter alpha\n",
    "noise_contribution = model_parameters['noise_contribution']\n",
    "alpha_decay = 0.5 * (1 - noise_contribution**2)\n",
    "\n",
    "# Dropouts for node and edge models (independent of each other)\n",
    "dropout_node = model_parameters['dropout_node']\n",
    "dropout_edge = model_parameters['dropout_edge']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4946b2e8",
   "metadata": {},
   "source": [
    "# Generation of graph database for training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b5cbe57",
   "metadata": {},
   "source": [
    "Load the datasets, already standarized if possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b3d1809a",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_name         = f'{target_folder}/labels.pt'\n",
    "dataset_name        = f'{target_folder}/dataset.pt'\n",
    "dataset_name_std    = f'{target_folder}/standardized_dataset.pt'\n",
    "parameters_name_std = f'{target_folder}/standardized_parameters.pt'  # Parameters for rescaling the predictions\n",
    "\n",
    "# Load the standardized dataset, with corresponding labels and parameters\n",
    "dataset    = torch.load(dataset_name_std)\n",
    "parameters = torch.load(parameters_name_std)\n",
    "\n",
    "# Assigning parameters accordingly\n",
    "target_mean, feat_mean, edge_mean, target_std, edge_std, feat_std, scale = parameters\n",
    "\n",
    "# Defining target factor\n",
    "target_factor = target_std / scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "066eb85e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(71.86479949951172, 0.34193673729896545)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the mean and standard deviation of the number of nodes\n",
    "total_nodes = torch.tensor([data.num_nodes for data in dataset])\n",
    "mean_nodes  = torch.mean(total_nodes.float()).item()\n",
    "std_nodes   = torch.std(total_nodes.float()).item()\n",
    "\n",
    "mean_nodes, std_nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a76fc0",
   "metadata": {},
   "source": [
    "# Loading the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d1aa0ba5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Node GCNN:\n",
      "nGCNN(\n",
      "  (conv1): GraphConv(5, 256)\n",
      "  (conv2): GraphConv(256, 5)\n",
      ")\n",
      "\n",
      "Edge GCNN:\n",
      "eGCNN(\n",
      "  (linear1): Linear(in_features=6, out_features=32, bias=True)\n",
      "  (linear2): Linear(in_features=32, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Determine number of features in dataset, considering the t_step information\n",
    "n_features = dataset[0].num_node_features + 1\n",
    "\n",
    "# Instantiate the models for nodes and edges\n",
    "node_model = GML.nGCNN(n_features, dropout_node).to(device)\n",
    "node_model.load_state_dict(torch.load(node_model_name))\n",
    "node_model.eval()\n",
    "\n",
    "edge_model = GML.eGCNN(n_features, dropout_edge).to(device)\n",
    "edge_model.load_state_dict(torch.load(edge_model_name))\n",
    "edge_model.eval()\n",
    "\n",
    "print('\\nNode GCNN:')\n",
    "print(node_model)\n",
    "print('\\nEdge GCNN:')\n",
    "print(edge_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "963a0f21",
   "metadata": {},
   "source": [
    "# Generating new cystals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e9f5788d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Data(x=[71, 4], edge_index=[2, 2485], edge_attr=[2485]),\n",
       " Data(x=[72, 4], edge_index=[2, 2556], edge_attr=[2556]),\n",
       " Data(x=[71, 4], edge_index=[2, 2485], edge_attr=[2485]),\n",
       " Data(x=[71, 4], edge_index=[2, 2485], edge_attr=[2485]),\n",
       " Data(x=[72, 4], edge_index=[2, 2556], edge_attr=[2556]),\n",
       " Data(x=[71, 4], edge_index=[2, 2485], edge_attr=[2485]),\n",
       " Data(x=[72, 4], edge_index=[2, 2556], edge_attr=[2556]),\n",
       " Data(x=[72, 4], edge_index=[2, 2556], edge_attr=[2556]),\n",
       " Data(x=[71, 4], edge_index=[2, 2485], edge_attr=[2485]),\n",
       " Data(x=[72, 4], edge_index=[2, 2556], edge_attr=[2556])]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predicting loop\n",
    "predicted_dataset = []\n",
    "with torch.no_grad():\n",
    "    for i in range(N_predictions):\n",
    "        # Get random number of nodes\n",
    "        n_nodes = int(np.random.normal(mean_nodes, std_nodes))\n",
    "        \n",
    "        # Get random graph, acting as diffused\n",
    "        diffused_graph = GML.get_random_graph(n_nodes, n_features-1)\n",
    "        \n",
    "        # Denoise the diffused graph\n",
    "        #print(f'Denoising...')\n",
    "        denoised_graph, _ = GML.denoise(diffused_graph, n_t_steps, node_model, edge_model,\n",
    "                                        s=alpha_decay)\n",
    "        \n",
    "        # Append generated graph\n",
    "        predicted_dataset.append(denoised_graph)\n",
    "\n",
    "# Revert stardadization\n",
    "denoised_graphs = GML.revert_standardize_dataset(predicted_dataset, parameters)\n",
    "denoised_graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "57947938",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1\n",
      "25 30 68 11.714252 10.226208 10.617725 5.508799806263361 8.615593380385214\n",
      "\n",
      "2\n",
      "31 37 66 10.806225 10.929033 11.29813 5.023517594227143 9.7060825982029\n",
      "\n",
      "3\n",
      "49 59 61 10.358076 11.801014 10.567783 6.510650446581332 9.842528177694057\n",
      "\n",
      "4\n",
      "16 35 68 10.447621 10.900649 10.503468 5.630664974911289 9.333796767860683\n",
      "\n",
      "5\n",
      "3 50 61 11.09833 10.609603 10.661455 5.499474784362518 9.073006744702468\n",
      "\n",
      "6\n",
      "29 43 66 10.282546 10.72827 11.4563265 4.35588152731182 9.804186056852101\n",
      "\n",
      "7\n",
      "0 32 39 10.590068 10.8727045 10.337479 5.831019103622349 9.176868719026833\n",
      "\n",
      "8\n",
      "1 28 32 10.434946 10.515156 11.060737 4.653435900685312 9.429423930082594\n",
      "\n",
      "9\n",
      "38 39 49 10.692003 9.641688 11.845575 3.1314727067913575 9.118992974262596\n",
      "\n",
      "10\n",
      "5 25 51 11.181639 10.61794 10.982516 5.238678877884309 9.235631671723157\n"
     ]
    }
   ],
   "source": [
    "for i in range(N_predictions):\n",
    "    print()\n",
    "    print(i+1)\n",
    "    graph = denoised_graphs[i].clone()\n",
    "    try:\n",
    "        GML.POSCAR_graph_encoding(graph, L, file_name=f'POSCAR-{i}', POSCAR_directory='./')\n",
    "    except SystemExit:\n",
    "        continue"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
