{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a69f99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy             as np\n",
    "import torch.nn          as nn\n",
    "import libraries.dataset as gld\n",
    "import libraries.model   as glm\n",
    "import libraries.graph   as glg\n",
    "import torch\n",
    "import json\n",
    "\n",
    "from pymatgen.core        import Structure\n",
    "from scipy.optimize       import minimize\n",
    "from torch_geometric.data import Batch, Data\n",
    "\n",
    "# Checking if pytorch can run in GPU, else CPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44a88fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From random noise, we generate completely new materials\n",
    "# A target property can be seeked with this approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d83ca3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define folder in which all data will be stored\n",
    "is_molecule     = True\n",
    "target_folder   = 'models/QM9-all-linked/GM_v0'\n",
    "model_name = f'{target_folder}/model.pt'\n",
    "\n",
    "# Number of graphs to predict\n",
    "N_predictions = 10\n",
    "\n",
    "# Define target to be generated\n",
    "target_tensor = torch.tensor(0, dtype=torch.int, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f9310c",
   "metadata": {},
   "source": [
    "# Load model data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24741239",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the file in JSON format to a dictionary\n",
    "with open(f'{target_folder}/model_parameters.json', 'r') as json_file:\n",
    "    numpy_dict = json.load(json_file)\n",
    "\n",
    "# Convert torch tensors to numpy arrays\n",
    "model_parameters = {}\n",
    "for key, value in numpy_dict.items():\n",
    "    try:\n",
    "        model_parameters[key] = torch.tensor(value, device=device)\n",
    "    except:\n",
    "        model_parameters[key] = value\n",
    "\n",
    "# Number of diffusing and denoising steps\n",
    "n_t_steps = model_parameters['n_t_steps']\n",
    "\n",
    "model_parameters['alpha_decay'] = torch.tensor(0.4, device=device)\n",
    "\n",
    "# Decay of parameter alpha\n",
    "alpha_decay = model_parameters['alpha_decay']\n",
    "\n",
    "# Dropouts for node and edge models (independent of each other)\n",
    "pdropout_node = model_parameters['dropout_node']\n",
    "pdropout_edge = model_parameters['dropout_edge']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4946b2e8",
   "metadata": {},
   "source": [
    "# Generation of graph database for training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b5cbe57",
   "metadata": {},
   "source": [
    "Load the datasets, already standarized if possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b95aa1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name                = f'{target_folder}/dataset.pt'\n",
    "labels_name                 = f'{target_folder}/standardized_labels.pt'\n",
    "dataset_name_std            = f'{target_folder}/standardized_dataset.pt'\n",
    "dataset_parameters_name_std = f'{target_folder}/standardized_parameters.json'  # Parameters for rescaling the predictions\n",
    "\n",
    "# Load the standardized dataset\n",
    "dataset = torch.load(dataset_name_std, weights_only=False)\n",
    "\n",
    "# Read the file in JSON format to a dictionary\n",
    "with open(dataset_parameters_name_std, 'r') as json_file:\n",
    "    numpy_dict = json.load(json_file)\n",
    "\n",
    "# Convert torch tensors to numpy arrays\n",
    "dataset_parameters = {}\n",
    "for key, value in numpy_dict.items():\n",
    "    try:\n",
    "        dataset_parameters[key] = torch.tensor(value, device=device)\n",
    "    except:\n",
    "        dataset_parameters[key] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "339f409c-3092-41ee-a6ad-0485d67658b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize target_tensor accordingly\n",
    "target_tensor = (target_tensor - dataset_parameters['target_mean']) * dataset_parameters['scale'] / dataset_parameters['target_std']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "066eb85e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17.983739852905273, 2.9542582035064697)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the mean and standard deviation of the number of nodes\n",
    "total_nodes = torch.tensor([data.num_nodes for data in dataset])\n",
    "mean_nodes  = torch.mean(total_nodes.float()).item()\n",
    "std_nodes   = torch.std(total_nodes.float()).item()\n",
    "\n",
    "mean_nodes, std_nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a76fc0",
   "metadata": {},
   "source": [
    "# Loading the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dff10529-1eb5-4d9a-8b5f-c5e5fc08715b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "GCNN:\n",
      "DataParallel(\n",
      "  (module): GNN(\n",
      "    (node_conv1): GraphConv(8, 32)\n",
      "    (node_conv2): GraphConv(32, 64)\n",
      "    (node_conv3): GraphConv(64, 4)\n",
      "    (edge_linear_f1): Linear(in_features=17, out_features=32, bias=True)\n",
      "    (edge_linear_r1): Linear(in_features=32, out_features=1, bias=True)\n",
      "    (edge_linear_f2): Linear(in_features=65, out_features=32, bias=True)\n",
      "    (edge_linear_r2): Linear(in_features=32, out_features=1, bias=True)\n",
      "    (edge_linear_f3): Linear(in_features=129, out_features=16, bias=True)\n",
      "    (edge_linear_r3): Linear(in_features=16, out_features=1, bias=True)\n",
      "    (node_norm1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (edge_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Determine number of node-level features in dataset, considering the t_step information\n",
    "n_node_features = dataset[0].num_node_features\n",
    "\n",
    "# Determine the number of graph-level features to be predicted\n",
    "n_graph_features = len(dataset[0].y)\n",
    "\n",
    "# Instantiate the models for nodes and edges\n",
    "model = glm.GNN(n_node_features, n_graph_features, pdropout_node, pdropout_edge).to(device)\n",
    "\n",
    "model.load_state_dict(torch.load(model_name, map_location=torch.device(device), weights_only=False))\n",
    "model.eval()\n",
    "\n",
    "# Allow data parallelization among multi-GPU\n",
    "model= nn.DataParallel(model)\n",
    "\n",
    "print('\\nGCNN:')\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "963a0f21",
   "metadata": {},
   "source": [
    "# Generating new cystals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7bc8c1b6-011e-429d-ae7c-c2a48e57d1e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'libraries.model' from '/home/claudio/cibran/Work/UPC/GenerativeModels/libraries/model.py'>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(glm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e13c537c-c31e-4817-89b8-5e60a1281b16",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataBatch(x=[174, 8], edge_index=[2, 1469], edge_attr=[1469], batch=[174], ptr=[11])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Data(x=[18, 4], edge_index=[2, 153], edge_attr=[153]),\n",
       " Data(x=[13, 4], edge_index=[2, 78], edge_attr=[78]),\n",
       " Data(x=[18, 4], edge_index=[2, 153], edge_attr=[153]),\n",
       " Data(x=[17, 4], edge_index=[2, 136], edge_attr=[136]),\n",
       " Data(x=[14, 4], edge_index=[2, 91], edge_attr=[91]),\n",
       " Data(x=[21, 4], edge_index=[2, 210], edge_attr=[210]),\n",
       " Data(x=[17, 4], edge_index=[2, 136], edge_attr=[136]),\n",
       " Data(x=[14, 4], edge_index=[2, 91], edge_attr=[91]),\n",
       " Data(x=[20, 4], edge_index=[2, 190], edge_attr=[190]),\n",
       " Data(x=[22, 4], edge_index=[2, 231], edge_attr=[231])]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create constant target tensor once\n",
    "features_tensor = torch.cat([target_tensor, torch.tensor([0], device=device, dtype=target_tensor.dtype)])\n",
    "\n",
    "# Predicting loop\n",
    "diffused_dataset = []\n",
    "with torch.no_grad():\n",
    "    for idx in range(N_predictions):\n",
    "        # Get a positive random number of nodes using absolute value\n",
    "        n_nodes = int(np.abs(np.random.normal(mean_nodes, std_nodes)))\n",
    "        \n",
    "        # Get random graph, acting as diffused\n",
    "        diffused_graph = glm.get_random_graph(n_nodes, n_node_features)\n",
    "\n",
    "        # Make room for n_graph_features and t_steps in the dataset\n",
    "        diffused_graph = glm.add_features_to_graph(diffused_graph, features_tensor)\n",
    "        \n",
    "        diffused_dataset.append(diffused_graph)\n",
    "            \n",
    "    # Generate batch object and move data to device\n",
    "    diff_batch = Batch.from_data_list(diffused_dataset).to(device)\n",
    "    print(diff_batch)\n",
    "    # Denoise batch\n",
    "    predicted_dataset = glm.denoise(diff_batch,\n",
    "                                    n_t_steps, alpha_decay,\n",
    "                                    model,\n",
    "                                    n_features=n_node_features)\n",
    "\n",
    "# From batch object to list\n",
    "predicted_dataset = predicted_dataset.to_data_list()\n",
    "\n",
    "# Remove graph features\n",
    "for graph in predicted_dataset:\n",
    "    graph.x = graph.x[:, :n_node_features]\n",
    "\n",
    "# Revert standardization\n",
    "denoised_graphs = gld.revert_standardize_dataset(predicted_dataset, dataset_parameters)\n",
    "denoised_graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1962f70c-22a5-484d-8265-85784acb4a59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.7519, 2.9047, 2.6898, 3.0402, 2.9155, 2.9910, 3.0098, 3.0166, 2.8677,\n",
       "        2.6701, 3.1365, 2.7193, 3.0985, 2.8962, 2.8931, 2.9255, 3.0719, 2.6909,\n",
       "        2.7070, 3.3156, 3.1131, 2.5674, 2.9764, 2.9588, 3.2445, 2.6130, 2.9292,\n",
       "        2.7703, 3.1421, 3.2245, 2.7823, 2.9829, 2.7802, 2.5691, 3.2204, 2.9880,\n",
       "        2.6501, 2.6365, 2.6385, 3.1619, 2.9183, 2.6999, 2.9126, 3.0100, 3.0192,\n",
       "        3.1426, 2.8504, 2.9245, 2.9521, 2.9425, 2.6392, 2.7955, 2.8089, 2.9238,\n",
       "        2.9586, 3.1135, 2.8069, 2.8015, 2.8246, 2.6696, 2.9643, 2.8734, 2.7053,\n",
       "        3.0933, 2.9145, 3.0263, 2.6329, 2.6536, 2.9527, 2.9915, 2.7621, 2.8187,\n",
       "        2.6876, 2.9272, 3.1350, 3.0114, 2.8606, 2.7261, 2.8191, 2.9666, 3.0958,\n",
       "        3.1195, 3.1285, 3.0675, 2.8924, 2.7753, 3.1929, 2.6308, 3.3878, 3.1406,\n",
       "        2.8832, 2.9401, 2.6327, 2.8823, 3.0740, 2.8956, 2.8834, 3.1169, 3.3332,\n",
       "        2.9948, 2.9850, 2.7612, 2.8803, 2.8523, 2.8900, 2.9136, 2.9375, 3.2321,\n",
       "        3.1448, 3.2407, 2.6316, 3.0615, 2.7346, 3.1232, 2.7505, 2.8933, 3.2430,\n",
       "        2.6848, 2.9245, 2.8669, 2.6474, 2.9322, 2.9697, 2.9835, 2.9759, 2.8820,\n",
       "        2.8796, 2.6847, 2.8688, 2.6891, 2.8723, 2.7274, 2.9289, 2.8571, 2.7883,\n",
       "        3.0506, 2.8099, 2.6545, 2.9136, 3.0404, 3.1504, 2.7620, 2.8329, 2.6977,\n",
       "        2.9026, 2.8859, 2.8566, 3.0073, 2.8259, 3.1423, 3.0836, 2.9509, 2.9305],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "denoised_graphs[0].edge_attr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8af401f1-89eb-43b9-8f42-2996b590e6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = denoised_graphs[0]\n",
    "\n",
    "nodes = temp.x\n",
    "edges = temp.edge_index.detach().cpu().numpy().T\n",
    "weights = temp.edge_attr.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7110c5c9-d0cf-4056-ada5-5c2206034939",
   "metadata": {},
   "source": [
    "## Molecules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "32f199e7-5d19-4c52-81f7-25d8dec93263",
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_molecule:\n",
    "    # Initial guess for the positions\n",
    "    solution = np.random.rand(len(nodes) * 3)*10  # Initialize all points at origin, 1D array\n",
    "    #solution = coordinates.reshape(-1, 1).ravel()\n",
    "    \n",
    "    # Function to calculate the squared difference between distances and weights\n",
    "    def objective(solution_attempt, edges, weights):\n",
    "        positions = solution_attempt.reshape(-1, 3)  # Reshape to 2D array\n",
    "        errors = 0\n",
    "        for edge, weight in zip(edges, weights):\n",
    "            p1 = positions[edge[0]]\n",
    "            p2 = positions[edge[1]]\n",
    "            distance = np.linalg.norm(p2 - p1)\n",
    "            errors += np.power(distance - weight, 2)\n",
    "        #print(errors)\n",
    "        return errors\n",
    "    \n",
    "    def worst_identification(edges, attributes, solution_attempt):\n",
    "        positions = solution_attempt.reshape(-1, 3)  # Reshape to 2D array\n",
    "    \n",
    "        particle_errors = []\n",
    "        for particle in np.unique(edges):\n",
    "            # Get those edge indexes where particle has a connection\n",
    "            particle_connections = np.where((edges[:, 0] == particle) | (edges[:, 1] == particle))\n",
    "    \n",
    "            particle_error = 0\n",
    "            for idx in particle_connections[0]:\n",
    "                # Load indexes in edge\n",
    "                edge = edges[idx]\n",
    "    \n",
    "                # Load expected attribute\n",
    "                p1 = positions[edge[0]]\n",
    "                p2 = positions[edge[1]]\n",
    "    \n",
    "                # Load reference attribute\n",
    "                weight = attributes[idx].item()\n",
    "                \n",
    "                # Compute error\n",
    "                distance = np.linalg.norm(p2 - p1)\n",
    "\n",
    "                # Append to trial errors for different atom images\n",
    "                trial_error = np.power(distance - weight, 2)\n",
    "    \n",
    "                # Add error\n",
    "                particle_error += trial_error\n",
    "    \n",
    "            # Average over the connection of the node\n",
    "            particle_error /= len(particle_connections[0])\n",
    "    \n",
    "            # Append particle error\n",
    "            particle_errors.append(particle_error)\n",
    "    \n",
    "        return np.argmax(particle_errors), np.max(particle_errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff66e868-1cf3-483b-b86e-be0530df0704",
   "metadata": {},
   "source": [
    "## Crystals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e5c3eafb-d43b-4252-ad20-307679fd21f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "coordinates = np.array([\n",
    "     0.0833003865704711  , 0.1859270061465210  , 0.3777845439929735\n",
    "  , 0.0833003981061324  , 0.6859269881513725  , 0.3777845451628608\n",
    "  , 0.4167001356044722  , 0.1859269992816479  , 0.3777845191410876\n",
    "  , 0.4167001621404367  , 0.6859270194700571  , 0.3777845271190117\n",
    "  , 0.7500002705756827  , 0.1859316651280807  , 0.3777885037770403\n",
    "  , 0.7500002296629660  , 0.6859316875596519  , 0.3777885214985517\n",
    "  , 0.2499997225877237  , 0.3140683536350650  , 0.6222114970725059\n",
    "  , 0.2499996959117041  , 0.8140683345865583  , 0.6222114853550877\n",
    "  , 0.5832998677821450  , 0.3140729827261879  , 0.6222154671411744\n",
    "  , 0.5832999024809595  , 0.8140729783177250  , 0.6222154056502092\n",
    "  , 0.9166995955193187  , 0.3140729782225051  , 0.6222154505134370\n",
    "  , 0.9166995850678958  , 0.8140729821050883  , 0.6222154662954935\n",
    "  , 0.0833003557957213  , 0.4359388259980790  , 0.1222199397756398\n",
    "  , 0.0833003703218509  , 0.9359387910009076  , 0.1222198643536814\n",
    "  , 0.4166992957118154  , 0.4359388088130629  , 0.1222198955474596\n",
    "  , 0.4166993028463040  , 0.9359387786070243  , 0.1222199189671187\n",
    "  , 0.7499998539722768  , 0.4359438124948127  , 0.1222156160502195\n",
    "  , 0.7499998313637235  , 0.9359437662274885  , 0.1222156247913588\n",
    "  , 0.2500001334862176  , 0.0640561904985262  , 0.8777843960840457\n",
    "  , 0.2500001501522888  , 0.5640561935034967  , 0.8777843427165877\n",
    "  , 0.5833007338820693  , 0.0640612097785151  , 0.8777800558508204\n",
    "  , 0.5833007418971903  , 0.5640612254590351  , 0.8777801148276509\n",
    "  , 0.9166996202755655  , 0.0640611993023512  , 0.8777801089383459\n",
    "  , 0.9166996118127884  , 0.5640612295363212  , 0.8777801377671963\n",
    "  , 0.2499997762110198  , 0.1713601343107101  , 0.5481720876539455\n",
    "  , 0.2499997840703116  , 0.6713601214163134  , 0.5481720780145309\n",
    "  , 0.5833250162477910  , 0.1713572960325820  , 0.5481789775038095\n",
    "  , 0.5833250495988693  , 0.6713573040678895  , 0.5481789530732897\n",
    "  , 0.9166745746964295  , 0.1713572981373801  , 0.5481789842084837\n",
    "  , 0.9166745530899618  , 0.6713573021865074  , 0.5481789776050263\n",
    "  , 0.0833249621182475  , 0.0786333712486353  , 0.0481761717281017\n",
    "  , 0.0833249283762569  , 0.5786334128382151  , 0.0481761718552747\n",
    "  , 0.4166745279576674  , 0.0786333673791404  , 0.0481761917888477\n",
    "  , 0.4166745408175885  , 0.5786334029086504  , 0.0481761988613769\n",
    "  , 0.7499997542585817  , 0.0786306836572876  , 0.0481693636313025\n",
    "  , 0.7499997696249991  , 0.5786307106868804  , 0.0481693779947747\n",
    "  , 0.2500002428303674  , 0.4213693111674246  , 0.9518306289886667\n",
    "  , 0.2500002524284000  , 0.9213693090296857  , 0.9518306479504446\n",
    "  , 0.5833254785610436  , 0.4213666122472688  , 0.9518238281457627\n",
    "  , 0.5833254664540277  , 0.9213666048503626  , 0.9518238233300949\n",
    "  , 0.9166750443396126  , 0.4213666121736850  , 0.9518238196621454\n",
    "  , 0.9166750512045638  , 0.9213665989570998  , 0.9518238133931618\n",
    "  , 0.0833254093017004  , 0.3286426988348055  , 0.4518210070768447\n",
    "  , 0.0833254152034897  , 0.8286426985367399  , 0.4518210434996561\n",
    "  , 0.4166749883104828  , 0.3286426993701070  , 0.4518210326992929\n",
    "  , 0.4166750112461699  , 0.8286427028116776  , 0.4518210241465397\n",
    "  , 0.7500002189827981  , 0.3286398726945166  , 0.4518279165260282\n",
    "  , 0.7500002050440315  , 0.8286398695303134  , 0.4518279056712515\n",
    "  , 0.0833343904517392  , 0.2493895957389327  , 0.8276681784694375\n",
    "  , 0.0833343689273747  , 0.7493896103808027  , 0.8276681775519847\n",
    "  , 0.4166646008297334  , 0.2493895985448376  , 0.8276681888402280\n",
    "  , 0.4166646015290567  , 0.7493896053118263  , 0.8276681788916704\n",
    "  , 0.7499994955974358  , 0.2493892016752000  , 0.8276653349518099\n",
    "  , 0.7499994966257333  , 0.7493892321762345  , 0.8276653329659069\n",
    "  , 0.2499994993380952  , 0.0006115346223297  , 0.3276669512905670\n",
    "  , 0.2499994545945086  , 0.5006115507435567  , 0.3276669855827379\n",
    "  , 0.5833340316108817  , 0.0006112292100227  , 0.3276694445189889\n",
    "  , 0.5833340450490496  , 0.5006112576846249  , 0.3276694188060532\n",
    "  , 0.9166649171447929  , 0.0006112406556724  , 0.3276694414395962\n",
    "  , 0.9166649422872197  , 0.5006112516606720  , 0.3276694166837473\n",
    "  , 0.0833350774736772  , 0.4993887728596320  , 0.6723305520180602\n",
    "  , 0.0833350565146773  , 0.9993887556194139  , 0.6723305767408831\n",
    "  , 0.4166659399161503  , 0.4993887649443494  , 0.6723305628139755\n",
    "  , 0.4166659743108312  , 0.9993887529203889  , 0.6723305536346871\n",
    "  , 0.7500005282137465  , 0.4993884802271822  , 0.6723330568981183\n",
    "  , 0.7500005211473351  , 0.9993884480369175  , 0.6723330647731487\n",
    "  , 0.2500004948450609  , 0.2506107521768470  , 0.1723346898767488\n",
    "  , 0.2500005000138685  , 0.7506107679165481  , 0.1723346662931746\n",
    "  , 0.5833354355602083  , 0.2506103907686850  , 0.1723318159613498\n",
    "  , 0.5833354392384109  , 0.7506103988549171  , 0.1723318206017836\n",
    "  , 0.9166656093784553  , 0.2506103920247469  , 0.1723318129244831\n",
    "  , 0.9166656048998192  , 0.7506104136216649  , 0.1723318040722503\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f3a4e28f-83d9-4971-a5fc-3200d0ec4911",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not is_molecule:\n",
    "    # Initial guess for the lattice parameters\n",
    "    lattice_vectors = np.array([[12.6111574162109861, 0.0000011161086378, 0.0000448983002823],\n",
    "                                [0.0000017328561662, 17.1582865432904406, -0.0000025255958988],\n",
    "                                [0.0000367952301136, -0.0000015683987433, 10.2820259071568429]])\n",
    "    \n",
    "    # Initial guess for the positions\n",
    "    #initial_positions = np.random.rand(len(nodes) * 3)  # Initialize all points at origin, 1D array\n",
    "    initial_positions = coordinates\n",
    "    solution = np.concatenate([lattice_vectors.ravel(), initial_positions])\n",
    "    \n",
    "    # Function to calculate the squared difference between distances and weights\n",
    "    def objective(solution_attempt, edges, weights):\n",
    "        solution_attempt = solution_attempt.reshape(-1, 3)  # Reshape to 2D array\n",
    "        \n",
    "        lattice_vectors = solution_attempt[:3]\n",
    "        positions       = solution_attempt[3:]\n",
    "        \n",
    "        errors = 0\n",
    "        for edge, weight in zip(edges, weights):\n",
    "            p1 = positions[edge[0]]\n",
    "            p2 = positions[edge[1]]\n",
    "            \n",
    "            trial_errors = [] \n",
    "            for i in [-1, 0, 1]:\n",
    "                for j in [-1, 0, 1]:\n",
    "                    for k in [-1, 0, 1]:\n",
    "                        # i*lattice_vectors[0] + j*lattice_vectors[1] + k*lattice_vectors[2]\n",
    "                        ijk_lattice_vectors = np.sum([i, j, k] * lattice_vectors.T, axis=1)\n",
    "\n",
    "                        # Compute error\n",
    "                        distance = np.linalg.norm(p2 - p1 + ijk_lattice_vectors)\n",
    "\n",
    "                        # Append to trial errors for differente atom images\n",
    "                        trial_errors.append(np.power(distance - weight, 2))\n",
    "            errors += np.min(trial_errors)\n",
    "        #print(errors)\n",
    "        return errors\n",
    "    \n",
    "    def worst_identification(edges, attributes, solution_attempt):\n",
    "        solution_attempt = solution_attempt.reshape(-1, 3)  # Reshape to 2D array\n",
    "    \n",
    "        lattice_vectors = solution_attempt[:3]\n",
    "        positions       = solution_attempt[3:]\n",
    "    \n",
    "        particle_errors = []\n",
    "        for particle in np.unique(edges):\n",
    "            # Get those edge indexes where particle has a connection\n",
    "            particle_connections = np.where((edges[:, 0] == particle) | (edges[:, 1] == particle))\n",
    "    \n",
    "            particle_error = 0\n",
    "            for idx in particle_connections[0]:\n",
    "                # Load indexes in edge\n",
    "                edge = edges[idx]\n",
    "    \n",
    "                # Load expected attribute\n",
    "                p1 = positions[edge[0]]\n",
    "                p2 = positions[edge[1]]\n",
    "    \n",
    "                # Load reference attribute\n",
    "                weight = attributes[idx].item()\n",
    "    \n",
    "                trial_errors = []\n",
    "                for i in [-1, 0, 1]:\n",
    "                    for j in [-1, 0, 1]:\n",
    "                        for k in [-1, 0, 1]:\n",
    "                            # i*lattice_vectors[0] + j*lattice_vectors[1] + k*lattice_vectors[2]\n",
    "                            ijk_lattice_vectors = np.sum([i, j, k] * lattice_vectors.T, axis=1)\n",
    "    \n",
    "                            # Compute error\n",
    "                            distance = np.linalg.norm(p2 - p1 + ijk_lattice_vectors)\n",
    "    \n",
    "                            # Append to trial errors for different atom images\n",
    "                            trial_errors.append(np.power(distance - weight, 2))\n",
    "    \n",
    "                # Add error\n",
    "                particle_error += np.min(trial_errors)\n",
    "    \n",
    "            # Average over the connection of the node\n",
    "            particle_error /= len(particle_connections[0])\n",
    "    \n",
    "            # Append particle error\n",
    "            particle_errors.append(particle_error)\n",
    "    \n",
    "        return np.argmax(particle_errors), np.max(particle_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1d76ec67-05e8-4242-b25a-2a14bccac3b3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Attempt 0\n",
      "Total: 0.5415438589272228 and local 0.00040429978425656995 errors\n",
      "\n",
      "Attempt 1\n",
      "Total: 0.5368245350803098 and local 0.00038523575297439415 errors\n",
      "\n",
      "Attempt 2\n",
      "Total: 0.5366366950743916 and local 0.00038031069335487305 errors\n",
      "\n",
      "Attempt 3\n",
      "Total: 0.5366253064002295 and local 0.00038189563477137326 errors\n",
      "\n",
      "Attempt 4\n",
      "Total: 0.5367007180030032 and local 0.00038107941270398474 errors\n",
      "\n",
      "Attempt 5\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m()\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAttempt \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattempt\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m solution \u001b[38;5;241m=\u001b[39m \u001b[43mminimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msolution\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m                    \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43medges\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mPowell\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m is_success       \u001b[38;5;241m=\u001b[39m solution\u001b[38;5;241m.\u001b[39msuccess\n\u001b[1;32m     11\u001b[0m solution_message \u001b[38;5;241m=\u001b[39m solution\u001b[38;5;241m.\u001b[39mmessage\n",
      "File \u001b[0;32m~/cibran/Work/UPC/GenerativeModels/venv/lib/python3.12/site-packages/scipy/optimize/_minimize.py:722\u001b[0m, in \u001b[0;36mminimize\u001b[0;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[1;32m    719\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_neldermead(fun, x0, args, callback, bounds\u001b[38;5;241m=\u001b[39mbounds,\n\u001b[1;32m    720\u001b[0m                                \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n\u001b[1;32m    721\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m meth \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpowell\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 722\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43m_minimize_powell\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbounds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    723\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m meth \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcg\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    724\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_cg(fun, x0, args, jac, callback, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n",
      "File \u001b[0;32m~/cibran/Work/UPC/GenerativeModels/venv/lib/python3.12/site-packages/scipy/optimize/_optimize.py:3490\u001b[0m, in \u001b[0;36m_minimize_powell\u001b[0;34m(func, x0, args, callback, bounds, xtol, ftol, maxiter, maxfev, disp, direc, return_all, **unknown_options)\u001b[0m\n\u001b[1;32m   3488\u001b[0m direc1 \u001b[38;5;241m=\u001b[39m direc[i]\n\u001b[1;32m   3489\u001b[0m fx2 \u001b[38;5;241m=\u001b[39m fval\n\u001b[0;32m-> 3490\u001b[0m fval, x, direc1 \u001b[38;5;241m=\u001b[39m \u001b[43m_linesearch_powell\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdirec1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3491\u001b[0m \u001b[43m                                     \u001b[49m\u001b[43mtol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxtol\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3492\u001b[0m \u001b[43m                                     \u001b[49m\u001b[43mlower_bound\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlower_bound\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3493\u001b[0m \u001b[43m                                     \u001b[49m\u001b[43mupper_bound\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mupper_bound\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3494\u001b[0m \u001b[43m                                     \u001b[49m\u001b[43mfval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3495\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (fx2 \u001b[38;5;241m-\u001b[39m fval) \u001b[38;5;241m>\u001b[39m delta:\n\u001b[1;32m   3496\u001b[0m     delta \u001b[38;5;241m=\u001b[39m fx2 \u001b[38;5;241m-\u001b[39m fval\n",
      "File \u001b[0;32m~/cibran/Work/UPC/GenerativeModels/venv/lib/python3.12/site-packages/scipy/optimize/_optimize.py:3166\u001b[0m, in \u001b[0;36m_linesearch_powell\u001b[0;34m(func, p, xi, tol, lower_bound, upper_bound, fval)\u001b[0m\n\u001b[1;32m   3163\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ((fval, p, xi) \u001b[38;5;28;01mif\u001b[39;00m fval \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m (func(p), p, xi))\n\u001b[1;32m   3164\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m lower_bound \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m upper_bound \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3165\u001b[0m     \u001b[38;5;66;03m# non-bounded minimization\u001b[39;00m\n\u001b[0;32m-> 3166\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43m_recover_from_bracket_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_minimize_scalar_brent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3167\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43mmyfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxtol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtol\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3168\u001b[0m     alpha_min, fret \u001b[38;5;241m=\u001b[39m res\u001b[38;5;241m.\u001b[39mx, res\u001b[38;5;241m.\u001b[39mfun\n\u001b[1;32m   3169\u001b[0m     xi \u001b[38;5;241m=\u001b[39m alpha_min \u001b[38;5;241m*\u001b[39m xi\n",
      "File \u001b[0;32m~/cibran/Work/UPC/GenerativeModels/venv/lib/python3.12/site-packages/scipy/optimize/_optimize.py:3059\u001b[0m, in \u001b[0;36m_recover_from_bracket_error\u001b[0;34m(solver, fun, bracket, args, **options)\u001b[0m\n\u001b[1;32m   3040\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_recover_from_bracket_error\u001b[39m(solver, fun, bracket, args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions):\n\u001b[1;32m   3041\u001b[0m     \u001b[38;5;66;03m# `bracket` was originally written without checking whether the resulting\u001b[39;00m\n\u001b[1;32m   3042\u001b[0m     \u001b[38;5;66;03m# bracket is valid. `brent` and `golden` built on top of it without\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3056\u001b[0m     \u001b[38;5;66;03m# storing the information needed by `minimize_scalar` in the error object,\u001b[39;00m\n\u001b[1;32m   3057\u001b[0m     \u001b[38;5;66;03m# and intercepting it here.\u001b[39;00m\n\u001b[1;32m   3058\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3059\u001b[0m         res \u001b[38;5;241m=\u001b[39m \u001b[43msolver\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbracket\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3060\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m BracketError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   3061\u001b[0m         msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(e)\n",
      "File \u001b[0;32m~/cibran/Work/UPC/GenerativeModels/venv/lib/python3.12/site-packages/scipy/optimize/_optimize.py:2662\u001b[0m, in \u001b[0;36m_minimize_scalar_brent\u001b[0;34m(func, brack, args, xtol, maxiter, disp, **unknown_options)\u001b[0m\n\u001b[1;32m   2659\u001b[0m brent \u001b[38;5;241m=\u001b[39m Brent(func\u001b[38;5;241m=\u001b[39mfunc, args\u001b[38;5;241m=\u001b[39margs, tol\u001b[38;5;241m=\u001b[39mtol,\n\u001b[1;32m   2660\u001b[0m               full_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, maxiter\u001b[38;5;241m=\u001b[39mmaxiter, disp\u001b[38;5;241m=\u001b[39mdisp)\n\u001b[1;32m   2661\u001b[0m brent\u001b[38;5;241m.\u001b[39mset_bracket(brack)\n\u001b[0;32m-> 2662\u001b[0m \u001b[43mbrent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2663\u001b[0m x, fval, nit, nfev \u001b[38;5;241m=\u001b[39m brent\u001b[38;5;241m.\u001b[39mget_result(full_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   2665\u001b[0m success \u001b[38;5;241m=\u001b[39m nit \u001b[38;5;241m<\u001b[39m maxiter \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (np\u001b[38;5;241m.\u001b[39misnan(x) \u001b[38;5;129;01mor\u001b[39;00m np\u001b[38;5;241m.\u001b[39misnan(fval))\n",
      "File \u001b[0;32m~/cibran/Work/UPC/GenerativeModels/venv/lib/python3.12/site-packages/scipy/optimize/_optimize.py:2504\u001b[0m, in \u001b[0;36mBrent.optimize\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2502\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2503\u001b[0m     u \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m rat\n\u001b[0;32m-> 2504\u001b[0m fu \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mu\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m      \u001b[38;5;66;03m# calculate new output value\u001b[39;00m\n\u001b[1;32m   2505\u001b[0m funcalls \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   2507\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (fu \u001b[38;5;241m>\u001b[39m fx):                 \u001b[38;5;66;03m# if it's bigger than current\u001b[39;00m\n",
      "File \u001b[0;32m~/cibran/Work/UPC/GenerativeModels/venv/lib/python3.12/site-packages/scipy/optimize/_optimize.py:3159\u001b[0m, in \u001b[0;36m_linesearch_powell.<locals>.myfunc\u001b[0;34m(alpha)\u001b[0m\n\u001b[1;32m   3158\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmyfunc\u001b[39m(alpha):\n\u001b[0;32m-> 3159\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mxi\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/cibran/Work/UPC/GenerativeModels/venv/lib/python3.12/site-packages/scipy/optimize/_optimize.py:526\u001b[0m, in \u001b[0;36m_wrap_scalar_function_maxfun_validation.<locals>.function_wrapper\u001b[0;34m(x, *wrapper_args)\u001b[0m\n\u001b[1;32m    524\u001b[0m ncalls[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    525\u001b[0m \u001b[38;5;66;03m# A copy of x is sent to the user function (gh13740)\u001b[39;00m\n\u001b[0;32m--> 526\u001b[0m fx \u001b[38;5;241m=\u001b[39m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mwrapper_args\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[38;5;66;03m# Ideally, we'd like to a have a true scalar returned from f(x). For\u001b[39;00m\n\u001b[1;32m    528\u001b[0m \u001b[38;5;66;03m# backwards-compatibility, also allow np.array([1.3]),\u001b[39;00m\n\u001b[1;32m    529\u001b[0m \u001b[38;5;66;03m# np.array([[1.3]]) etc.\u001b[39;00m\n\u001b[1;32m    530\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39misscalar(fx):\n",
      "Cell \u001b[0;32mIn[16], line 35\u001b[0m, in \u001b[0;36mobjective\u001b[0;34m(solution_attempt, edges, weights)\u001b[0m\n\u001b[1;32m     32\u001b[0m                 distance \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mnorm(p2 \u001b[38;5;241m-\u001b[39m p1 \u001b[38;5;241m+\u001b[39m ijk_lattice_vectors)\n\u001b[1;32m     34\u001b[0m                 \u001b[38;5;66;03m# Append to trial errors for differente atom images\u001b[39;00m\n\u001b[0;32m---> 35\u001b[0m                 trial_errors\u001b[38;5;241m.\u001b[39mappend(\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpower\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdistance\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     36\u001b[0m     errors \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmin(trial_errors)\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m#print(errors)\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "error_threshold = 1e-5\n",
    "\n",
    "for attempt in range(100):\n",
    "    print()\n",
    "    print(f'Attempt {attempt}')\n",
    "    solution = minimize(objective, solution,\n",
    "                        args=(edges, weights),\n",
    "                        method='Powell')\n",
    "\n",
    "    is_success       = solution.success\n",
    "    solution_message = solution.message\n",
    "    worst_particle, worst_error = worst_identification(edges, weights, solution.x)\n",
    "\n",
    "    attempt_error = objective(solution.x, edges, weights)\n",
    "    print(f'Total: {attempt_error} and local {worst_error} errors')\n",
    "\n",
    "    if attempt_error < error_threshold:\n",
    "        break\n",
    "\n",
    "    solution = solution.x.reshape(-1, 3)  # Reshape to 2D array\n",
    "\n",
    "    # Re-initialize that position\n",
    "    if is_molecule:\n",
    "        solution[worst_particle] = np.random.rand(3)\n",
    "    else:\n",
    "        solution[worst_particle+3] = np.random.rand(3)\n",
    "\n",
    "    solution = solution.flatten()\n",
    "\n",
    "# Check convergence status\n",
    "if is_success:\n",
    "    print('Converged to a solution.')\n",
    "else:\n",
    "    print(f'Failed to converge: {solution_message}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "515f6a4d-8542-4695-866c-9734d739f79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "solution = solution.reshape(-1, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c66525-8a75-4c42-9a2a-a9edf135d70c",
   "metadata": {},
   "source": [
    "## Molecules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "74512108-9c89-46c6-a60c-a3f1cd5d487d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_molecule:\n",
    "    # Get the position of each atom in direct coordinates\n",
    "    #direct_positions = graph_to_cartesian_positions(graph)\n",
    "    #cartesian_positions = solution.x.reshape(-1, 3)*mw\n",
    "    #cartesian_positions = solution.x.reshape(-1, 3)\n",
    "    \n",
    "    lattice_vectors     = np.array([[10,  0,   0],\n",
    "                                    [0,   10,  0],\n",
    "                                    [0,   0,   10]])\n",
    "    cartesian_positions = solution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a292e640-09fc-4593-9782-6b022dc1f860",
   "metadata": {},
   "source": [
    "## Crystals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c905edb6-ba68-41f3-927d-cd0fc21fee33",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not is_molecule:\n",
    "    # Get the position of each atom in direct coordinates\n",
    "    #direct_positions = graph_to_cartesian_positions(graph)\n",
    "    #cartesian_positions = solution.x.reshape(-1, 3)*mw\n",
    "    \n",
    "    lattice_vectors     = solution[:3]\n",
    "    cartesian_positions = solution[3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b0709aff-bf63-4f99-ab14-e8bcabac3d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "POSCAR_name = None\n",
    "\n",
    "# Get name for the first line of the POSCAR\n",
    "POSCAR_name = POSCAR_name or 'POSCAR from GenerativeModels'\n",
    "\n",
    "# Clone the input graph to preserve the original structure\n",
    "new_graph = temp.clone()\n",
    "\n",
    "# Load and detach embeddings for the graph nodes\n",
    "data_embeddings = new_graph.x.detach().cpu().numpy()\n",
    "\n",
    "# Loading dictionary of available embeddings for atoms\n",
    "available_embeddings = {}\n",
    "with open('../MP/input/atomic_masses.dat', 'r') as atomic_masses_file:\n",
    "    for line in atomic_masses_file:\n",
    "        key, mass, charge, electronegativity, ionization_energy = line.split()\n",
    "\n",
    "        # Check if all information is present\n",
    "        if all(val != 'None' for val in (mass, charge, electronegativity, ionization_energy)):\n",
    "            available_embeddings[key] = np.array([mass, charge, electronegativity, ionization_energy], dtype=float)\n",
    "\n",
    "# Get most similar atoms for each graph node and create a list of keys\n",
    "keys = [find_closest_key(available_embeddings, emb) for emb in data_embeddings]\n",
    "\n",
    "# Get elements' composition, concentration, and positions\n",
    "POSCAR_composition, POSCAR_concentration, POSCAR_positions = composition_concentration_from_keys(keys, cartesian_positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4065eb29-e8e9-4530-a68a-dd5bf8d7dd7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write file\n",
    "with open('CONTCAR', 'w') as POSCAR_file:\n",
    "    # Delete previous data in the file\n",
    "    POSCAR_file.truncate()\n",
    "    \n",
    "    # Write POSCAR's name\n",
    "    POSCAR_file.write(f'{POSCAR_name}\\n')\n",
    "\n",
    "    # Write scaling factor (assumed to be 1.0)\n",
    "    POSCAR_file.write('1.0\\n')\n",
    "\n",
    "    # Write lattice parameters (assumed to be orthogonal)\n",
    "    np.savetxt(POSCAR_file, lattice_vectors, delimiter=' ')\n",
    "\n",
    "    # Write composition (each different species, previously sorted)\n",
    "    np.savetxt(POSCAR_file, [POSCAR_composition], fmt='%s', delimiter=' ')\n",
    "\n",
    "    # Write concentration (number of each of the previous elements)\n",
    "    np.savetxt(POSCAR_file, [POSCAR_concentration], fmt='%d', delimiter=' ')\n",
    "\n",
    "    # Write position in cartesian form\n",
    "    POSCAR_file.write('Cartesian\\n')\n",
    "    np.savetxt(POSCAR_file, POSCAR_positions, delimiter=' ')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
