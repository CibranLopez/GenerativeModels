{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6a69f99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy    as np\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import json\n",
    "\n",
    "from torch_geometric.data import Batch\n",
    "from libraries.model      import nGCNN, eGCNN, denoise, get_random_graph, add_features_to_graph\n",
    "from libraries.dataset    import revert_standardize_dataset\n",
    "from libraries.graph      import POSCAR_graph_encoding\n",
    "\n",
    "# Checking if pytorch can run in GPU, else CPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44a88fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From random noise, we generate completely new materials\n",
    "# A target property can be seeked with this approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d83ca3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define folder in which all data will be stored\n",
    "target_folder    = 'models/Loaded_QM9_gap-sphere-images/GM_v9'\n",
    "edge_model_name = f'{target_folder}/edge_model.pt'\n",
    "node_model_name = f'{target_folder}/node_model.pt'\n",
    "\n",
    "# Number of graphs to predict\n",
    "N_predictions = 10\n",
    "\n",
    "# Define target to be generated\n",
    "target_tensor = torch.tensor(1, dtype=torch.int, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f9310c",
   "metadata": {},
   "source": [
    "# Load model data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "24741239",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the file in JSON format to a dictionary\n",
    "with open(f'{target_folder}/model_parameters.json', 'r') as json_file:\n",
    "    numpy_dict = json.load(json_file)\n",
    "\n",
    "# Convert torch tensors to numpy arrays\n",
    "model_parameters = {}\n",
    "for key, value in numpy_dict.items():\n",
    "    try:\n",
    "        model_parameters[key] = torch.tensor(value, device=device)\n",
    "    except:\n",
    "        model_parameters[key] = value\n",
    "\n",
    "# Number of diffusing and denoising steps\n",
    "n_t_steps = model_parameters['n_t_steps']\n",
    "\n",
    "# Decay of parameter alpha\n",
    "noise_contribution = model_parameters['noise_contribution']\n",
    "alpha_decay = 0.5 * (1 - noise_contribution**2)\n",
    "\n",
    "# Dropouts for node and edge models (independent of each other)\n",
    "dropout_node = model_parameters['dropout_node']\n",
    "dropout_edge = model_parameters['dropout_edge']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4946b2e8",
   "metadata": {},
   "source": [
    "# Generation of graph database for training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b5cbe57",
   "metadata": {},
   "source": [
    "Load the datasets, already standarized if possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b95aa1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_362992/933877349.py:7: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  dataset = torch.load(dataset_name_std)\n"
     ]
    }
   ],
   "source": [
    "dataset_name                = f'{target_folder}/dataset.pt'\n",
    "labels_name                 = f'{target_folder}/standardized_labels.pt'\n",
    "dataset_name_std            = f'{target_folder}/standardized_dataset.pt'\n",
    "dataset_parameters_name_std = f'{target_folder}/standardized_parameters.json'  # Parameters for rescaling the predictions\n",
    "\n",
    "# Load the standardized dataset\n",
    "dataset = torch.load(dataset_name_std)\n",
    "\n",
    "# Read the file in JSON format to a dictionary\n",
    "with open(dataset_parameters_name_std, 'r') as json_file:\n",
    "    numpy_dict = json.load(json_file)\n",
    "\n",
    "# Convert torch tensors to numpy arrays\n",
    "dataset_parameters = {}\n",
    "for key, value in numpy_dict.items():\n",
    "    try:\n",
    "        dataset_parameters[key] = torch.tensor(value, device=device)\n",
    "    except:\n",
    "        dataset_parameters[key] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "339f409c-3092-41ee-a6ad-0485d67658b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize target_tensor accordingly\n",
    "target_tensor = (target_tensor - dataset_parameters['target_mean']) * dataset_parameters['scale'] / dataset_parameters['target_std']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "066eb85e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17.983739852905273, 2.9542582035064697)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the mean and standard deviation of the number of nodes\n",
    "total_nodes = torch.tensor([data.num_nodes for data in dataset])\n",
    "mean_nodes  = torch.mean(total_nodes.float()).item()\n",
    "std_nodes   = torch.std(total_nodes.float()).item()\n",
    "\n",
    "mean_nodes, std_nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a76fc0",
   "metadata": {},
   "source": [
    "# Loading the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aaf28a6f-8ec6-4800-a109-4ec222ffbf41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Node GCNN:\n",
      "DataParallel(\n",
      "  (module): nGCNN(\n",
      "    (conv1): GraphConv(6, 256)\n",
      "    (conv2): GraphConv(256, 512)\n",
      "    (conv3): GraphConv(512, 256)\n",
      "    (conv4): GraphConv(256, 4)\n",
      "    (norm1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      ")\n",
      "\n",
      "Edge GCNN:\n",
      "DataParallel(\n",
      "  (module): eGCNN(\n",
      "    (linear1): Linear(in_features=7, out_features=128, bias=True)\n",
      "    (linear2): Linear(in_features=128, out_features=256, bias=True)\n",
      "    (linear3): Linear(in_features=256, out_features=64, bias=True)\n",
      "    (linear4): Linear(in_features=64, out_features=1, bias=True)\n",
      "    (norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Determine number of node-level features in dataset, considering the t_step information\n",
    "n_node_features = dataset[0].num_node_features\n",
    "\n",
    "# Determine the number of graph-level features to be predicted\n",
    "n_graph_features = len(dataset[0].y)\n",
    "\n",
    "# Instantiate the models for nodes and edges\n",
    "node_model = nGCNN(n_node_features, n_graph_features+1, dropout_node)\n",
    "edge_model = eGCNN(n_node_features, n_graph_features+1, dropout_edge)\n",
    "\n",
    "node_model.load_state_dict(torch.load(node_model_name, map_location=torch.device(device), weights_only=False))\n",
    "edge_model.load_state_dict(torch.load(edge_model_name, map_location=torch.device(device), weights_only=False))\n",
    "node_model.eval()\n",
    "edge_model.eval()\n",
    "\n",
    "# Allow data parallelization among multi-GPU\n",
    "node_model= nn.DataParallel(node_model)\n",
    "edge_model= nn.DataParallel(edge_model)\n",
    "\n",
    "print('\\nNode GCNN:')\n",
    "print(node_model)\n",
    "print('\\nEdge GCNN:')\n",
    "print(edge_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "963a0f21",
   "metadata": {},
   "source": [
    "# Generating new cystals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8fd3de58-8827-4fde-8a83-f40f51f18ffb",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (6) must match the size of tensor b (4) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 26\u001b[0m\n\u001b[1;32m     23\u001b[0m     diff_batch \u001b[38;5;241m=\u001b[39m diff_batch\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;66;03m# Denoise batch of diffused graphs\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m     predicted_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mdenoise\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdiff_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_t_steps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malpha_decay\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msigma\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_parameters\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msigma\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# From batch object to list\u001b[39;00m\n\u001b[1;32m     29\u001b[0m predicted_dataset \u001b[38;5;241m=\u001b[39m predicted_dataset\u001b[38;5;241m.\u001b[39mto_data_list()\n",
      "File \u001b[0;32m~/cibran/Work/UPC/GenerativeModels/libraries/model.py:273\u001b[0m, in \u001b[0;36mdenoise\u001b[0;34m(batch_t, n_t_steps, node_model, edge_model, alpha_decay, sigma, plot_steps)\u001b[0m\n\u001b[1;32m    271\u001b[0m     \u001b[38;5;66;03m# Compute alpha_t and denoise batch altogether\u001b[39;00m\n\u001b[1;32m    272\u001b[0m     alpha_t \u001b[38;5;241m=\u001b[39m get_alpha_t(t_step, n_t_steps, alpha_decay)\n\u001b[0;32m--> 273\u001b[0m     batch_0 \u001b[38;5;241m=\u001b[39m \u001b[43mdenoising_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpred_epsilon_t\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha_t\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msigma\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[38;5;66;03m# Check if intermediate steps are plotted; then, plot the NetworkX graph\u001b[39;00m\n\u001b[1;32m    276\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m plot_steps:\n\u001b[1;32m    277\u001b[0m     \u001b[38;5;66;03m# Convert PyTorch graph to NetworkX graph\u001b[39;00m\n",
      "File \u001b[0;32m~/cibran/Work/UPC/GenerativeModels/libraries/model.py:229\u001b[0m, in \u001b[0;36mdenoising_step\u001b[0;34m(batch_t, epsilon, alpha_t, sigma)\u001b[0m\n\u001b[1;32m    226\u001b[0m epsilon_t \u001b[38;5;241m=\u001b[39m get_random_graph(n_nodes, n_features, batch_0\u001b[38;5;241m.\u001b[39medge_index)\n\u001b[1;32m    228\u001b[0m \u001b[38;5;66;03m# Backward pass\u001b[39;00m\n\u001b[0;32m--> 229\u001b[0m batch_0\u001b[38;5;241m.\u001b[39mx         \u001b[38;5;241m=\u001b[39m \u001b[43mbatch_0\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m         \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[43malpha_t\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43malpha_t\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43malpha_t\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mepsilon\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx\u001b[49m         \u001b[38;5;241m+\u001b[39m sigma \u001b[38;5;241m*\u001b[39m epsilon_t\u001b[38;5;241m.\u001b[39mx\n\u001b[1;32m    230\u001b[0m batch_0\u001b[38;5;241m.\u001b[39medge_attr \u001b[38;5;241m=\u001b[39m batch_0\u001b[38;5;241m.\u001b[39medge_attr \u001b[38;5;241m/\u001b[39m torch\u001b[38;5;241m.\u001b[39msqrt(alpha_t) \u001b[38;5;241m-\u001b[39m torch\u001b[38;5;241m.\u001b[39msqrt((\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m alpha_t) \u001b[38;5;241m/\u001b[39m alpha_t) \u001b[38;5;241m*\u001b[39m epsilon\u001b[38;5;241m.\u001b[39medge_attr \u001b[38;5;241m+\u001b[39m sigma \u001b[38;5;241m*\u001b[39m epsilon_t\u001b[38;5;241m.\u001b[39medge_attr\n\u001b[1;32m    231\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m batch_0\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (6) must match the size of tensor b (4) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "# Predicting loop\n",
    "diffused_dataset = []\n",
    "with torch.no_grad():\n",
    "    for idx in range(N_predictions):\n",
    "        # Get random number of nodes\n",
    "        n_nodes = int(np.random.normal(mean_nodes, std_nodes))\n",
    "        while n_nodes < 0:  # Make sure n_nodes is a positive integer from the normal distribution\n",
    "            n_nodes = int(np.random.normal(mean_nodes, std_nodes))\n",
    "        \n",
    "        # Get random graph, acting as diffused\n",
    "        diffused_graph = get_random_graph(n_nodes, n_node_features)\n",
    "\n",
    "        # Make room for n_graph_features and t_steps in the dataset\n",
    "        diffused_graph = add_features_to_graph(diffused_graph,\n",
    "                                               torch.tensor([target_tensor, 0], device=device))\n",
    "        \n",
    "        diffused_dataset.append(diffused_graph)\n",
    "            \n",
    "    # Generate batch objects\n",
    "    diff_batch = Batch.from_data_list(diffused_dataset)\n",
    "    \n",
    "    # Move data to device\n",
    "    diff_batch = diff_batch.to(device)\n",
    "    \n",
    "    # Denoise batch of diffused graphs\n",
    "    predicted_dataset = denoise(diff_batch, n_t_steps, node_model, edge_model, alpha_decay=alpha_decay, sigma=model_parameters['sigma'])\n",
    "\n",
    "# From batch object to list\n",
    "predicted_dataset = predicted_dataset.to_data_list()\n",
    "\n",
    "# Revert stardadization\n",
    "denoised_graphs = revert_standardize_dataset(predicted_dataset, dataset_parameters)\n",
    "denoised_graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8af401f1-89eb-43b9-8f42-2996b590e6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = denoised_graphs[0]\n",
    "\n",
    "nodes = temp.x\n",
    "edges = temp.edge_index.detach().cpu().numpy().T\n",
    "weights = temp.edge_attr.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "38d0a5a5-0002-448f-a7ce-855126635b89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 71.9272,  21.0472,   2.5597,   9.5406],\n",
       "         [104.1651,  31.0890,   2.6542,   9.3892],\n",
       "         [116.9652,  35.3267,   2.4768,  10.1779],\n",
       "         [117.9008,  52.7503,   2.7047,  10.6533],\n",
       "         [109.6857,  52.4652,   2.6629,  10.6234],\n",
       "         [105.8927,  44.1827,   2.6604,  10.0779],\n",
       "         [127.7625,  54.5869,   2.5684,  10.1005],\n",
       "         [101.0349,  40.1833,   2.5784,   9.6555],\n",
       "         [ 91.9999,  37.2730,   2.4036,   9.9699],\n",
       "         [116.0556,  50.2209,   2.5086,  10.1145],\n",
       "         [122.6762,  51.0751,   2.6933,  10.5572],\n",
       "         [134.8280,  54.1657,   2.6574,  10.1510],\n",
       "         [121.8354,  40.7826,   2.6859,  10.3472],\n",
       "         [ 99.7271,  44.1657,   2.3131,   9.3684],\n",
       "         [ 92.6044,  44.8905,   2.6500,  10.3383],\n",
       "         [213.7116,  64.5890,   2.6510,   8.8843],\n",
       "         [ 71.8913,  41.0737,   2.4813,   9.8112],\n",
       "         [190.2209,  62.8202,   2.3617,   9.5126],\n",
       "         [101.2071,  36.3617,   2.5780,   9.7299],\n",
       "         [146.4583,  50.7582,   2.8548,   9.9258],\n",
       "         [ 88.4008,  47.6011,   2.7737,  10.3803],\n",
       "         [108.5087,  54.0008,   2.4800,   9.4794],\n",
       "         [128.5490,  64.1379,   2.5098,  10.1892],\n",
       "         [147.1311,  47.0771,   2.7450,  10.0833],\n",
       "         [141.4171,  42.3587,   2.6378,  10.3243],\n",
       "         [130.9117,  40.6080,   2.6121,  10.1761],\n",
       "         [146.0631,  37.1077,   2.7921,  10.1514],\n",
       "         [123.5835,  56.6283,   2.6352,  10.2253],\n",
       "         [122.1861,  49.1406,   2.4682,  10.1285],\n",
       "         [ 71.4834,  42.0892,   2.5146,   9.8688],\n",
       "         [119.0262,  42.3772,   2.4538,   9.9935],\n",
       "         [142.2299,  64.7420,   2.6388,  10.6613],\n",
       "         [143.3930,  51.9253,   2.4185,   9.7157],\n",
       "         [ 83.2601,  52.2454,   2.3687,   9.3422],\n",
       "         [111.7799,  55.0073,   2.6758,  10.7310],\n",
       "         [ 35.7749,  30.3587,   2.2809,   8.9092],\n",
       "         [100.2648,  46.1143,   2.6165,  10.3400],\n",
       "         [124.9439,  62.3834,   2.6389,  10.6292],\n",
       "         [158.0292,  54.4513,   2.6293,  10.9456],\n",
       "         [106.4737,  55.2676,   2.3127,   8.8305],\n",
       "         [111.6576,  52.1182,   2.5915,  10.1389],\n",
       "         [115.5857,  58.1450,   2.6116,  10.0692],\n",
       "         [187.9220,  74.3246,   2.3303,   8.2133],\n",
       "         [109.5864,  51.9538,   2.6444,  10.7042],\n",
       "         [105.4704,  68.8639,   2.5363,   9.5179],\n",
       "         [109.1224,  40.9701,   2.6927,  10.6479],\n",
       "         [113.2707,  44.8076,   2.5572,   9.5432],\n",
       "         [102.6958,  39.5003,   2.2019,   7.7634],\n",
       "         [102.9525,  49.0446,   2.7305,  10.1691],\n",
       "         [154.4871,  41.5771,   2.7858,  11.3251],\n",
       "         [121.0770,  44.3408,   2.7465,  10.9709],\n",
       "         [145.5649,  63.5939,   2.8213,  10.8297],\n",
       "         [121.3650,  58.4625,   2.4913,  10.5373],\n",
       "         [109.1153,  58.5948,   2.3419,   9.3117],\n",
       "         [ 71.3283,  67.7165,   2.3845,   9.8867],\n",
       "         [122.5953,  58.0202,   2.6295,   9.6836],\n",
       "         [ 93.0769,  56.3258,   2.4663,   9.7077],\n",
       "         [128.0987,  65.4048,   2.5713,  10.1812],\n",
       "         [121.4314,  62.3027,   2.4826,   8.7842],\n",
       "         [ 28.8052,  30.2874,   2.5424,  10.0817],\n",
       "         [110.5877,  70.3790,   2.3150,   8.8017],\n",
       "         [108.8216,  49.0939,   2.4896,   9.6886],\n",
       "         [156.4461,  39.0440,   2.6886,  10.6878],\n",
       "         [ 86.7536,  54.9678,   2.7373,  10.7477],\n",
       "         [129.5561,  67.6095,   2.6219,  10.1275],\n",
       "         [ 68.9938,  64.8322,   2.2938,   9.1230],\n",
       "         [ 67.7645,  61.6571,   2.3147,   9.3270],\n",
       "         [119.0523,  22.6559,   2.6721,  10.8115],\n",
       "         [116.3378,  60.0342,   2.7761,  10.1708],\n",
       "         [141.7097,  73.3291,   2.6313,  10.2542],\n",
       "         [154.2294,  42.5837,   2.8388,  10.8103],\n",
       "         [112.4206,  15.5841,   2.7996,  11.0688]], device='cuda:0'),\n",
       " array([0.00546314, 0.06806778, 0.0496646 , ..., 0.08588617, 0.06593615,\n",
       "        0.04514361], dtype=float32))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes, weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "087b15ac-0819-4d19-b613-7c5dbc908885",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from scipy.optimize       import minimize\n",
    "from libraries.graph      import graph_POSCAR_encoding, find_closest_key, composition_concentration_from_keys\n",
    "from torch_geometric.data import Data\n",
    "from pymatgen.core        import Structure\n",
    "\n",
    "\n",
    "is_molecule = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7110c5c9-d0cf-4056-ada5-5c2206034939",
   "metadata": {},
   "source": [
    "## Molecules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "32f199e7-5d19-4c52-81f7-25d8dec93263",
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_molecule:\n",
    "    # Initial guess for the positions\n",
    "    solution = np.random.rand(len(nodes) * 3)*10  # Initialize all points at origin, 1D array\n",
    "    #solution = coordinates.reshape(-1, 1).ravel()\n",
    "    \n",
    "    # Function to calculate the squared difference between distances and weights\n",
    "    def objective(solution_attempt, edges, weights):\n",
    "        positions = solution_attempt.reshape(-1, 3)  # Reshape to 2D array\n",
    "        errors = 0\n",
    "        for edge, weight in zip(edges, weights):\n",
    "            p1 = positions[edge[0]]\n",
    "            p2 = positions[edge[1]]\n",
    "            distance = np.linalg.norm(p2 - p1)\n",
    "            errors += np.power(distance - weight, 2)\n",
    "        print(errors)\n",
    "        return errors\n",
    "    \n",
    "    def worst_identification(edges, attributes, solution_attempt):\n",
    "        positions = solution_attempt.reshape(-1, 3)  # Reshape to 2D array\n",
    "    \n",
    "        particle_errors = []\n",
    "        for particle in np.unique(edges):\n",
    "            # Get those edge indexes where particle has a connection\n",
    "            particle_connections = np.where((edges[:, 0] == particle) | (edges[:, 1] == particle))\n",
    "    \n",
    "            particle_error = 0\n",
    "            for idx in particle_connections[0]:\n",
    "                # Load indexes in edge\n",
    "                edge = edges[idx]\n",
    "    \n",
    "                # Load expected attribute\n",
    "                p1 = positions[edge[0]]\n",
    "                p2 = positions[edge[1]]\n",
    "    \n",
    "                # Load reference attribute\n",
    "                weight = attributes[idx].item()\n",
    "                \n",
    "                # Compute error\n",
    "                distance = np.linalg.norm(p2 - p1)\n",
    "\n",
    "                # Append to trial errors for different atom images\n",
    "                trial_error = np.power(distance - weight, 2)\n",
    "    \n",
    "                # Add error\n",
    "                particle_error += trial_error\n",
    "    \n",
    "            # Average over the connection of the node\n",
    "            particle_error /= len(particle_connections[0])\n",
    "    \n",
    "            # Append particle error\n",
    "            particle_errors.append(particle_error)\n",
    "    \n",
    "        return np.argmax(particle_errors), np.max(particle_errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff66e868-1cf3-483b-b86e-be0530df0704",
   "metadata": {},
   "source": [
    "## Crystals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f3a4e28f-83d9-4971-a5fc-3200d0ec4911",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not is_molecule:\n",
    "    # Initial guess for the lattice parameters\n",
    "    lattice_vectors = np.array([[10, 0,   0],\n",
    "                                [0,   10, 0],\n",
    "                                [0,   0,   10]])\n",
    "    \n",
    "    # Initial guess for the positions\n",
    "    initial_positions = np.random.rand(len(nodes) * 3)  # Initialize all points at origin, 1D array\n",
    "    #initial_positions = coordinates.reshape(-1, 1).ravel()\n",
    "    solution = np.concatenate([lattice_vectors.ravel(), initial_positions])\n",
    "    \n",
    "    # Function to calculate the squared difference between distances and weights\n",
    "    def objective(solution_attempt, edges, weights):\n",
    "        solution_attempt = solution_attempt.reshape(-1, 3)  # Reshape to 2D array\n",
    "        \n",
    "        lattice_vectors = solution_attempt[:3]\n",
    "        positions       = solution_attempt[3:]\n",
    "        \n",
    "        errors = 0\n",
    "        for edge, weight in zip(edges, weights):\n",
    "            p1 = positions[edge[0]]\n",
    "            p2 = positions[edge[1]]\n",
    "            \n",
    "            trial_errors = [] \n",
    "            for i in [-1, 0, 1]:\n",
    "                for j in [-1, 0, 1]:\n",
    "                    for k in [-1, 0, 1]:\n",
    "                        # i*lattice_vectors[0] + j*lattice_vectors[1] + k*lattice_vectors[2]\n",
    "                        ijk_lattice_vectors = np.sum([i, j, k] * lattice_vectors.T, axis=1)\n",
    "\n",
    "                        # Compute error\n",
    "                        distance = np.linalg.norm(p2 - p1 + ijk_lattice_vectors)\n",
    "\n",
    "                        # Append to trial errors for differente atom images\n",
    "                        trial_errors.append(np.power(distance - weight, 2))\n",
    "            errors += np.min(trial_errors)\n",
    "        #print(errors)\n",
    "        return errors\n",
    "    \n",
    "    def worst_identification(edges, attributes, solution_attempt):\n",
    "        solution_attempt = solution_attempt.reshape(-1, 3)  # Reshape to 2D array\n",
    "    \n",
    "        lattice_vectors = solution_attempt[:3]\n",
    "        positions       = solution_attempt[3:]\n",
    "    \n",
    "        particle_errors = []\n",
    "        for particle in np.unique(edges):\n",
    "            # Get those edge indexes where particle has a connection\n",
    "            particle_connections = np.where((edges[:, 0] == particle) | (edges[:, 1] == particle))\n",
    "    \n",
    "            particle_error = 0\n",
    "            for idx in particle_connections[0]:\n",
    "                # Load indexes in edge\n",
    "                edge = edges[idx]\n",
    "    \n",
    "                # Load expected attribute\n",
    "                p1 = positions[edge[0]]\n",
    "                p2 = positions[edge[1]]\n",
    "    \n",
    "                # Load reference attribute\n",
    "                weight = attributes[idx].item()\n",
    "    \n",
    "                trial_errors = []\n",
    "                for i in [-1, 0, 1]:\n",
    "                    for j in [-1, 0, 1]:\n",
    "                        for k in [-1, 0, 1]:\n",
    "                            # i*lattice_vectors[0] + j*lattice_vectors[1] + k*lattice_vectors[2]\n",
    "                            ijk_lattice_vectors = np.sum([i, j, k] * lattice_vectors.T, axis=1)\n",
    "    \n",
    "                            # Compute error\n",
    "                            distance = np.linalg.norm(p2 - p1 + ijk_lattice_vectors)\n",
    "    \n",
    "                            # Append to trial errors for different atom images\n",
    "                            trial_errors.append(np.power(distance - weight, 2))\n",
    "    \n",
    "                # Add error\n",
    "                particle_error += np.min(trial_errors)\n",
    "    \n",
    "            # Average over the connection of the node\n",
    "            particle_error /= len(particle_connections[0])\n",
    "    \n",
    "            # Append particle error\n",
    "            particle_errors.append(particle_error)\n",
    "    \n",
    "        return np.argmax(particle_errors), np.max(particle_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1d76ec67-05e8-4242-b25a-2a14bccac3b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Attempt 0\n",
      "Total: 2.309938997110655 and local 0.001681339479037708 errors\n",
      "\n",
      "Attempt 1\n",
      "Total: 2.306763882561487 and local 0.0016847482113030656 errors\n",
      "\n",
      "Attempt 2\n",
      "Total: 2.2954953720193885 and local 0.0015095455800962466 errors\n",
      "\n",
      "Attempt 3\n",
      "Total: 2.294899020058665 and local 0.001505644310177865 errors\n",
      "\n",
      "Attempt 4\n",
      "Total: 2.295161097717207 and local 0.0015100120370680605 errors\n",
      "\n",
      "Attempt 5\n",
      "Total: 2.2971136478068925 and local 0.0014992801363405389 errors\n",
      "\n",
      "Attempt 6\n",
      "Total: 2.289032667962247 and local 0.0015065632586896236 errors\n",
      "\n",
      "Attempt 7\n",
      "Total: 2.2890327985574106 and local 0.001504973148908069 errors\n",
      "\n",
      "Attempt 8\n",
      "Total: 2.289088239771534 and local 0.001518590576754965 errors\n",
      "\n",
      "Attempt 9\n",
      "Total: 2.3340758185522983 and local 0.0015462482662238137 errors\n",
      "\n",
      "Attempt 10\n",
      "Total: 2.293514373688564 and local 0.0015288544798004891 errors\n",
      "\n",
      "Attempt 11\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m()\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAttempt \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattempt\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m solution \u001b[38;5;241m=\u001b[39m \u001b[43mminimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msolution\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m                    \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43medges\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mPowell\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m is_success       \u001b[38;5;241m=\u001b[39m solution\u001b[38;5;241m.\u001b[39msuccess\n\u001b[1;32m     11\u001b[0m solution_message \u001b[38;5;241m=\u001b[39m solution\u001b[38;5;241m.\u001b[39mmessage\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/scipy/optimize/_minimize.py:701\u001b[0m, in \u001b[0;36mminimize\u001b[0;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[1;32m    698\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_neldermead(fun, x0, args, callback, bounds\u001b[38;5;241m=\u001b[39mbounds,\n\u001b[1;32m    699\u001b[0m                                \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n\u001b[1;32m    700\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m meth \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpowell\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 701\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43m_minimize_powell\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbounds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    702\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m meth \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcg\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    703\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_cg(fun, x0, args, jac, callback, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/scipy/optimize/_optimize.py:3507\u001b[0m, in \u001b[0;36m_minimize_powell\u001b[0;34m(func, x0, args, callback, bounds, xtol, ftol, maxiter, maxfev, disp, direc, return_all, **unknown_options)\u001b[0m\n\u001b[1;32m   3505\u001b[0m direc1 \u001b[38;5;241m=\u001b[39m direc[i]\n\u001b[1;32m   3506\u001b[0m fx2 \u001b[38;5;241m=\u001b[39m fval\n\u001b[0;32m-> 3507\u001b[0m fval, x, direc1 \u001b[38;5;241m=\u001b[39m \u001b[43m_linesearch_powell\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdirec1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3508\u001b[0m \u001b[43m                                     \u001b[49m\u001b[43mtol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxtol\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3509\u001b[0m \u001b[43m                                     \u001b[49m\u001b[43mlower_bound\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlower_bound\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3510\u001b[0m \u001b[43m                                     \u001b[49m\u001b[43mupper_bound\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mupper_bound\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3511\u001b[0m \u001b[43m                                     \u001b[49m\u001b[43mfval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (fx2 \u001b[38;5;241m-\u001b[39m fval) \u001b[38;5;241m>\u001b[39m delta:\n\u001b[1;32m   3513\u001b[0m     delta \u001b[38;5;241m=\u001b[39m fx2 \u001b[38;5;241m-\u001b[39m fval\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/scipy/optimize/_optimize.py:3183\u001b[0m, in \u001b[0;36m_linesearch_powell\u001b[0;34m(func, p, xi, tol, lower_bound, upper_bound, fval)\u001b[0m\n\u001b[1;32m   3180\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ((fval, p, xi) \u001b[38;5;28;01mif\u001b[39;00m fval \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m (func(p), p, xi))\n\u001b[1;32m   3181\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m lower_bound \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m upper_bound \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3182\u001b[0m     \u001b[38;5;66;03m# non-bounded minimization\u001b[39;00m\n\u001b[0;32m-> 3183\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43m_recover_from_bracket_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_minimize_scalar_brent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3184\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43mmyfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxtol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtol\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3185\u001b[0m     alpha_min, fret \u001b[38;5;241m=\u001b[39m res\u001b[38;5;241m.\u001b[39mx, res\u001b[38;5;241m.\u001b[39mfun\n\u001b[1;32m   3186\u001b[0m     xi \u001b[38;5;241m=\u001b[39m alpha_min \u001b[38;5;241m*\u001b[39m xi\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/scipy/optimize/_optimize.py:3076\u001b[0m, in \u001b[0;36m_recover_from_bracket_error\u001b[0;34m(solver, fun, bracket, args, **options)\u001b[0m\n\u001b[1;32m   3057\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_recover_from_bracket_error\u001b[39m(solver, fun, bracket, args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions):\n\u001b[1;32m   3058\u001b[0m     \u001b[38;5;66;03m# `bracket` was originally written without checking whether the resulting\u001b[39;00m\n\u001b[1;32m   3059\u001b[0m     \u001b[38;5;66;03m# bracket is valid. `brent` and `golden` built on top of it without\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3073\u001b[0m     \u001b[38;5;66;03m# storing the information needed by `minimize_scalar` in the error object,\u001b[39;00m\n\u001b[1;32m   3074\u001b[0m     \u001b[38;5;66;03m# and intercepting it here.\u001b[39;00m\n\u001b[1;32m   3075\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3076\u001b[0m         res \u001b[38;5;241m=\u001b[39m \u001b[43msolver\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbracket\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3077\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m BracketError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   3078\u001b[0m         msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(e)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/scipy/optimize/_optimize.py:2679\u001b[0m, in \u001b[0;36m_minimize_scalar_brent\u001b[0;34m(func, brack, args, xtol, maxiter, disp, **unknown_options)\u001b[0m\n\u001b[1;32m   2676\u001b[0m brent \u001b[38;5;241m=\u001b[39m Brent(func\u001b[38;5;241m=\u001b[39mfunc, args\u001b[38;5;241m=\u001b[39margs, tol\u001b[38;5;241m=\u001b[39mtol,\n\u001b[1;32m   2677\u001b[0m               full_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, maxiter\u001b[38;5;241m=\u001b[39mmaxiter, disp\u001b[38;5;241m=\u001b[39mdisp)\n\u001b[1;32m   2678\u001b[0m brent\u001b[38;5;241m.\u001b[39mset_bracket(brack)\n\u001b[0;32m-> 2679\u001b[0m \u001b[43mbrent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2680\u001b[0m x, fval, nit, nfev \u001b[38;5;241m=\u001b[39m brent\u001b[38;5;241m.\u001b[39mget_result(full_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   2682\u001b[0m success \u001b[38;5;241m=\u001b[39m nit \u001b[38;5;241m<\u001b[39m maxiter \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (np\u001b[38;5;241m.\u001b[39misnan(x) \u001b[38;5;129;01mor\u001b[39;00m np\u001b[38;5;241m.\u001b[39misnan(fval))\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/scipy/optimize/_optimize.py:2521\u001b[0m, in \u001b[0;36mBrent.optimize\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2519\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2520\u001b[0m     u \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m rat\n\u001b[0;32m-> 2521\u001b[0m fu \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mu\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m      \u001b[38;5;66;03m# calculate new output value\u001b[39;00m\n\u001b[1;32m   2522\u001b[0m funcalls \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   2524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (fu \u001b[38;5;241m>\u001b[39m fx):                 \u001b[38;5;66;03m# if it's bigger than current\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/scipy/optimize/_optimize.py:3176\u001b[0m, in \u001b[0;36m_linesearch_powell.<locals>.myfunc\u001b[0;34m(alpha)\u001b[0m\n\u001b[1;32m   3175\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmyfunc\u001b[39m(alpha):\n\u001b[0;32m-> 3176\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mxi\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/scipy/optimize/_optimize.py:620\u001b[0m, in \u001b[0;36m_wrap_scalar_function_maxfun_validation.<locals>.function_wrapper\u001b[0;34m(x, *wrapper_args)\u001b[0m\n\u001b[1;32m    618\u001b[0m ncalls[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# A copy of x is sent to the user function (gh13740)\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m fx \u001b[38;5;241m=\u001b[39m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mwrapper_args\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    621\u001b[0m \u001b[38;5;66;03m# Ideally, we'd like to a have a true scalar returned from f(x). For\u001b[39;00m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;66;03m# backwards-compatibility, also allow np.array([1.3]),\u001b[39;00m\n\u001b[1;32m    623\u001b[0m \u001b[38;5;66;03m# np.array([[1.3]]) etc.\u001b[39;00m\n\u001b[1;32m    624\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39misscalar(fx):\n",
      "Cell \u001b[0;32mIn[15], line 29\u001b[0m, in \u001b[0;36mobjective\u001b[0;34m(solution_attempt, edges, weights)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m]:\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m]:\n\u001b[1;32m     28\u001b[0m         \u001b[38;5;66;03m# i*lattice_vectors[0] + j*lattice_vectors[1] + k*lattice_vectors[2]\u001b[39;00m\n\u001b[0;32m---> 29\u001b[0m         ijk_lattice_vectors \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlattice_vectors\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     31\u001b[0m         \u001b[38;5;66;03m# Compute error\u001b[39;00m\n\u001b[1;32m     32\u001b[0m         distance \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mnorm(p2 \u001b[38;5;241m-\u001b[39m p1 \u001b[38;5;241m+\u001b[39m ijk_lattice_vectors)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "error_threshold = 1e-5\n",
    "\n",
    "for attempt in range(100):\n",
    "    print()\n",
    "    print(f'Attempt {attempt}')\n",
    "    solution = minimize(objective, solution,\n",
    "                        args=(edges, weights),\n",
    "                        method='Powell')\n",
    "\n",
    "    is_success       = solution.success\n",
    "    solution_message = solution.message\n",
    "    worst_particle, worst_error = worst_identification(edges, weights, solution.x)\n",
    "\n",
    "    attempt_error = objective(solution.x, edges, weights)\n",
    "    print(f'Total: {attempt_error} and local {worst_error} errors')\n",
    "\n",
    "    if attempt_error < error_threshold:\n",
    "        break\n",
    "\n",
    "    solution = solution.x.reshape(-1, 3)  # Reshape to 2D array\n",
    "\n",
    "    # Re-initialize that position\n",
    "    solution[worst_particle+3] = np.random.rand(3)\n",
    "\n",
    "    solution = solution.flatten()\n",
    "\n",
    "# Check convergence status\n",
    "if is_success:\n",
    "    print('Converged to a solution.')\n",
    "else:\n",
    "    print(f'Failed to converge: {solution_message}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "515f6a4d-8542-4695-866c-9734d739f79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "solution = solution.reshape(-1, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c66525-8a75-4c42-9a2a-a9edf135d70c",
   "metadata": {},
   "source": [
    "## Molecules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "74512108-9c89-46c6-a60c-a3f1cd5d487d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_molecule:\n",
    "    # Get the position of each atom in direct coordinates\n",
    "    #direct_positions = graph_to_cartesian_positions(graph)\n",
    "    #cartesian_positions = solution.x.reshape(-1, 3)*mw\n",
    "    #cartesian_positions = solution.x.reshape(-1, 3)\n",
    "    \n",
    "    lattice_vectors     = np.array([[10,  0,   0],\n",
    "                                    [0,   10,  0],\n",
    "                                    [0,   0,   10]])\n",
    "    cartesian_positions = solution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a292e640-09fc-4593-9782-6b022dc1f860",
   "metadata": {},
   "source": [
    "## Crystals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c905edb6-ba68-41f3-927d-cd0fc21fee33",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not is_molecule:\n",
    "    # Get the position of each atom in direct coordinates\n",
    "    #direct_positions = graph_to_cartesian_positions(graph)\n",
    "    #cartesian_positions = solution.x.reshape(-1, 3)*mw\n",
    "    \n",
    "    lattice_vectors     = solution[:3]\n",
    "    cartesian_positions = solution[3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b0709aff-bf63-4f99-ab14-e8bcabac3d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "POSCAR_name = None\n",
    "\n",
    "# Get name for the first line of the POSCAR\n",
    "POSCAR_name = POSCAR_name or 'POSCAR from GenerativeModels'\n",
    "\n",
    "# Clone the input graph to preserve the original structure\n",
    "new_graph = temp.clone()\n",
    "\n",
    "# Load and detach embeddings for the graph nodes\n",
    "data_embeddings = new_graph.x.detach().cpu().numpy()\n",
    "\n",
    "# Loading dictionary of available embeddings for atoms\n",
    "available_embeddings = {}\n",
    "with open('../MP/input/atomic_masses.dat', 'r') as atomic_masses_file:\n",
    "    for line in atomic_masses_file:\n",
    "        key, mass, charge, electronegativity, ionization_energy = line.split()\n",
    "\n",
    "        # Check if all information is present\n",
    "        if all(val != 'None' for val in (mass, charge, electronegativity, ionization_energy)):\n",
    "            available_embeddings[key] = np.array([mass, charge, electronegativity, ionization_energy], dtype=float)\n",
    "\n",
    "# Get most similar atoms for each graph node and create a list of keys\n",
    "keys = [find_closest_key(available_embeddings, emb) for emb in data_embeddings]\n",
    "\n",
    "# Get elements' composition, concentration, and positions\n",
    "POSCAR_composition, POSCAR_concentration, POSCAR_positions = composition_concentration_from_keys(keys, cartesian_positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4065eb29-e8e9-4530-a68a-dd5bf8d7dd7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write file\n",
    "with open('CONTCAR', 'w') as POSCAR_file:\n",
    "    # Delete previous data in the file\n",
    "    POSCAR_file.truncate()\n",
    "    \n",
    "    # Write POSCAR's name\n",
    "    POSCAR_file.write(f'{POSCAR_name}\\n')\n",
    "\n",
    "    # Write scaling factor (assumed to be 1.0)\n",
    "    POSCAR_file.write('1.0\\n')\n",
    "\n",
    "    # Write lattice parameters (assumed to be orthogonal)\n",
    "    np.savetxt(POSCAR_file, lattice_vectors, delimiter=' ')\n",
    "\n",
    "    # Write composition (each different species, previously sorted)\n",
    "    np.savetxt(POSCAR_file, [POSCAR_composition], fmt='%s', delimiter=' ')\n",
    "\n",
    "    # Write concentration (number of each of the previous elements)\n",
    "    np.savetxt(POSCAR_file, [POSCAR_concentration], fmt='%d', delimiter=' ')\n",
    "\n",
    "    # Write position in cartesian form\n",
    "    POSCAR_file.write('Cartesian\\n')\n",
    "    np.savetxt(POSCAR_file, POSCAR_positions, delimiter=' ')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
