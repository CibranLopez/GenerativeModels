{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a69f99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn    as nn\n",
    "import torch.optim as optim\n",
    "import GM_library  as GML\n",
    "import numpy       as np\n",
    "import torch\n",
    "\n",
    "from os                   import path, listdir\n",
    "from torch.utils.data     import random_split\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "import MP.MP_library as MPL\n",
    "\n",
    "# Checking if pytorch can run in GPU, else CPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75aa6001",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define target value to look for\n",
    "#seeked_target = ##\n",
    "\n",
    "# Machine-learning parameters\n",
    "n_epochs      = 100\n",
    "batch_size    = 128\n",
    "learning_rate = 0.0001\n",
    "\n",
    "# Number of diffusing and denoising steps\n",
    "n_t_steps = 5\n",
    "\n",
    "# Decay of parameter alpha\n",
    "noise_contribution = 0.15\n",
    "alpha_decay = 0.5 * (1 - noise_contribution**2)\n",
    "\n",
    "# Dropouts for node and edge models (independent of each other)\n",
    "dropout_node = 0.2\n",
    "dropout_edge = 0.2\n",
    "\n",
    "# Define box shape\n",
    "L = [40, 40, 40]\n",
    "\n",
    "# Target to generate new crystals\n",
    "target = 'GM_EPA'\n",
    "\n",
    "# In case database is created from scratch (otherwise, it is not being used)\n",
    "DB_path = '../MP/Loaded_EMP'\n",
    "\n",
    "input_folder    = 'models'\n",
    "target_folder   = f'{input_folder}/{target}'\n",
    "edge_model_name = f'{target_folder}/edge_model.pt'\n",
    "node_model_name = f'{target_folder}/node_model.pt'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4946b2e8",
   "metadata": {},
   "source": [
    "# Generation of graph database for training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b5cbe57",
   "metadata": {},
   "source": [
    "Load the datasets, already standarized if possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85dcaa99",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_name         = f'{target_folder}/labels.pt'\n",
    "dataset_name        = f'{target_folder}/dataset.pt'\n",
    "dataset_name_std    = f'{target_folder}/standardized_dataset.pt'\n",
    "parameters_name_std = f'{target_folder}/standardized_parameters.pt'  # Parameters for rescaling the predictions\n",
    "\n",
    "if path.exists(dataset_name_std) and path.exists(parameters_name_std) and path.exists(labels_name):\n",
    "    # Load the standardized dataset, with corresponding labels and parameters\n",
    "    dataset    = torch.load(dataset_name_std)\n",
    "    labels     = torch.load(labels_name)\n",
    "    parameters = torch.load(parameters_name_std)\n",
    "\n",
    "    # Assigning parameters accordingly\n",
    "    target_mean, feat_mean, edge_mean, target_std, edge_std, feat_std, scale = parameters\n",
    "    \n",
    "    # Defining target factor\n",
    "    target_factor = target_std / scale\n",
    "\n",
    "elif path.exists(dataset_name) and path.exists(labels_name):\n",
    "    # Load the raw dataset, with corresponding labels, and standardize it\n",
    "    dataset = torch.load(dataset_name)\n",
    "    labels  = torch.load(labels_name)\n",
    "    \n",
    "    # Standardize dataset\n",
    "    dataset, parameters = GML.standardize_dataset(dataset, labels)\n",
    "    \n",
    "    # Save standardized dataset\n",
    "    torch.save(dataset,    dataset_name_std)\n",
    "    torch.save(parameters, parameters_name_std)\n",
    "\n",
    "else:\n",
    "    # Generate the raw dataset from scratch, and standardize it\n",
    "    \n",
    "    # Read all mateials within the database\n",
    "    materials = listdir(DB_path)[:50]\n",
    "    \n",
    "    dataset = []\n",
    "    labels  = []\n",
    "    for material in materials:\n",
    "        try:\n",
    "            # Try to read the polyforms\n",
    "            polymorfs = listdir(f'{DB_path}/{material}')\n",
    "        except:\n",
    "            continue\n",
    "        \n",
    "        print(material)\n",
    "        for polymorf in polymorfs:\n",
    "            # Path to folder containing the POSCAR\n",
    "            path_to_POSCAR = f'{DB_path}/{material}/{polymorf}'\n",
    "            \n",
    "            # Check that the folder is valid\n",
    "            if path.exists(f'{path_to_POSCAR}/POSCAR'):\n",
    "                print(f'\\t{polymorf}')\n",
    "\n",
    "                # Extract parameters from POSCAR\n",
    "                cell, composition, concentration, positions = MPL.information_from_VASPfile(path_to_POSCAR,\n",
    "                                                                                            'POSCAR')\n",
    "\n",
    "                # Generate POSCAR covering the box\n",
    "                try:\n",
    "                    nodes, edges, attributes, _, _, _ = GML.graph_POSCAR_encoding(cell,\n",
    "                                                                                  composition,\n",
    "                                                                                  concentration,\n",
    "                                                                                  positions,\n",
    "                                                                                  L)\n",
    "                except:\n",
    "                    print(f'Error: {material} {polymorf} not loaded')\n",
    "                    continue\n",
    "\n",
    "                # Load ground state energy per atom\n",
    "                gs_energy = float(np.loadtxt(f'{path_to_POSCAR}/EPA'))\n",
    "\n",
    "                # Construct temporal graph structure\n",
    "                graph = Data(x=nodes,\n",
    "                             edge_index=edges,\n",
    "                             edge_attr=attributes,\n",
    "                             y=torch.tensor([[gs_energy]], dtype=torch.float)\n",
    "                            )\n",
    "\n",
    "                # Append to dataset and labels\n",
    "                dataset.append(graph)\n",
    "                labels.append(f'{material}-{polymorf}')\n",
    "    \n",
    "    # Standardize dataset\n",
    "    dataset, parameters = GML.standardize_dataset(dataset, labels)\n",
    "    \n",
    "    # Save standardized dataset\n",
    "    torch.save(dataset,    dataset_name_std)\n",
    "    torch.save(parameters, parameters_name_std)\n",
    "    torch.save(labels,     labels_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e59715",
   "metadata": {},
   "source": [
    "# Definition of train-test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96173a78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training graphs: 48\n",
      "Number of testing  graphs: 13\n"
     ]
    }
   ],
   "source": [
    "# torch.manual_seed(12345)\n",
    "\n",
    "# Define the sizes of the train and test sets\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size  = len(dataset) - train_size\n",
    "\n",
    "# Use random_split() to generate train and test sets\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "print(f'Number of training graphs: {len(train_dataset)}')\n",
    "print(f'Number of testing  graphs: {len(test_dataset)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a76fc0",
   "metadata": {},
   "source": [
    "# Training of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f86aed2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Node GCNN:\n",
      "nGCNN(\n",
      "  (conv1): GraphConv(5, 64)\n",
      "  (conv2): GraphConv(64, 64)\n",
      "  (conv3): GraphConv(64, 5)\n",
      ")\n",
      "\n",
      "Edge GCNN:\n",
      "eGCNN(\n",
      "  (linear1): Linear(in_features=5, out_features=32, bias=True)\n",
      "  (linear2): Linear(in_features=32, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Determine number of features in dataset, considering the t_step information\n",
    "n_features = dataset[0].num_node_features + 1\n",
    "\n",
    "# Instantiate the models for nodes and edges\n",
    "node_model = GML.nGCNN(n_features, dropout_node).to(device)\n",
    "edge_model = GML.eGCNN(n_features, dropout_edge).to(device)\n",
    "print('\\nNode GCNN:')\n",
    "print(node_model)\n",
    "print('\\nEdge GCNN:')\n",
    "print(edge_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1029b6f5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Train Loss: 336923682473038.8125\n",
      "Epoch: 2, Train Loss: 37992409348294.3516\n",
      "Epoch: 3, Train Loss: 20036061613594.3398\n",
      "Epoch: 4, Train Loss: 14038385700828.2207\n",
      "Epoch: 5, Train Loss: 10730788405295.3086\n",
      "Epoch: 6, Train Loss: 9210179850768.9863\n",
      "Epoch: 7, Train Loss: 8157680522187.2188\n",
      "Epoch: 8, Train Loss: 7180978797422.7412\n",
      "Epoch: 9, Train Loss: 6510316808158.1455\n",
      "Epoch: 10, Train Loss: 6097583359231.9561\n",
      "Epoch: 11, Train Loss: 5487054094763.1748\n",
      "Epoch: 12, Train Loss: 5101804977284.4893\n",
      "Epoch: 13, Train Loss: 4703714664164.7188\n",
      "Epoch: 14, Train Loss: 4735114579175.4043\n",
      "Epoch: 15, Train Loss: 4668523177814.9980\n",
      "Epoch: 16, Train Loss: 4312617277929.4502\n",
      "Epoch: 17, Train Loss: 3811088469651.4644\n",
      "Epoch: 18, Train Loss: 4205734433153.4541\n",
      "Epoch: 19, Train Loss: 3824657912955.6333\n",
      "Epoch: 20, Train Loss: 3371807702054.7666\n",
      "Epoch: 21, Train Loss: 3235998890521.5874\n",
      "Epoch: 22, Train Loss: 4222005213186.9834\n",
      "Epoch: 23, Train Loss: 3312771145418.8623\n",
      "Epoch: 24, Train Loss: 3486509227042.6460\n",
      "Epoch: 25, Train Loss: 3763442695399.7437\n",
      "Epoch: 26, Train Loss: 4085299056135.9312\n",
      "Epoch: 27, Train Loss: 3812129105696.4688\n",
      "Epoch: 28, Train Loss: 3483058641903.9248\n",
      "Epoch: 29, Train Loss: 3477495987662.1084\n",
      "Epoch: 30, Train Loss: 3298871889249.4751\n",
      "Epoch: 31, Train Loss: 1800243037991.4792\n",
      "Epoch: 32, Train Loss: 3142670670324.6626\n",
      "Epoch: 33, Train Loss: 3416186690108.2710\n",
      "Epoch: 34, Train Loss: 4561330288766.4961\n",
      "Epoch: 35, Train Loss: 3400438796341.8208\n",
      "Epoch: 36, Train Loss: 2491641845630.5498\n",
      "Epoch: 37, Train Loss: 2120639672263.6812\n",
      "Epoch: 38, Train Loss: 2029103402947.3813\n",
      "Epoch: 39, Train Loss: 2091583464579.6125\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [9], line 56\u001b[0m\n\u001b[1;32m     53\u001b[0m x_j \u001b[38;5;241m=\u001b[39m graph_t\u001b[38;5;241m.\u001b[39mx[graph_t\u001b[38;5;241m.\u001b[39medge_index[\u001b[38;5;241m1\u001b[39m]]\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# Perform a single forward pass for predicting edge attributes\u001b[39;00m\n\u001b[0;32m---> 56\u001b[0m out_attr \u001b[38;5;241m=\u001b[39m \u001b[43medge_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_i\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_j\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;66;03m# Construct noise graph\u001b[39;00m\n\u001b[1;32m     59\u001b[0m pred_epsilon_t \u001b[38;5;241m=\u001b[39m Data(x\u001b[38;5;241m=\u001b[39mout_x,\n\u001b[1;32m     60\u001b[0m                       edge_index\u001b[38;5;241m=\u001b[39mgraph_t\u001b[38;5;241m.\u001b[39medge_index,\n\u001b[1;32m     61\u001b[0m                       edge_attr\u001b[38;5;241m=\u001b[39mout_attr\u001b[38;5;241m.\u001b[39mravel())\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Work/UPC/GenerativeModels/GM_library.py:612\u001b[0m, in \u001b[0;36meGCNN.forward\u001b[0;34m(self, x_i, x_j)\u001b[0m\n\u001b[1;32m    609\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mrelu()\n\u001b[1;32m    611\u001b[0m \u001b[38;5;66;03m# Dropout layer (only for training)\u001b[39;00m\n\u001b[0;32m--> 612\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpdropout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    614\u001b[0m \u001b[38;5;66;03m# Last linear convolution\u001b[39;00m\n\u001b[1;32m    615\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear2(x)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/functional.py:1252\u001b[0m, in \u001b[0;36mdropout\u001b[0;34m(input, p, training, inplace)\u001b[0m\n\u001b[1;32m   1250\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m p \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0.0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m p \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1.0\u001b[39m:\n\u001b[1;32m   1251\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdropout probability has to be between 0 and 1, \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(p))\n\u001b[0;32m-> 1252\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _VF\u001b[38;5;241m.\u001b[39mdropout_(\u001b[38;5;28minput\u001b[39m, p, training) \u001b[38;5;28;01mif\u001b[39;00m inplace \u001b[38;5;28;01melse\u001b[39;00m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Initialize the optimizers\n",
    "node_optimizer = torch.optim.Adam(node_model.parameters(), lr=learning_rate)\n",
    "edge_optimizer = torch.optim.Adam(edge_model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Training loop\n",
    "train_losses = []\n",
    "for epoch in range(n_epochs):\n",
    "    # Initialize train loss variable\n",
    "    train_loss = 0\n",
    "    graph_counter = 0\n",
    "    for graph in train_dataset:\n",
    "        # Count new graph\n",
    "        graph_counter += 1\n",
    "        \n",
    "        #print()\n",
    "        #print(f'Graph: {graph_counter}')\n",
    "        # Clone existing graph\n",
    "        graph_0 = graph.clone()\n",
    "        \n",
    "        # Initialize the gradient of the optimizers\n",
    "        node_optimizer.zero_grad()\n",
    "        edge_optimizer.zero_grad()\n",
    "        \n",
    "        # Start denoising-diffusing process\n",
    "        for t_step in np.arange(1, n_t_steps+1):\n",
    "            # Diffuse the graph with some noise\n",
    "            #print()\n",
    "            #print(f'Step: {t_step}')\n",
    "            #print('Diffusing...')\n",
    "            \n",
    "            graph_t, epsilon_t = GML.diffusion_step(graph_0, t_step, n_t_steps, alpha_decay)\n",
    "            \n",
    "            # Update diffused graph as next one\n",
    "            graph_0 = graph_t.clone()\n",
    "\n",
    "            # Denoise the diffused graph\n",
    "            #print(f'Denoising...')\n",
    "            \n",
    "            # Add t_step information to graph_t\n",
    "            graph_t = GML.add_t_information(graph_t, t_step)\n",
    "\n",
    "            # Perform a single forward pass for predicting node features\n",
    "            out_x = node_model(graph_t.x,\n",
    "                               graph_t.edge_index,\n",
    "                               graph_t.edge_attr)\n",
    "            \n",
    "            \n",
    "            # Remove t_step information\n",
    "            out_x = out_x[:, :-1]\n",
    "\n",
    "            # Define x_i and x_j as features of every corresponding pair of nodes (same order than attributes)\n",
    "            x_i = graph_t.x[graph_t.edge_index[0]]\n",
    "            x_j = graph_t.x[graph_t.edge_index[1]]\n",
    "\n",
    "            # Perform a single forward pass for predicting edge attributes\n",
    "            out_attr = edge_model(x_i, x_j)\n",
    "\n",
    "            # Construct noise graph\n",
    "            pred_epsilon_t = Data(x=out_x,\n",
    "                                  edge_index=graph_t.edge_index,\n",
    "                                  edge_attr=out_attr.ravel())\n",
    "            \n",
    "            # Backpropagation and optimization step\n",
    "            #print('Backpropagating...')\n",
    "\n",
    "            # Calculate the loss for node features and edge attributes\n",
    "            node_loss, edge_loss = GML.get_graph_losses(epsilon_t, pred_epsilon_t)\n",
    "\n",
    "            # Backpropagate node and edge losses (retained graph, as it is used two times)\n",
    "            node_loss.backward(retain_graph=True)\n",
    "            edge_loss.backward(retain_graph=True)\n",
    "\n",
    "            # Perform a single step for each optimized\n",
    "            node_optimizer.step()\n",
    "            edge_optimizer.step()\n",
    "\n",
    "            # Predict target for current graph\n",
    "            #predicted_target = ###\n",
    "\n",
    "            # Compute target loss\n",
    "            #target_loss = GML.get_target_loss(predicted_target, seeked_target)\n",
    "            target_loss = 0\n",
    "\n",
    "            # Accumulate the total training loss\n",
    "            loss = node_loss + edge_loss + target_loss\n",
    "            train_loss += loss.item()\n",
    "    \n",
    "    # Compute the average train loss\n",
    "    train_loss = train_loss / (len(train_dataset) * n_t_steps)\n",
    "    train_losses.append(train_loss)\n",
    "    \n",
    "    print(f'Epoch: {epoch+1}, Train Loss: {train_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "537fce1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(edge_model.state_dict(), edge_model_name)\n",
    "torch.save(node_model.state_dict(), node_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bd3a3dd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f158943ce50>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(np.log(train_losses))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
