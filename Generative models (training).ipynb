{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a69f99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn    as nn\n",
    "import torch.optim as optim\n",
    "import numpy       as np\n",
    "import torch\n",
    "import json\n",
    "import os\n",
    "\n",
    "from libraries.model      import nGCNN, eGCNN, diffusion_step, add_features_to_graph, get_graph_losses\n",
    "from libraries.dataset    import standardize_dataset\n",
    "from libraries.graph      import graph_POSCAR_encoding\n",
    "from torch.utils.data     import random_split\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "# Checking if pytorch can run in GPU, else CPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "686ad446",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on adding and removing noise to materials\n",
    "# the models is able to learn hidded patterns\n",
    "# It can be trained regarding some target property"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33a85832",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In case database is created from scratch (otherwise, it is not being used)\n",
    "DB_path = '../MP/Loaded_PT'\n",
    "\n",
    "# Define folder in which all data will be stored\n",
    "target_folder    = 'models/GM_BiSI'\n",
    "edge_model_name = f'{target_folder}/edge_model.pt'\n",
    "node_model_name = f'{target_folder}/node_model.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75aa6001",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define target value to look for\n",
    "#seeked_target = ##\n",
    "\n",
    "# Machine-learning parameters\n",
    "n_epochs      = 3000\n",
    "batch_size    = 32\n",
    "learning_rate = 0.0001\n",
    "\n",
    "# Ratios for dividing training data\n",
    "test_ratio = 0.0\n",
    "\n",
    "# Number of diffusing and denoising steps\n",
    "n_t_steps = 1\n",
    "\n",
    "# Decay of parameter alpha\n",
    "noise_contribution = 0.15\n",
    "alpha_decay = 0.5 * (1 - noise_contribution**2)\n",
    "\n",
    "# Dropouts for node and edge models (independent of each other)\n",
    "dropout_node = 0.2\n",
    "dropout_edge = 0.2\n",
    "\n",
    "# Create and save as a dictionary\n",
    "model_parameters = {\n",
    "    'n_epochs':           n_epochs,\n",
    "    'batch_size':         batch_size,\n",
    "    'learning_rate':      learning_rate,\n",
    "    'test_ratio':         test_ratio,\n",
    "    'n_t_steps':          n_t_steps,\n",
    "    'noise_contribution': noise_contribution,\n",
    "    'dropout_node':       dropout_node,\n",
    "    'dropout_edge':       dropout_edge\n",
    "}\n",
    "\n",
    "# Write the dictionary to the file in JSON format\n",
    "with open(f'{target_folder}/model_parameters.json', 'w') as json_file:\n",
    "    json.dump(model_parameters, json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4946b2e8",
   "metadata": {},
   "source": [
    "# Generation of graph database for training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b5cbe57",
   "metadata": {},
   "source": [
    "Load the datasets, already standardized if possible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c70e2b",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "labels_name                 = f'{target_folder}/labels.pt'\n",
    "dataset_name                = f'{target_folder}/dataset.pt'\n",
    "dataset_name_std            = f'{target_folder}/standardized_dataset.pt'\n",
    "dataset_parameters_name_std = f'{target_folder}/standardized_dataset_parameters.json'\n",
    "\n",
    "if os.path.exists(dataset_name_std) and os.path.exists(dataset_parameters_name_std) and os.path.exists(labels_name):\n",
    "    # Load the standardized dataset, with corresponding labels and parameters\n",
    "    dataset = torch.load(dataset_name_std)\n",
    "    labels  = torch.load(labels_name)\n",
    "    \n",
    "    # Load the data from the JSON file\n",
    "    with open(dataset_parameters_name_std, 'r') as json_file:\n",
    "        numpy_dict = json.load(json_file)\n",
    "\n",
    "    # Convert NumPy arrays back to PyTorch tensors\n",
    "    dataset_parameters = {key: torch.tensor(value) for key, value in numpy_dict.items()}\n",
    "\n",
    "elif os.path.exists(dataset_name) and os.path.exists(labels_name):\n",
    "    # Load the raw dataset, with corresponding labels, and standardize it\n",
    "    dataset = torch.load(dataset_name)\n",
    "    labels  = torch.load(labels_name)\n",
    "    \n",
    "    # Standardize dataset\n",
    "    dataset, dataset_parameters = standardize_dataset(dataset)\n",
    "    \n",
    "    # Save standardized dataset\n",
    "    torch.save(dataset, dataset_name_std)\n",
    "    \n",
    "    # Convert torch tensors to numpy arrays\n",
    "    numpy_dict = {key: value.cpu().numpy().tolist() for key, value in dataset_parameters.items()}\n",
    "\n",
    "    # Dump the dictionary with numpy arrays to a JSON file\n",
    "    with open(parameters_name_std, 'w') as json_file:\n",
    "        json.dump(numpy_dict, json_file)\n",
    "\n",
    "else:\n",
    "    # Generate the raw dataset from scratch, and standardize it\n",
    "    \n",
    "    # Read all mateials within the database\n",
    "    materials = os.listdir(DB_path)\n",
    "    \n",
    "    dataset = []\n",
    "    labels  = []\n",
    "    for material in materials:\n",
    "        try:\n",
    "            # Try to read the polyforms\n",
    "            polymorfs = os.listdir(f'{DB_path}/{material}')\n",
    "        except:\n",
    "            continue\n",
    "        \n",
    "        print(material)\n",
    "        for polymorf in polymorfs:\n",
    "            # Path to folder containing the POSCAR\n",
    "            path_to_POSCAR = f'{DB_path}/{material}/{polymorf}'\n",
    "            \n",
    "            # Check that the folder is valid\n",
    "            if os.path.exists(f'{path_to_POSCAR}/POSCAR'):\n",
    "                print(f'\\t{polymorf}')\n",
    "\n",
    "                # Extract parameters from POSCAR\n",
    "                cell, composition, concentration, positions = MPL.information_from_VASPfile(path_to_POSCAR,\n",
    "                                                                                            'POSCAR')\n",
    "\n",
    "                # Generate POSCAR covering the box\n",
    "                try:\n",
    "                    nodes, edges, attributes, _, _, _ = graph_POSCAR_encoding(cell,\n",
    "                                                                                  composition,\n",
    "                                                                                  concentration,\n",
    "                                                                                  positions,\n",
    "                                                                                  L)\n",
    "                except:\n",
    "                    print(f'Error: {material} {polymorf} not loaded')\n",
    "                    continue\n",
    "\n",
    "                # Load ground state energy per atom\n",
    "                gs_energy = float(np.loadtxt(f'{path_to_POSCAR}/EPA'))\n",
    "\n",
    "                # Construct temporal graph structure\n",
    "                graph = Data(x=nodes,\n",
    "                             edge_index=edges,\n",
    "                             edge_attr=attributes,\n",
    "                             y=torch.tensor([[gs_energy]], dtype=torch.float)\n",
    "                            )\n",
    "\n",
    "                # Append to dataset and labels\n",
    "                dataset.append(graph)\n",
    "                labels.append(f'{material}-{polymorf}')\n",
    "    \n",
    "    # Standardize dataset\n",
    "    dataset, dataset_parameters = standardize_dataset(dataset)\n",
    "    \n",
    "    # Save standardized dataset\n",
    "    torch.save(dataset, dataset_name_std)\n",
    "    torch.save(labels,  labels_name)\n",
    "    \n",
    "    # Convert torch tensors to numpy arrays\n",
    "    numpy_dict = {key: value.cpu().numpy().tolist() for key, value in dataset_parameters.items()}\n",
    "\n",
    "    # Dump the dictionary with numpy arrays to a JSON file\n",
    "    with open(dataset_parameters_name_std, 'w') as json_file:\n",
    "        json.dump(numpy_dict, json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1439db4c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BiSBr\n",
      "\n",
      "BiSeBr\n",
      "\n",
      "BiSeI\n",
      "\n",
      "BiSI\n",
      "\tas_1_Bi_on_S_-1\n",
      "Error: vasprun not correctly loaded.\n",
      "Error: vasprun not correctly loaded.\n",
      "Error: vasprun not correctly loaded.\n",
      "Error: vasprun not correctly loaded.\n",
      "Error: vasprun not correctly loaded.\n",
      "Error: vasprun not correctly loaded.\n",
      "\tas_1_Bi_on_S_-2\n",
      "Error: vasprun not correctly loaded.\n",
      "Error: vasprun not correctly loaded.\n",
      "Error: vasprun not correctly loaded.\n",
      "Error: vasprun not correctly loaded.\n",
      "Error: vasprun not correctly loaded.\n",
      "\tas_1_Bi_on_S_0\n",
      "\tas_1_Bi_on_S_1\n",
      "Error: vasprun not correctly loaded.\n",
      "Error: vasprun not correctly loaded.\n",
      "Error: vasprun not correctly loaded.\n",
      "Error: vasprun not correctly loaded.\n",
      "\tas_1_Bi_on_S_2\n",
      "Error: vasprun not correctly loaded.\n",
      "Error: vasprun not correctly loaded.\n",
      "Error: vasprun not correctly loaded.\n",
      "Error: vasprun not correctly loaded.\n",
      "\tas_1_Bi_on_S_3\n",
      "Error: vasprun not correctly loaded.\n",
      "\tas_1_Bi_on_S_4\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 106\u001b[0m\n\u001b[1;32m    100\u001b[0m temp_energy    \u001b[38;5;241m=\u001b[39m vasprun\u001b[38;5;241m.\u001b[39mionic_steps[ionic_step_idx][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124me_fr_energy\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    102\u001b[0m \u001b[38;5;66;03m# Save temp_structure to POSCAR\u001b[39;00m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;66;03m#temp_Poscar = Poscar(temp_structure)\u001b[39;00m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;66;03m#temp_Poscar.write_file('POSCAR')\u001b[39;00m\n\u001b[0;32m--> 106\u001b[0m nodes, edges, attributes \u001b[38;5;241m=\u001b[39m \u001b[43mgraph_POSCAR_encoding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtemp_structure\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;66;03m# Construct temporal graph structure\u001b[39;00m\n\u001b[1;32m    109\u001b[0m graph \u001b[38;5;241m=\u001b[39m Data(x\u001b[38;5;241m=\u001b[39mnodes,\n\u001b[1;32m    110\u001b[0m              edge_index\u001b[38;5;241m=\u001b[39medges,\n\u001b[1;32m    111\u001b[0m              edge_attr\u001b[38;5;241m=\u001b[39mattributes,\n\u001b[1;32m    112\u001b[0m              y\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mtensor([[temp_energy]], dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat)\n\u001b[1;32m    113\u001b[0m             )\n",
      "File \u001b[0;32m~/Work/UPC/GenerativeModels/libraries/graph.py:368\u001b[0m, in \u001b[0;36mgraph_POSCAR_encoding\u001b[0;34m(structure, encoding_type)\u001b[0m\n\u001b[1;32m    364\u001b[0m         ionization_energies[key] \u001b[38;5;241m=\u001b[39m ionization_energy\n\u001b[1;32m    366\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m encoding_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvoronoi\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    367\u001b[0m     \u001b[38;5;66;03m# Get edges and attributes for the corresponding tessellation\u001b[39;00m\n\u001b[0;32m--> 368\u001b[0m     nodes, edges, attributes \u001b[38;5;241m=\u001b[39m \u001b[43mget_voronoi_tessellation\u001b[49m\u001b[43m(\u001b[49m\u001b[43matomic_masses\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    369\u001b[0m \u001b[43m                                                        \u001b[49m\u001b[43mcharges\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    370\u001b[0m \u001b[43m                                                        \u001b[49m\u001b[43melectronegativities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    371\u001b[0m \u001b[43m                                                        \u001b[49m\u001b[43mionization_energies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    372\u001b[0m \u001b[43m                                                        \u001b[49m\u001b[43mstructure\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    374\u001b[0m     \u001b[38;5;66;03m# Convert to torch tensors and return\u001b[39;00m\n\u001b[1;32m    375\u001b[0m     nodes      \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(nodes,      dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat)\n",
      "File \u001b[0;32m~/Work/UPC/GenerativeModels/libraries/graph.py:254\u001b[0m, in \u001b[0;36mget_voronoi_tessellation\u001b[0;34m(atomic_masses, charges, electronegativities, ionization_energies, structure)\u001b[0m\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m np\u001b[38;5;241m.\u001b[39many(frac_coords_uc \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m): frac_coords_uc[np\u001b[38;5;241m.\u001b[39mwhere(frac_coords_uc \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    253\u001b[0m \u001b[38;5;66;03m# Obtain mapping to index in unit cell\u001b[39;00m\n\u001b[0;32m--> 254\u001b[0m uc_idx \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmin(np\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mnorm(\u001b[43mstructure\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrac_coords\u001b[49m \u001b[38;5;241m-\u001b[39m frac_coords_uc, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m    256\u001b[0m \u001b[38;5;66;03m# Generate dictionary storing relevant information of the atom\u001b[39;00m\n\u001b[1;32m    257\u001b[0m atom_info \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    258\u001b[0m     atom_idx: {\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124matom\u001b[39m\u001b[38;5;124m'\u001b[39m:           atom,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    263\u001b[0m     }\n\u001b[1;32m    264\u001b[0m }\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pymatgen/core/structure.py:1388\u001b[0m, in \u001b[0;36mIStructure.frac_coords\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1385\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m   1386\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrac_coords\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   1387\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Fractional coordinates as a Nx3 numpy array.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1388\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray([site\u001b[38;5;241m.\u001b[39mfrac_coords \u001b[38;5;28;01mfor\u001b[39;00m site \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m])\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "labels_name                 = f'{target_folder}/labels.pt'\n",
    "dataset_name                = f'{target_folder}/dataset.pt'\n",
    "dataset_name_std            = f'{target_folder}/standardized_dataset.pt'\n",
    "dataset_parameters_name_std = f'{target_folder}/standardized_dataset_parameters.json'\n",
    "\n",
    "from pymatgen.io.vasp.inputs  import Poscar\n",
    "from pymatgen.io.vasp.outputs import Vasprun\n",
    "\n",
    "import sys\n",
    "sys.path.append('../../UCL/m3gnet')\n",
    "import ML_library as MLL\n",
    "\n",
    "dataset = []\n",
    "labels  = []\n",
    "\n",
    "### Loaded database ###\n",
    "\n",
    "data_path = 'Loaded_BiSI/gamma'\n",
    "\n",
    "# Iterate over materials and relaxations in the dataset\n",
    "while len(dataset) < 200:\n",
    "    for material in os.listdir(data_path):\n",
    "        # Define path to material\n",
    "        path_to_material = f'{data_path}/{material}'\n",
    "\n",
    "        # Check if it is a folder\n",
    "        if not os.path.isdir(path_to_material):\n",
    "            continue\n",
    "\n",
    "        print()\n",
    "        print(material)\n",
    "\n",
    "        # Get relaxations steps (rel1, rel2...)\n",
    "        relaxation_steps = os.listdir(path_to_material)\n",
    "\n",
    "        # Determine all defect states across every folder\n",
    "        defect_states = []\n",
    "        for relaxation_step in relaxation_steps:\n",
    "            path_to_relaxation_step = f'{path_to_material}/{relaxation_step}'\n",
    "            if os.path.isdir(path_to_relaxation_step):\n",
    "                for defect_state in os.listdir(path_to_relaxation_step):\n",
    "                    if os.path.isdir(f'{path_to_material}/{relaxation_step}/{defect_state}'):\n",
    "                        defect_states.append(defect_state)\n",
    "\n",
    "        # Determine unique defect states across every folder\n",
    "        unique_defect_states = np.unique(defect_states)\n",
    "\n",
    "        # Run over all defect states\n",
    "        for defect_state in unique_defect_states:\n",
    "            print(f'\\t{defect_state}')\n",
    "\n",
    "            # Run over all relaxation steps\n",
    "            for relaxation_step in relaxation_steps:\n",
    "                # Define path to relaxation loading every relaxation step of a same defect state in the same data column\n",
    "                path_to_deformation = f'{path_to_material}/{relaxation_step}/{defect_state}'\n",
    "\n",
    "                # Avoiding non-directories (such as .DS_Store)\n",
    "                if not os.path.isdir(path_to_deformation):\n",
    "                    continue\n",
    "\n",
    "                # Define name for the defect state folder\n",
    "                temp_relaxation = f'{material}_{defect_state}'\n",
    "\n",
    "                # Check if it is a valid relaxation (with a vasprun.xml file)\n",
    "                # If not, it might be that there are different deformation folders of the defect state\n",
    "                if MLL.is_relaxation_folder_valid(path_to_deformation):\n",
    "                    path_to_relaxations = [path_to_deformation]\n",
    "                else:\n",
    "                    # Try to extact deformation folders\n",
    "                    deformation_folders = os.listdir(path_to_deformation)\n",
    "\n",
    "                    # Run over deformations\n",
    "                    path_to_relaxations = []\n",
    "                    for deformation_folder in deformation_folders:\n",
    "                        path_to_relaxation = f'{path_to_deformation}/{deformation_folder}'\n",
    "                        if MLL.is_relaxation_folder_valid(path_to_relaxation):\n",
    "                            path_to_relaxations.append(path_to_relaxation)\n",
    "\n",
    "                # Gather relaxations from different deformations as different ionic steps\n",
    "                for path_to_relaxation in path_to_relaxations:\n",
    "                    # Remove invalid characters from the vasprun.xml file\n",
    "                    MLL.clean_vasprun(path_to_relaxation)  # Uncomment is it happens to you as well!!\n",
    "\n",
    "                    if not os.path.exists(f'{path_to_relaxation}/vasprun.xml'):\n",
    "                        print(f'Check {path_to_relaxation}')\n",
    "\n",
    "                    # Load data from relaxation\n",
    "                    try:\n",
    "                        # Try to load those unfinished relaxations as well\n",
    "                        vasprun = Vasprun(f'{path_to_relaxation}/vasprun.xml', exception_on_bad_xml=False)\n",
    "                    except:\n",
    "                        print('Error: vasprun not correctly loaded.')\n",
    "                        continue\n",
    "\n",
    "                    # Run over ionic steps\n",
    "                    for ionic_step_idx in range(len(vasprun.ionic_steps)):\n",
    "                        temp_ionic_step = f'{temp_relaxation}_{ionic_step_idx}'\n",
    "                        # Extract data from each ionic step\n",
    "                        temp_structure = vasprun.ionic_steps[ionic_step_idx]['structure']\n",
    "                        temp_energy    = vasprun.ionic_steps[ionic_step_idx]['e_fr_energy']\n",
    "\n",
    "                        # Save temp_structure to POSCAR\n",
    "                        #temp_Poscar = Poscar(temp_structure)\n",
    "                        #temp_Poscar.write_file('POSCAR')\n",
    "                        \n",
    "                        nodes, edges, attributes = graph_POSCAR_encoding(temp_structure)\n",
    "\n",
    "                        # Construct temporal graph structure\n",
    "                        graph = Data(x=nodes,\n",
    "                                     edge_index=edges,\n",
    "                                     edge_attr=attributes,\n",
    "                                     y=torch.tensor([[temp_energy]], dtype=torch.float)\n",
    "                                    )\n",
    "\n",
    "                        # Append to dataset and labels\n",
    "                        dataset.append(graph)\n",
    "                        labels.append(f'')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c94dd927",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize dataset\n",
    "dataset, dataset_parameters = standardize_dataset(dataset)\n",
    "\n",
    "# Save standardized dataset\n",
    "torch.save(dataset, dataset_name_std)\n",
    "torch.save(labels,  labels_name)\n",
    "\n",
    "# Convert torch tensors to numpy arrays\n",
    "numpy_dict = {key: value.cpu().numpy().tolist() for key, value in dataset_parameters.items()}\n",
    "\n",
    "# Dump the dictionary with numpy arrays to a JSON file\n",
    "with open(dataset_parameters_name_std, 'w') as json_file:\n",
    "    json.dump(numpy_dict, json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e59715",
   "metadata": {},
   "source": [
    "# Definition of train-test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "96173a78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training graphs: 8447\n",
      "Number of testing  graphs: 0\n"
     ]
    }
   ],
   "source": [
    "# torch.manual_seed(12345)\n",
    "\n",
    "# Define the sizes of the train and test sets\n",
    "test_size  = int(test_ratio * len(dataset))\n",
    "train_size = len(dataset) - test_size\n",
    "\n",
    "# Use random_split() to generate train and test sets\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "print(f'Number of training graphs: {len(train_dataset)}')\n",
    "print(f'Number of testing  graphs: {len(test_dataset)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a76fc0",
   "metadata": {},
   "source": [
    "# Training of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8f86aed2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Node GCNN:\n",
      "nGCNN(\n",
      "  (conv1): GraphConv(5, 256)\n",
      "  (conv2): GraphConv(256, 5)\n",
      ")\n",
      "\n",
      "Edge GCNN:\n",
      "eGCNN(\n",
      "  (linear1): Linear(in_features=6, out_features=64, bias=True)\n",
      "  (linear2): Linear(in_features=64, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Determine number of features in dataset, considering the t_step information\n",
    "n_features = dataset[0].num_node_features + 1\n",
    "\n",
    "# Instantiate the models for nodes and edges\n",
    "node_model = nGCNN(n_features, dropout_node).to(device)\n",
    "edge_model = eGCNN(n_features, dropout_edge).to(device)\n",
    "\n",
    "# Load previous model if available\n",
    "try:\n",
    "    node_model.load_state_dict(torch.load(node_model_name))\n",
    "    edge_model.load_state_dict(torch.load(edge_model_name))\n",
    "except FileNotFoundError:\n",
    "    pass\n",
    "\n",
    "# Evaluate model state\n",
    "node_model.eval()\n",
    "edge_model.eval()\n",
    "\n",
    "print('\\nNode GCNN:')\n",
    "print(node_model)\n",
    "print('\\nEdge GCNN:')\n",
    "print(edge_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d75d00f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, total loss: 366.5962, edge loss: 1.7033, node loss: 364.8929\n",
      "Epoch: 2, total loss: 18.8334, edge loss: 1.0006, node loss: 17.8327\n",
      "Epoch: 3, total loss: 13.5539, edge loss: 0.9985, node loss: 12.5553\n",
      "Epoch: 4, total loss: 11.2833, edge loss: 1.0001, node loss: 10.2832\n",
      "Epoch: 5, total loss: 11.0856, edge loss: 1.0002, node loss: 10.0855\n",
      "Epoch: 6, total loss: 11.2289, edge loss: 0.9996, node loss: 10.2293\n",
      "Epoch: 7, total loss: 11.4829, edge loss: 0.9998, node loss: 10.4832\n",
      "Epoch: 8, total loss: 9.6480, edge loss: 1.0000, node loss: 8.6480\n",
      "Epoch: 9, total loss: 10.7281, edge loss: 0.9996, node loss: 9.7285\n",
      "Epoch: 10, total loss: 10.6607, edge loss: 0.9998, node loss: 9.6609\n",
      "Epoch: 11, total loss: 8.6604, edge loss: 0.9997, node loss: 7.6607\n",
      "Epoch: 12, total loss: 8.1937, edge loss: 1.0002, node loss: 7.1935\n",
      "Epoch: 13, total loss: 8.9677, edge loss: 1.0004, node loss: 7.9672\n",
      "Epoch: 14, total loss: 8.7095, edge loss: 0.9997, node loss: 7.7098\n",
      "Epoch: 15, total loss: 8.3262, edge loss: 1.0006, node loss: 7.3256\n",
      "Epoch: 16, total loss: 9.3695, edge loss: 1.0004, node loss: 8.3691\n",
      "Epoch: 17, total loss: 8.3651, edge loss: 1.0001, node loss: 7.3649\n",
      "Epoch: 18, total loss: 9.0883, edge loss: 1.0004, node loss: 8.0879\n",
      "Epoch: 19, total loss: 7.5811, edge loss: 1.0000, node loss: 6.5811\n",
      "Epoch: 20, total loss: 9.4981, edge loss: 1.0008, node loss: 8.4973\n",
      "Epoch: 21, total loss: 7.8353, edge loss: 1.0008, node loss: 6.8345\n",
      "Epoch: 22, total loss: 7.5279, edge loss: 1.0003, node loss: 6.5276\n",
      "Epoch: 23, total loss: 7.2924, edge loss: 0.9985, node loss: 6.2938\n",
      "Epoch: 24, total loss: 9.1305, edge loss: 0.9997, node loss: 8.1309\n",
      "Epoch: 25, total loss: 7.3581, edge loss: 1.0004, node loss: 6.3578\n",
      "Epoch: 26, total loss: 6.6358, edge loss: 0.9993, node loss: 5.6366\n",
      "Epoch: 27, total loss: 7.2981, edge loss: 0.9995, node loss: 6.2986\n",
      "Epoch: 28, total loss: 6.2654, edge loss: 1.0003, node loss: 5.2652\n",
      "Epoch: 29, total loss: 7.9376, edge loss: 1.0003, node loss: 6.9373\n",
      "Epoch: 30, total loss: 7.2479, edge loss: 1.0001, node loss: 6.2478\n",
      "Epoch: 31, total loss: 6.6372, edge loss: 1.0011, node loss: 5.6361\n",
      "Epoch: 32, total loss: 7.8384, edge loss: 1.0006, node loss: 6.8379\n",
      "Epoch: 33, total loss: 6.1950, edge loss: 1.0003, node loss: 5.1947\n",
      "Epoch: 34, total loss: 7.1993, edge loss: 1.0001, node loss: 6.1993\n",
      "Epoch: 35, total loss: 6.0933, edge loss: 0.9992, node loss: 5.0941\n",
      "Epoch: 36, total loss: 6.7384, edge loss: 0.9998, node loss: 5.7386\n",
      "Epoch: 37, total loss: 6.6184, edge loss: 0.9992, node loss: 5.6193\n",
      "Epoch: 38, total loss: 6.4561, edge loss: 1.0005, node loss: 5.4556\n",
      "Epoch: 39, total loss: 6.7028, edge loss: 0.9996, node loss: 5.7031\n",
      "Epoch: 40, total loss: 5.8457, edge loss: 0.9994, node loss: 4.8463\n",
      "Epoch: 41, total loss: 6.8333, edge loss: 0.9992, node loss: 5.8342\n",
      "Epoch: 42, total loss: 5.2888, edge loss: 0.9997, node loss: 4.2891\n",
      "Epoch: 43, total loss: 5.7556, edge loss: 0.9996, node loss: 4.7560\n",
      "Epoch: 44, total loss: 5.5613, edge loss: 1.0011, node loss: 4.5602\n",
      "Epoch: 45, total loss: 5.7253, edge loss: 1.0004, node loss: 4.7248\n",
      "Epoch: 46, total loss: 5.9544, edge loss: 1.0005, node loss: 4.9538\n",
      "Epoch: 47, total loss: 6.0381, edge loss: 1.0004, node loss: 5.0377\n",
      "Epoch: 48, total loss: 4.9790, edge loss: 1.0007, node loss: 3.9783\n",
      "Epoch: 49, total loss: 5.5474, edge loss: 1.0006, node loss: 4.5469\n",
      "Epoch: 50, total loss: 5.6466, edge loss: 0.9989, node loss: 4.6478\n",
      "Epoch: 51, total loss: 4.8234, edge loss: 1.0003, node loss: 3.8231\n",
      "Epoch: 52, total loss: 5.6614, edge loss: 0.9992, node loss: 4.6622\n",
      "Epoch: 53, total loss: 4.6016, edge loss: 0.9993, node loss: 3.6023\n",
      "Epoch: 54, total loss: 4.9378, edge loss: 1.0000, node loss: 3.9378\n",
      "Epoch: 55, total loss: 4.2976, edge loss: 0.9996, node loss: 3.2980\n",
      "Epoch: 56, total loss: 4.8696, edge loss: 1.0002, node loss: 3.8694\n",
      "Epoch: 57, total loss: 4.3463, edge loss: 1.0002, node loss: 3.3461\n",
      "Epoch: 58, total loss: 4.6012, edge loss: 1.0004, node loss: 3.6007\n",
      "Epoch: 59, total loss: 4.5910, edge loss: 1.0001, node loss: 3.5908\n",
      "Epoch: 60, total loss: 4.5134, edge loss: 0.9991, node loss: 3.5144\n",
      "Epoch: 61, total loss: 4.3383, edge loss: 0.9995, node loss: 3.3389\n",
      "Epoch: 62, total loss: 4.3730, edge loss: 0.9995, node loss: 3.3736\n",
      "Epoch: 63, total loss: 4.4928, edge loss: 0.9995, node loss: 3.4932\n",
      "Epoch: 64, total loss: 3.7145, edge loss: 1.0000, node loss: 2.7145\n",
      "Epoch: 65, total loss: 4.3523, edge loss: 1.0000, node loss: 3.3523\n",
      "Epoch: 66, total loss: 4.9007, edge loss: 1.0003, node loss: 3.9004\n",
      "Epoch: 67, total loss: 4.0419, edge loss: 1.0010, node loss: 3.0409\n",
      "Epoch: 68, total loss: 4.8609, edge loss: 1.0001, node loss: 3.8608\n",
      "Epoch: 69, total loss: 3.7507, edge loss: 0.9997, node loss: 2.7510\n",
      "Epoch: 70, total loss: 3.4719, edge loss: 0.9998, node loss: 2.4721\n",
      "Epoch: 71, total loss: 3.7813, edge loss: 0.9995, node loss: 2.7818\n",
      "Epoch: 72, total loss: 4.0700, edge loss: 1.0002, node loss: 3.0698\n",
      "Epoch: 73, total loss: 3.5163, edge loss: 1.0015, node loss: 2.5148\n",
      "Epoch: 74, total loss: 3.6557, edge loss: 1.0009, node loss: 2.6548\n",
      "Epoch: 75, total loss: 3.5722, edge loss: 1.0003, node loss: 2.5719\n",
      "Epoch: 76, total loss: 3.4297, edge loss: 0.9999, node loss: 2.4298\n",
      "Epoch: 77, total loss: 3.5161, edge loss: 1.0004, node loss: 2.5157\n",
      "Epoch: 78, total loss: 3.6966, edge loss: 1.0002, node loss: 2.6964\n",
      "Epoch: 79, total loss: 3.2431, edge loss: 0.9995, node loss: 2.2436\n",
      "Epoch: 80, total loss: 3.2154, edge loss: 1.0007, node loss: 2.2147\n",
      "Epoch: 81, total loss: 3.3862, edge loss: 0.9986, node loss: 2.3876\n",
      "Epoch: 82, total loss: 3.1787, edge loss: 1.0008, node loss: 2.1780\n",
      "Epoch: 83, total loss: 3.1398, edge loss: 0.9995, node loss: 2.1403\n",
      "Epoch: 84, total loss: 2.8662, edge loss: 1.0005, node loss: 1.8657\n",
      "Epoch: 85, total loss: 3.0144, edge loss: 0.9993, node loss: 2.0151\n",
      "Epoch: 86, total loss: 2.9336, edge loss: 1.0008, node loss: 1.9327\n",
      "Epoch: 87, total loss: 3.4698, edge loss: 1.0006, node loss: 2.4693\n",
      "Epoch: 88, total loss: 3.1637, edge loss: 1.0005, node loss: 2.1632\n",
      "Epoch: 89, total loss: 2.7961, edge loss: 0.9996, node loss: 1.7964\n",
      "Epoch: 90, total loss: 3.1599, edge loss: 1.0005, node loss: 2.1595\n",
      "Epoch: 91, total loss: 2.5672, edge loss: 1.0006, node loss: 1.5666\n",
      "Epoch: 92, total loss: 3.5551, edge loss: 0.9995, node loss: 2.5556\n",
      "Epoch: 93, total loss: 2.8021, edge loss: 1.0003, node loss: 1.8018\n",
      "Epoch: 94, total loss: 2.6864, edge loss: 0.9992, node loss: 1.6872\n",
      "Epoch: 95, total loss: 2.6598, edge loss: 1.0003, node loss: 1.6595\n",
      "Epoch: 96, total loss: 2.5711, edge loss: 0.9992, node loss: 1.5719\n",
      "Epoch: 97, total loss: 2.5424, edge loss: 0.9999, node loss: 1.5425\n",
      "Epoch: 98, total loss: 2.7592, edge loss: 0.9990, node loss: 1.7603\n",
      "Epoch: 99, total loss: 2.5754, edge loss: 1.0005, node loss: 1.5749\n",
      "Epoch: 100, total loss: 2.6282, edge loss: 0.9994, node loss: 1.6289\n",
      "Epoch: 101, total loss: 2.6760, edge loss: 0.9997, node loss: 1.6763\n",
      "Epoch: 102, total loss: 2.4799, edge loss: 1.0005, node loss: 1.4794\n",
      "Epoch: 103, total loss: 2.4285, edge loss: 0.9994, node loss: 1.4291\n",
      "Epoch: 104, total loss: 2.5008, edge loss: 0.9998, node loss: 1.5010\n",
      "Epoch: 105, total loss: 2.3803, edge loss: 1.0002, node loss: 1.3801\n",
      "Epoch: 106, total loss: 2.6174, edge loss: 1.0010, node loss: 1.6165\n",
      "Epoch: 107, total loss: 2.3959, edge loss: 1.0005, node loss: 1.3954\n",
      "Epoch: 108, total loss: 2.5227, edge loss: 1.0005, node loss: 1.5223\n",
      "Epoch: 109, total loss: 2.3814, edge loss: 0.9990, node loss: 1.3824\n",
      "Epoch: 110, total loss: 2.3993, edge loss: 0.9991, node loss: 1.4002\n",
      "Epoch: 111, total loss: 2.4895, edge loss: 1.0000, node loss: 1.4895\n",
      "Epoch: 112, total loss: 2.4627, edge loss: 0.9992, node loss: 1.4635\n",
      "Epoch: 113, total loss: 2.2721, edge loss: 1.0001, node loss: 1.2719\n",
      "Epoch: 114, total loss: 2.4248, edge loss: 1.0000, node loss: 1.4248\n",
      "Epoch: 115, total loss: 2.0581, edge loss: 1.0001, node loss: 1.0580\n",
      "Epoch: 116, total loss: 2.2818, edge loss: 1.0006, node loss: 1.2812\n",
      "Epoch: 117, total loss: 2.2258, edge loss: 1.0000, node loss: 1.2258\n",
      "Epoch: 118, total loss: 2.1447, edge loss: 0.9997, node loss: 1.1450\n",
      "Epoch: 119, total loss: 2.0799, edge loss: 0.9998, node loss: 1.0801\n",
      "Epoch: 120, total loss: 1.9641, edge loss: 0.9995, node loss: 0.9646\n",
      "Epoch: 121, total loss: 2.1973, edge loss: 0.9996, node loss: 1.1977\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 122, total loss: 2.1297, edge loss: 1.0002, node loss: 1.1295\n",
      "Epoch: 123, total loss: 2.0744, edge loss: 1.0008, node loss: 1.0736\n",
      "Epoch: 124, total loss: 2.1201, edge loss: 1.0003, node loss: 1.1198\n",
      "Epoch: 125, total loss: 1.8958, edge loss: 0.9992, node loss: 0.8965\n",
      "Epoch: 126, total loss: 2.1123, edge loss: 0.9996, node loss: 1.1127\n",
      "Epoch: 127, total loss: 1.9650, edge loss: 1.0004, node loss: 0.9645\n",
      "Epoch: 128, total loss: 1.8686, edge loss: 0.9992, node loss: 0.8694\n",
      "Epoch: 129, total loss: 2.0756, edge loss: 0.9998, node loss: 1.0758\n",
      "Epoch: 130, total loss: 1.9802, edge loss: 0.9996, node loss: 0.9807\n",
      "Epoch: 131, total loss: 1.9825, edge loss: 1.0002, node loss: 0.9823\n",
      "Epoch: 132, total loss: 1.7591, edge loss: 1.0006, node loss: 0.7584\n",
      "Epoch: 133, total loss: 1.9309, edge loss: 0.9997, node loss: 0.9312\n",
      "Epoch: 134, total loss: 1.8959, edge loss: 1.0005, node loss: 0.8954\n",
      "Epoch: 135, total loss: 1.9004, edge loss: 0.9999, node loss: 0.9005\n",
      "Epoch: 136, total loss: 1.8256, edge loss: 0.9990, node loss: 0.8266\n",
      "Epoch: 137, total loss: 1.7856, edge loss: 1.0007, node loss: 0.7849\n",
      "Epoch: 138, total loss: 1.8757, edge loss: 1.0005, node loss: 0.8753\n",
      "Epoch: 139, total loss: 1.9092, edge loss: 0.9996, node loss: 0.9096\n",
      "Epoch: 140, total loss: 1.8642, edge loss: 0.9989, node loss: 0.8653\n",
      "Epoch: 141, total loss: 1.6706, edge loss: 0.9994, node loss: 0.6712\n",
      "Epoch: 142, total loss: 1.7342, edge loss: 1.0000, node loss: 0.7342\n",
      "Epoch: 143, total loss: 1.7017, edge loss: 1.0003, node loss: 0.7014\n",
      "Epoch: 144, total loss: 1.8200, edge loss: 1.0006, node loss: 0.8194\n",
      "Epoch: 145, total loss: 1.6799, edge loss: 1.0002, node loss: 0.6797\n",
      "Epoch: 146, total loss: 1.6531, edge loss: 1.0009, node loss: 0.6521\n",
      "Epoch: 147, total loss: 1.7534, edge loss: 0.9997, node loss: 0.7537\n",
      "Epoch: 148, total loss: 1.6597, edge loss: 1.0005, node loss: 0.6593\n",
      "Epoch: 149, total loss: 1.6609, edge loss: 0.9996, node loss: 0.6613\n",
      "Epoch: 150, total loss: 1.6351, edge loss: 0.9990, node loss: 0.6360\n",
      "Epoch: 151, total loss: 1.6157, edge loss: 1.0002, node loss: 0.6155\n",
      "Epoch: 152, total loss: 1.6914, edge loss: 0.9992, node loss: 0.6922\n",
      "Epoch: 153, total loss: 1.5746, edge loss: 1.0006, node loss: 0.5740\n",
      "Epoch: 154, total loss: 1.5836, edge loss: 1.0004, node loss: 0.5832\n",
      "Epoch: 155, total loss: 1.5379, edge loss: 0.9997, node loss: 0.5381\n",
      "Epoch: 156, total loss: 1.5568, edge loss: 1.0007, node loss: 0.5562\n",
      "Epoch: 157, total loss: 1.5318, edge loss: 1.0004, node loss: 0.5314\n",
      "Epoch: 158, total loss: 1.5252, edge loss: 0.9987, node loss: 0.5265\n",
      "Epoch: 159, total loss: 1.4998, edge loss: 1.0008, node loss: 0.4990\n",
      "Epoch: 160, total loss: 1.4682, edge loss: 0.9994, node loss: 0.4688\n",
      "Epoch: 161, total loss: 1.4975, edge loss: 0.9999, node loss: 0.4976\n",
      "Epoch: 162, total loss: 1.4720, edge loss: 1.0007, node loss: 0.4713\n",
      "Epoch: 163, total loss: 1.4292, edge loss: 1.0004, node loss: 0.4287\n",
      "Epoch: 164, total loss: 1.4253, edge loss: 0.9996, node loss: 0.4256\n",
      "Epoch: 165, total loss: 1.4321, edge loss: 0.9997, node loss: 0.4324\n",
      "Epoch: 166, total loss: 1.4193, edge loss: 0.9996, node loss: 0.4198\n",
      "Epoch: 167, total loss: 1.4716, edge loss: 0.9991, node loss: 0.4725\n",
      "Epoch: 168, total loss: 1.4323, edge loss: 1.0002, node loss: 0.4321\n",
      "Epoch: 169, total loss: 1.4967, edge loss: 1.0021, node loss: 0.4946\n",
      "Epoch: 170, total loss: 1.3849, edge loss: 0.9999, node loss: 0.3849\n",
      "Epoch: 171, total loss: 1.3971, edge loss: 1.0002, node loss: 0.3968\n",
      "Epoch: 172, total loss: 1.3962, edge loss: 1.0000, node loss: 0.3962\n",
      "Epoch: 173, total loss: 1.3882, edge loss: 0.9999, node loss: 0.3883\n",
      "Epoch: 174, total loss: 1.3818, edge loss: 0.9995, node loss: 0.3824\n",
      "Epoch: 175, total loss: 1.3570, edge loss: 0.9993, node loss: 0.3577\n",
      "Epoch: 176, total loss: 1.3789, edge loss: 1.0006, node loss: 0.3784\n",
      "Epoch: 177, total loss: 1.3649, edge loss: 0.9997, node loss: 0.3652\n",
      "Epoch: 178, total loss: 1.3442, edge loss: 0.9993, node loss: 0.3450\n",
      "Epoch: 179, total loss: 1.3344, edge loss: 1.0003, node loss: 0.3341\n",
      "Epoch: 180, total loss: 1.3491, edge loss: 1.0000, node loss: 0.3492\n",
      "Epoch: 181, total loss: 1.3294, edge loss: 0.9999, node loss: 0.3295\n",
      "Epoch: 182, total loss: 1.3146, edge loss: 0.9997, node loss: 0.3149\n",
      "Epoch: 183, total loss: 1.3171, edge loss: 1.0003, node loss: 0.3167\n",
      "Epoch: 184, total loss: 1.3198, edge loss: 1.0003, node loss: 0.3195\n",
      "Epoch: 185, total loss: 1.3249, edge loss: 1.0004, node loss: 0.3246\n",
      "Epoch: 186, total loss: 1.2934, edge loss: 0.9999, node loss: 0.2935\n",
      "Epoch: 187, total loss: 1.3098, edge loss: 1.0010, node loss: 0.3089\n",
      "Epoch: 188, total loss: 1.3016, edge loss: 1.0006, node loss: 0.3010\n",
      "Epoch: 189, total loss: 1.2980, edge loss: 0.9998, node loss: 0.2981\n",
      "Epoch: 190, total loss: 1.2965, edge loss: 1.0006, node loss: 0.2958\n",
      "Epoch: 191, total loss: 1.2875, edge loss: 0.9997, node loss: 0.2878\n",
      "Epoch: 192, total loss: 1.2668, edge loss: 0.9992, node loss: 0.2676\n",
      "Epoch: 193, total loss: 1.2965, edge loss: 1.0001, node loss: 0.2964\n",
      "Epoch: 194, total loss: 1.2740, edge loss: 0.9992, node loss: 0.2747\n",
      "Epoch: 195, total loss: 1.2687, edge loss: 0.9988, node loss: 0.2699\n",
      "Epoch: 196, total loss: 1.2560, edge loss: 1.0008, node loss: 0.2552\n",
      "Epoch: 197, total loss: 1.2698, edge loss: 1.0006, node loss: 0.2692\n",
      "Epoch: 198, total loss: 1.2575, edge loss: 0.9998, node loss: 0.2577\n",
      "Epoch: 199, total loss: 1.2556, edge loss: 1.0002, node loss: 0.2554\n",
      "Epoch: 200, total loss: 1.2521, edge loss: 1.0005, node loss: 0.2516\n",
      "Epoch: 201, total loss: 1.2435, edge loss: 0.9997, node loss: 0.2438\n",
      "Epoch: 202, total loss: 1.2604, edge loss: 1.0002, node loss: 0.2602\n",
      "Epoch: 203, total loss: 1.2403, edge loss: 0.9995, node loss: 0.2408\n",
      "Epoch: 204, total loss: 1.2304, edge loss: 1.0001, node loss: 0.2303\n",
      "Epoch: 205, total loss: 1.2355, edge loss: 0.9995, node loss: 0.2360\n",
      "Epoch: 206, total loss: 1.2306, edge loss: 1.0003, node loss: 0.2303\n",
      "Epoch: 207, total loss: 1.2217, edge loss: 1.0004, node loss: 0.2213\n",
      "Epoch: 208, total loss: 1.2288, edge loss: 0.9991, node loss: 0.2297\n",
      "Epoch: 209, total loss: 1.2162, edge loss: 1.0006, node loss: 0.2156\n",
      "Epoch: 210, total loss: 1.2094, edge loss: 0.9997, node loss: 0.2096\n",
      "Epoch: 211, total loss: 1.2266, edge loss: 0.9996, node loss: 0.2270\n",
      "Epoch: 212, total loss: 1.2070, edge loss: 1.0004, node loss: 0.2066\n",
      "Epoch: 213, total loss: 1.2104, edge loss: 0.9995, node loss: 0.2109\n",
      "Epoch: 214, total loss: 1.2009, edge loss: 0.9993, node loss: 0.2016\n",
      "Epoch: 215, total loss: 1.1991, edge loss: 0.9994, node loss: 0.1997\n",
      "Epoch: 216, total loss: 1.1913, edge loss: 1.0002, node loss: 0.1911\n",
      "Epoch: 217, total loss: 1.2024, edge loss: 1.0000, node loss: 0.2024\n",
      "Epoch: 218, total loss: 1.1876, edge loss: 1.0003, node loss: 0.1873\n",
      "Epoch: 219, total loss: 1.1903, edge loss: 0.9996, node loss: 0.1907\n",
      "Epoch: 220, total loss: 1.1771, edge loss: 1.0005, node loss: 0.1765\n",
      "Epoch: 221, total loss: 1.1788, edge loss: 0.9992, node loss: 0.1796\n",
      "Epoch: 222, total loss: 1.1740, edge loss: 0.9999, node loss: 0.1741\n",
      "Epoch: 223, total loss: 1.1677, edge loss: 0.9999, node loss: 0.1678\n",
      "Epoch: 224, total loss: 1.1693, edge loss: 1.0009, node loss: 0.1684\n",
      "Epoch: 225, total loss: 1.1687, edge loss: 0.9993, node loss: 0.1694\n",
      "Epoch: 226, total loss: 1.1605, edge loss: 0.9999, node loss: 0.1606\n",
      "Epoch: 227, total loss: 1.1560, edge loss: 0.9995, node loss: 0.1565\n",
      "Epoch: 228, total loss: 1.1571, edge loss: 1.0002, node loss: 0.1569\n",
      "Epoch: 229, total loss: 1.1528, edge loss: 0.9992, node loss: 0.1536\n",
      "Epoch: 230, total loss: 1.1480, edge loss: 1.0001, node loss: 0.1479\n",
      "Epoch: 231, total loss: 1.1475, edge loss: 1.0001, node loss: 0.1473\n",
      "Epoch: 232, total loss: 1.1458, edge loss: 0.9994, node loss: 0.1464\n",
      "Epoch: 233, total loss: 1.1438, edge loss: 1.0002, node loss: 0.1436\n",
      "Epoch: 234, total loss: 1.1398, edge loss: 0.9989, node loss: 0.1408\n",
      "Epoch: 235, total loss: 1.1411, edge loss: 1.0002, node loss: 0.1408\n",
      "Epoch: 236, total loss: 1.1357, edge loss: 1.0001, node loss: 0.1355\n",
      "Epoch: 237, total loss: 1.1338, edge loss: 0.9996, node loss: 0.1342\n",
      "Epoch: 238, total loss: 1.1297, edge loss: 1.0002, node loss: 0.1295\n",
      "Epoch: 239, total loss: 1.1289, edge loss: 1.0005, node loss: 0.1284\n",
      "Epoch: 240, total loss: 1.1255, edge loss: 1.0007, node loss: 0.1248\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 241, total loss: 1.1340, edge loss: 1.0012, node loss: 0.1328\n",
      "Epoch: 242, total loss: 1.1265, edge loss: 1.0008, node loss: 0.1258\n",
      "Epoch: 243, total loss: 1.1231, edge loss: 1.0006, node loss: 0.1225\n",
      "Epoch: 244, total loss: 1.1164, edge loss: 1.0002, node loss: 0.1162\n",
      "Epoch: 245, total loss: 1.1169, edge loss: 0.9988, node loss: 0.1180\n",
      "Epoch: 246, total loss: 1.1143, edge loss: 0.9996, node loss: 0.1147\n",
      "Epoch: 247, total loss: 1.1129, edge loss: 0.9998, node loss: 0.1131\n",
      "Epoch: 248, total loss: 1.1111, edge loss: 0.9999, node loss: 0.1112\n",
      "Epoch: 249, total loss: 1.1084, edge loss: 0.9996, node loss: 0.1089\n",
      "Epoch: 250, total loss: 1.1079, edge loss: 0.9999, node loss: 0.1080\n",
      "Epoch: 251, total loss: 1.1053, edge loss: 1.0014, node loss: 0.1039\n",
      "Epoch: 252, total loss: 1.1041, edge loss: 1.0010, node loss: 0.1031\n",
      "Epoch: 253, total loss: 1.1039, edge loss: 1.0002, node loss: 0.1037\n",
      "Epoch: 254, total loss: 1.1030, edge loss: 0.9992, node loss: 0.1039\n",
      "Epoch: 255, total loss: 1.0987, edge loss: 1.0000, node loss: 0.0987\n",
      "Epoch: 256, total loss: 1.0999, edge loss: 1.0000, node loss: 0.0999\n",
      "Epoch: 257, total loss: 1.0958, edge loss: 1.0004, node loss: 0.0954\n",
      "Epoch: 258, total loss: 1.0955, edge loss: 0.9994, node loss: 0.0962\n",
      "Epoch: 259, total loss: 1.0944, edge loss: 0.9991, node loss: 0.0952\n",
      "Epoch: 260, total loss: 1.0939, edge loss: 1.0006, node loss: 0.0933\n",
      "Epoch: 261, total loss: 1.0899, edge loss: 0.9994, node loss: 0.0905\n",
      "Epoch: 262, total loss: 1.0911, edge loss: 1.0006, node loss: 0.0905\n",
      "Epoch: 263, total loss: 1.0896, edge loss: 0.9994, node loss: 0.0902\n",
      "Epoch: 264, total loss: 1.0871, edge loss: 1.0001, node loss: 0.0870\n",
      "Epoch: 265, total loss: 1.0867, edge loss: 1.0004, node loss: 0.0863\n",
      "Epoch: 266, total loss: 1.0852, edge loss: 0.9993, node loss: 0.0859\n",
      "Epoch: 267, total loss: 1.0828, edge loss: 1.0004, node loss: 0.0825\n",
      "Epoch: 268, total loss: 1.0811, edge loss: 0.9995, node loss: 0.0817\n",
      "Epoch: 269, total loss: 1.0800, edge loss: 0.9999, node loss: 0.0801\n",
      "Epoch: 270, total loss: 1.0768, edge loss: 0.9997, node loss: 0.0771\n",
      "Epoch: 271, total loss: 1.0758, edge loss: 0.9996, node loss: 0.0762\n",
      "Epoch: 272, total loss: 1.0766, edge loss: 1.0006, node loss: 0.0760\n",
      "Epoch: 273, total loss: 1.0731, edge loss: 1.0001, node loss: 0.0730\n",
      "Epoch: 274, total loss: 1.0733, edge loss: 1.0004, node loss: 0.0728\n",
      "Epoch: 275, total loss: 1.0706, edge loss: 1.0004, node loss: 0.0702\n",
      "Epoch: 276, total loss: 1.0705, edge loss: 0.9999, node loss: 0.0706\n",
      "Epoch: 277, total loss: 1.0706, edge loss: 0.9997, node loss: 0.0708\n",
      "Epoch: 278, total loss: 1.0663, edge loss: 0.9993, node loss: 0.0670\n",
      "Epoch: 279, total loss: 1.0677, edge loss: 1.0002, node loss: 0.0676\n",
      "Epoch: 280, total loss: 1.0641, edge loss: 1.0000, node loss: 0.0641\n",
      "Epoch: 281, total loss: 1.0628, edge loss: 0.9998, node loss: 0.0631\n",
      "Epoch: 282, total loss: 1.0621, edge loss: 1.0004, node loss: 0.0617\n",
      "Epoch: 283, total loss: 1.0607, edge loss: 0.9999, node loss: 0.0608\n",
      "Epoch: 284, total loss: 1.0587, edge loss: 0.9994, node loss: 0.0593\n",
      "Epoch: 285, total loss: 1.0564, edge loss: 1.0001, node loss: 0.0564\n",
      "Epoch: 286, total loss: 1.0563, edge loss: 0.9990, node loss: 0.0573\n",
      "Epoch: 287, total loss: 1.0547, edge loss: 0.9994, node loss: 0.0553\n",
      "Epoch: 288, total loss: 1.0555, edge loss: 0.9998, node loss: 0.0558\n",
      "Epoch: 289, total loss: 1.0551, edge loss: 1.0009, node loss: 0.0542\n",
      "Epoch: 290, total loss: 1.0519, edge loss: 0.9995, node loss: 0.0524\n",
      "Epoch: 291, total loss: 1.0516, edge loss: 0.9998, node loss: 0.0518\n",
      "Epoch: 292, total loss: 1.0494, edge loss: 1.0001, node loss: 0.0493\n",
      "Epoch: 293, total loss: 1.0483, edge loss: 0.9996, node loss: 0.0488\n",
      "Epoch: 294, total loss: 1.0483, edge loss: 1.0008, node loss: 0.0475\n",
      "Epoch: 295, total loss: 1.0470, edge loss: 1.0002, node loss: 0.0469\n",
      "Epoch: 296, total loss: 1.0461, edge loss: 0.9999, node loss: 0.0462\n",
      "Epoch: 297, total loss: 1.0452, edge loss: 0.9996, node loss: 0.0456\n",
      "Epoch: 298, total loss: 1.0451, edge loss: 1.0009, node loss: 0.0443\n",
      "Epoch: 299, total loss: 1.0435, edge loss: 1.0002, node loss: 0.0433\n",
      "Epoch: 300, total loss: 1.0426, edge loss: 1.0014, node loss: 0.0413\n",
      "Epoch: 301, total loss: 1.0407, edge loss: 0.9999, node loss: 0.0408\n",
      "Epoch: 302, total loss: 1.0400, edge loss: 0.9994, node loss: 0.0406\n",
      "Epoch: 303, total loss: 1.0397, edge loss: 0.9998, node loss: 0.0398\n",
      "Epoch: 304, total loss: 1.0361, edge loss: 0.9990, node loss: 0.0371\n",
      "Epoch: 305, total loss: 1.0359, edge loss: 0.9987, node loss: 0.0371\n",
      "Epoch: 306, total loss: 1.0359, edge loss: 0.9990, node loss: 0.0369\n",
      "Epoch: 307, total loss: 1.0359, edge loss: 0.9999, node loss: 0.0360\n",
      "Epoch: 308, total loss: 1.0324, edge loss: 0.9988, node loss: 0.0336\n",
      "Epoch: 309, total loss: 1.0332, edge loss: 1.0000, node loss: 0.0332\n",
      "Epoch: 310, total loss: 1.0322, edge loss: 0.9996, node loss: 0.0326\n",
      "Epoch: 311, total loss: 1.0312, edge loss: 0.9989, node loss: 0.0323\n",
      "Epoch: 312, total loss: 1.0315, edge loss: 1.0004, node loss: 0.0311\n",
      "Epoch: 313, total loss: 1.0320, edge loss: 1.0000, node loss: 0.0320\n",
      "Epoch: 314, total loss: 1.0306, edge loss: 1.0005, node loss: 0.0301\n",
      "Epoch: 315, total loss: 1.0300, edge loss: 1.0003, node loss: 0.0297\n",
      "Epoch: 316, total loss: 1.0295, edge loss: 1.0005, node loss: 0.0290\n",
      "Epoch: 317, total loss: 1.0280, edge loss: 1.0004, node loss: 0.0276\n",
      "Epoch: 318, total loss: 1.0276, edge loss: 0.9998, node loss: 0.0279\n",
      "Epoch: 319, total loss: 1.0268, edge loss: 1.0007, node loss: 0.0261\n",
      "Epoch: 320, total loss: 1.0258, edge loss: 0.9996, node loss: 0.0263\n",
      "Epoch: 321, total loss: 1.0242, edge loss: 0.9993, node loss: 0.0249\n",
      "Epoch: 322, total loss: 1.0233, edge loss: 0.9997, node loss: 0.0236\n",
      "Epoch: 323, total loss: 1.0238, edge loss: 0.9996, node loss: 0.0241\n",
      "Epoch: 324, total loss: 1.0233, edge loss: 1.0002, node loss: 0.0230\n",
      "Epoch: 325, total loss: 1.0209, edge loss: 0.9986, node loss: 0.0223\n",
      "Epoch: 326, total loss: 1.0223, edge loss: 0.9999, node loss: 0.0224\n",
      "Epoch: 327, total loss: 1.0227, edge loss: 0.9989, node loss: 0.0238\n",
      "Epoch: 328, total loss: 1.0197, edge loss: 0.9994, node loss: 0.0203\n",
      "Epoch: 329, total loss: 1.0204, edge loss: 0.9997, node loss: 0.0207\n",
      "Epoch: 330, total loss: 1.0200, edge loss: 1.0000, node loss: 0.0200\n",
      "Epoch: 331, total loss: 1.0185, edge loss: 1.0000, node loss: 0.0185\n",
      "Epoch: 332, total loss: 1.0193, edge loss: 1.0002, node loss: 0.0192\n",
      "Epoch: 333, total loss: 1.0194, edge loss: 1.0008, node loss: 0.0186\n",
      "Epoch: 334, total loss: 1.0177, edge loss: 1.0000, node loss: 0.0177\n",
      "Epoch: 335, total loss: 1.0157, edge loss: 0.9993, node loss: 0.0164\n",
      "Epoch: 336, total loss: 1.0177, edge loss: 1.0001, node loss: 0.0176\n",
      "Epoch: 337, total loss: 1.0169, edge loss: 1.0003, node loss: 0.0166\n",
      "Epoch: 338, total loss: 1.0163, edge loss: 0.9997, node loss: 0.0166\n",
      "Epoch: 339, total loss: 1.0160, edge loss: 1.0002, node loss: 0.0158\n",
      "Epoch: 340, total loss: 1.0147, edge loss: 0.9996, node loss: 0.0150\n",
      "Epoch: 341, total loss: 1.0153, edge loss: 1.0001, node loss: 0.0152\n",
      "Epoch: 342, total loss: 1.0144, edge loss: 0.9996, node loss: 0.0148\n",
      "Epoch: 343, total loss: 1.0136, edge loss: 1.0000, node loss: 0.0136\n",
      "Epoch: 344, total loss: 1.0144, edge loss: 1.0009, node loss: 0.0135\n",
      "Epoch: 345, total loss: 1.0132, edge loss: 1.0000, node loss: 0.0132\n",
      "Epoch: 346, total loss: 1.0142, edge loss: 0.9999, node loss: 0.0143\n",
      "Epoch: 347, total loss: 1.0134, edge loss: 1.0001, node loss: 0.0133\n",
      "Epoch: 348, total loss: 1.0133, edge loss: 1.0002, node loss: 0.0132\n",
      "Epoch: 349, total loss: 1.0118, edge loss: 0.9989, node loss: 0.0129\n",
      "Epoch: 350, total loss: 1.0142, edge loss: 1.0008, node loss: 0.0134\n",
      "Epoch: 351, total loss: 1.0118, edge loss: 0.9998, node loss: 0.0120\n",
      "Epoch: 352, total loss: 1.0119, edge loss: 1.0003, node loss: 0.0116\n",
      "Epoch: 353, total loss: 1.0122, edge loss: 1.0004, node loss: 0.0118\n",
      "Epoch: 354, total loss: 1.0123, edge loss: 1.0007, node loss: 0.0116\n",
      "Epoch: 355, total loss: 1.0116, edge loss: 1.0004, node loss: 0.0112\n",
      "Epoch: 356, total loss: 1.0115, edge loss: 0.9999, node loss: 0.0116\n",
      "Epoch: 357, total loss: 1.0090, edge loss: 0.9993, node loss: 0.0097\n",
      "Epoch: 358, total loss: 1.0115, edge loss: 1.0001, node loss: 0.0114\n",
      "Epoch: 359, total loss: 1.0106, edge loss: 1.0003, node loss: 0.0103\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 360, total loss: 1.0097, edge loss: 0.9995, node loss: 0.0102\n",
      "Epoch: 361, total loss: 1.0098, edge loss: 1.0001, node loss: 0.0098\n",
      "Epoch: 362, total loss: 1.0117, edge loss: 1.0004, node loss: 0.0113\n",
      "Epoch: 363, total loss: 1.0091, edge loss: 0.9997, node loss: 0.0094\n",
      "Epoch: 364, total loss: 1.0093, edge loss: 0.9997, node loss: 0.0096\n",
      "Epoch: 365, total loss: 1.0085, edge loss: 0.9993, node loss: 0.0092\n",
      "Epoch: 366, total loss: 1.0082, edge loss: 0.9993, node loss: 0.0089\n",
      "Epoch: 367, total loss: 1.0096, edge loss: 1.0007, node loss: 0.0089\n",
      "Epoch: 368, total loss: 1.0088, edge loss: 0.9996, node loss: 0.0092\n",
      "Epoch: 369, total loss: 1.0092, edge loss: 0.9996, node loss: 0.0095\n",
      "Epoch: 370, total loss: 1.0099, edge loss: 0.9996, node loss: 0.0103\n",
      "Epoch: 371, total loss: 1.0075, edge loss: 1.0001, node loss: 0.0074\n",
      "Epoch: 372, total loss: 1.0085, edge loss: 1.0004, node loss: 0.0081\n",
      "Epoch: 373, total loss: 1.0080, edge loss: 0.9998, node loss: 0.0082\n",
      "Epoch: 374, total loss: 1.0087, edge loss: 0.9999, node loss: 0.0088\n",
      "Epoch: 375, total loss: 1.0083, edge loss: 1.0003, node loss: 0.0080\n",
      "Epoch: 376, total loss: 1.0097, edge loss: 1.0006, node loss: 0.0091\n",
      "Epoch: 377, total loss: 1.0075, edge loss: 0.9999, node loss: 0.0076\n",
      "Epoch: 378, total loss: 1.0096, edge loss: 1.0002, node loss: 0.0095\n",
      "Epoch: 379, total loss: 1.0084, edge loss: 1.0004, node loss: 0.0080\n",
      "Epoch: 380, total loss: 1.0094, edge loss: 1.0011, node loss: 0.0083\n",
      "Epoch: 381, total loss: 1.0104, edge loss: 0.9992, node loss: 0.0112\n",
      "Epoch: 382, total loss: 1.0086, edge loss: 0.9996, node loss: 0.0090\n",
      "Epoch: 383, total loss: 1.0080, edge loss: 1.0003, node loss: 0.0077\n",
      "Epoch: 384, total loss: 1.0070, edge loss: 1.0002, node loss: 0.0068\n",
      "Epoch: 385, total loss: 1.0064, edge loss: 0.9992, node loss: 0.0071\n",
      "Epoch: 386, total loss: 1.0061, edge loss: 0.9987, node loss: 0.0074\n",
      "Epoch: 387, total loss: 1.0084, edge loss: 1.0003, node loss: 0.0081\n",
      "Epoch: 388, total loss: 1.0064, edge loss: 0.9995, node loss: 0.0069\n",
      "Epoch: 389, total loss: 1.0082, edge loss: 1.0002, node loss: 0.0080\n",
      "Epoch: 390, total loss: 1.0081, edge loss: 1.0003, node loss: 0.0078\n",
      "Epoch: 391, total loss: 1.0064, edge loss: 1.0003, node loss: 0.0061\n",
      "Epoch: 392, total loss: 1.0067, edge loss: 0.9997, node loss: 0.0070\n",
      "Epoch: 393, total loss: 1.0069, edge loss: 0.9996, node loss: 0.0073\n",
      "Epoch: 394, total loss: 1.0082, edge loss: 0.9997, node loss: 0.0085\n",
      "Epoch: 395, total loss: 1.0063, edge loss: 0.9998, node loss: 0.0064\n",
      "Epoch: 396, total loss: 1.0078, edge loss: 1.0003, node loss: 0.0075\n",
      "Epoch: 397, total loss: 1.0043, edge loss: 0.9984, node loss: 0.0059\n",
      "Epoch: 398, total loss: 1.0069, edge loss: 1.0001, node loss: 0.0069\n",
      "Epoch: 399, total loss: 1.0076, edge loss: 1.0007, node loss: 0.0069\n",
      "Epoch: 400, total loss: 1.0085, edge loss: 0.9999, node loss: 0.0086\n",
      "Epoch: 401, total loss: 1.0085, edge loss: 0.9996, node loss: 0.0089\n",
      "Epoch: 402, total loss: 1.0063, edge loss: 0.9997, node loss: 0.0067\n",
      "Epoch: 403, total loss: 1.0087, edge loss: 1.0009, node loss: 0.0078\n",
      "Epoch: 404, total loss: 1.0070, edge loss: 1.0006, node loss: 0.0065\n",
      "Epoch: 405, total loss: 1.0071, edge loss: 1.0005, node loss: 0.0066\n",
      "Epoch: 406, total loss: 1.0080, edge loss: 1.0006, node loss: 0.0074\n",
      "Epoch: 407, total loss: 1.0067, edge loss: 1.0002, node loss: 0.0064\n",
      "Epoch: 408, total loss: 1.0062, edge loss: 0.9995, node loss: 0.0067\n",
      "Epoch: 409, total loss: 1.0059, edge loss: 0.9998, node loss: 0.0061\n",
      "Epoch: 410, total loss: 1.0056, edge loss: 1.0002, node loss: 0.0053\n",
      "Epoch: 411, total loss: 1.0045, edge loss: 0.9989, node loss: 0.0056\n",
      "Epoch: 412, total loss: 1.0063, edge loss: 0.9995, node loss: 0.0068\n",
      "Epoch: 413, total loss: 1.0068, edge loss: 1.0003, node loss: 0.0066\n",
      "Epoch: 414, total loss: 1.0063, edge loss: 1.0003, node loss: 0.0061\n",
      "Epoch: 415, total loss: 1.0056, edge loss: 0.9991, node loss: 0.0065\n",
      "Epoch: 416, total loss: 1.0056, edge loss: 1.0001, node loss: 0.0054\n",
      "Epoch: 417, total loss: 1.0069, edge loss: 1.0000, node loss: 0.0069\n",
      "Epoch: 418, total loss: 1.0067, edge loss: 1.0006, node loss: 0.0061\n",
      "Epoch: 419, total loss: 1.0050, edge loss: 0.9997, node loss: 0.0053\n",
      "Epoch: 420, total loss: 1.0048, edge loss: 0.9993, node loss: 0.0054\n",
      "Epoch: 421, total loss: 1.0049, edge loss: 0.9994, node loss: 0.0054\n",
      "Epoch: 422, total loss: 1.0061, edge loss: 0.9998, node loss: 0.0062\n",
      "Epoch: 423, total loss: 1.0054, edge loss: 0.9996, node loss: 0.0058\n",
      "Epoch: 424, total loss: 1.0057, edge loss: 0.9996, node loss: 0.0060\n",
      "Epoch: 425, total loss: 1.0075, edge loss: 1.0000, node loss: 0.0074\n",
      "Epoch: 426, total loss: 1.0059, edge loss: 1.0005, node loss: 0.0054\n",
      "Epoch: 427, total loss: 1.0070, edge loss: 1.0001, node loss: 0.0069\n",
      "Epoch: 428, total loss: 1.0064, edge loss: 0.9996, node loss: 0.0068\n",
      "Epoch: 429, total loss: 1.0069, edge loss: 1.0006, node loss: 0.0063\n",
      "Epoch: 430, total loss: 1.0058, edge loss: 0.9998, node loss: 0.0060\n",
      "Epoch: 431, total loss: 1.0063, edge loss: 1.0002, node loss: 0.0061\n",
      "Epoch: 432, total loss: 1.0067, edge loss: 1.0001, node loss: 0.0066\n",
      "Epoch: 433, total loss: 1.0056, edge loss: 0.9997, node loss: 0.0059\n",
      "Epoch: 434, total loss: 1.0068, edge loss: 1.0010, node loss: 0.0058\n",
      "Epoch: 435, total loss: 1.0078, edge loss: 0.9993, node loss: 0.0085\n",
      "Epoch: 436, total loss: 1.0049, edge loss: 0.9991, node loss: 0.0059\n",
      "Epoch: 437, total loss: 1.0061, edge loss: 1.0001, node loss: 0.0061\n",
      "Epoch: 438, total loss: 1.0067, edge loss: 1.0007, node loss: 0.0059\n",
      "Epoch: 439, total loss: 1.0052, edge loss: 0.9994, node loss: 0.0058\n",
      "Epoch: 440, total loss: 1.0041, edge loss: 0.9989, node loss: 0.0053\n",
      "Epoch: 441, total loss: 1.0042, edge loss: 0.9992, node loss: 0.0050\n",
      "Epoch: 442, total loss: 1.0060, edge loss: 1.0002, node loss: 0.0058\n",
      "Epoch: 443, total loss: 1.0044, edge loss: 0.9994, node loss: 0.0051\n",
      "Epoch: 444, total loss: 1.0062, edge loss: 0.9999, node loss: 0.0063\n",
      "Epoch: 445, total loss: 1.0057, edge loss: 1.0002, node loss: 0.0055\n",
      "Epoch: 446, total loss: 1.0061, edge loss: 1.0003, node loss: 0.0059\n",
      "Epoch: 447, total loss: 1.0048, edge loss: 0.9998, node loss: 0.0051\n",
      "Epoch: 448, total loss: 1.0049, edge loss: 1.0001, node loss: 0.0048\n",
      "Epoch: 449, total loss: 1.0065, edge loss: 1.0006, node loss: 0.0059\n",
      "Epoch: 450, total loss: 1.0048, edge loss: 0.9990, node loss: 0.0057\n",
      "Epoch: 451, total loss: 1.0046, edge loss: 0.9997, node loss: 0.0049\n",
      "Epoch: 452, total loss: 1.0051, edge loss: 1.0003, node loss: 0.0048\n",
      "Epoch: 453, total loss: 1.0047, edge loss: 0.9993, node loss: 0.0054\n",
      "Epoch: 454, total loss: 1.0095, edge loss: 1.0009, node loss: 0.0086\n",
      "Epoch: 455, total loss: 1.0061, edge loss: 1.0001, node loss: 0.0060\n",
      "Epoch: 456, total loss: 1.0064, edge loss: 1.0005, node loss: 0.0059\n",
      "Epoch: 457, total loss: 1.0054, edge loss: 1.0001, node loss: 0.0053\n",
      "Epoch: 458, total loss: 1.0050, edge loss: 0.9995, node loss: 0.0056\n",
      "Epoch: 459, total loss: 1.0060, edge loss: 1.0008, node loss: 0.0052\n",
      "Epoch: 460, total loss: 1.0069, edge loss: 1.0007, node loss: 0.0062\n",
      "Epoch: 461, total loss: 1.0056, edge loss: 1.0005, node loss: 0.0051\n",
      "Epoch: 462, total loss: 1.0067, edge loss: 1.0004, node loss: 0.0063\n",
      "Epoch: 463, total loss: 1.0057, edge loss: 0.9999, node loss: 0.0058\n",
      "Epoch: 464, total loss: 1.0047, edge loss: 0.9997, node loss: 0.0049\n",
      "Epoch: 465, total loss: 1.0052, edge loss: 1.0002, node loss: 0.0050\n",
      "Epoch: 466, total loss: 1.0068, edge loss: 0.9998, node loss: 0.0070\n",
      "Epoch: 467, total loss: 1.0058, edge loss: 0.9997, node loss: 0.0060\n",
      "Epoch: 468, total loss: 1.0055, edge loss: 1.0002, node loss: 0.0053\n",
      "Epoch: 469, total loss: 1.0037, edge loss: 0.9996, node loss: 0.0041\n",
      "Epoch: 470, total loss: 1.0053, edge loss: 0.9996, node loss: 0.0057\n",
      "Epoch: 471, total loss: 1.0039, edge loss: 0.9998, node loss: 0.0042\n",
      "Epoch: 472, total loss: 1.0047, edge loss: 1.0002, node loss: 0.0045\n",
      "Epoch: 473, total loss: 1.0050, edge loss: 1.0005, node loss: 0.0046\n",
      "Epoch: 474, total loss: 1.0041, edge loss: 0.9991, node loss: 0.0050\n",
      "Epoch: 475, total loss: 1.0050, edge loss: 1.0003, node loss: 0.0047\n",
      "Epoch: 476, total loss: 1.0046, edge loss: 0.9991, node loss: 0.0055\n",
      "Epoch: 477, total loss: 1.0049, edge loss: 0.9995, node loss: 0.0054\n",
      "Epoch: 478, total loss: 1.0063, edge loss: 0.9993, node loss: 0.0070\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 479, total loss: 1.0053, edge loss: 1.0002, node loss: 0.0051\n",
      "Epoch: 480, total loss: 1.0059, edge loss: 1.0012, node loss: 0.0046\n",
      "Epoch: 481, total loss: 1.0052, edge loss: 1.0004, node loss: 0.0048\n",
      "Epoch: 482, total loss: 1.0043, edge loss: 0.9997, node loss: 0.0046\n",
      "Epoch: 483, total loss: 1.0043, edge loss: 0.9996, node loss: 0.0047\n",
      "Epoch: 484, total loss: 1.0064, edge loss: 1.0016, node loss: 0.0049\n",
      "Epoch: 485, total loss: 1.0043, edge loss: 0.9993, node loss: 0.0049\n",
      "Epoch: 486, total loss: 1.0060, edge loss: 1.0004, node loss: 0.0056\n",
      "Epoch: 487, total loss: 1.0045, edge loss: 0.9998, node loss: 0.0046\n",
      "Epoch: 488, total loss: 1.0067, edge loss: 1.0010, node loss: 0.0057\n",
      "Epoch: 489, total loss: 1.0069, edge loss: 1.0006, node loss: 0.0063\n",
      "Epoch: 490, total loss: 1.0041, edge loss: 0.9991, node loss: 0.0050\n",
      "Epoch: 491, total loss: 1.0055, edge loss: 1.0008, node loss: 0.0048\n",
      "Epoch: 492, total loss: 1.0069, edge loss: 1.0014, node loss: 0.0055\n",
      "Epoch: 493, total loss: 1.0043, edge loss: 0.9991, node loss: 0.0052\n",
      "Epoch: 494, total loss: 1.0042, edge loss: 0.9994, node loss: 0.0048\n",
      "Epoch: 495, total loss: 1.0042, edge loss: 0.9997, node loss: 0.0045\n",
      "Epoch: 496, total loss: 1.0066, edge loss: 1.0005, node loss: 0.0061\n",
      "Epoch: 497, total loss: 1.0059, edge loss: 1.0005, node loss: 0.0054\n",
      "Epoch: 498, total loss: 1.0044, edge loss: 0.9999, node loss: 0.0045\n",
      "Epoch: 499, total loss: 1.0038, edge loss: 0.9992, node loss: 0.0046\n",
      "Epoch: 500, total loss: 1.0054, edge loss: 1.0003, node loss: 0.0051\n",
      "Epoch: 501, total loss: 1.0053, edge loss: 1.0005, node loss: 0.0048\n",
      "Epoch: 502, total loss: 1.0040, edge loss: 1.0001, node loss: 0.0039\n",
      "Epoch: 503, total loss: 1.0049, edge loss: 1.0001, node loss: 0.0047\n",
      "Epoch: 504, total loss: 1.0040, edge loss: 0.9999, node loss: 0.0041\n",
      "Epoch: 505, total loss: 1.0040, edge loss: 0.9994, node loss: 0.0046\n",
      "Epoch: 506, total loss: 1.0048, edge loss: 1.0006, node loss: 0.0042\n",
      "Epoch: 507, total loss: 1.0050, edge loss: 1.0001, node loss: 0.0049\n",
      "Epoch: 508, total loss: 1.0040, edge loss: 0.9983, node loss: 0.0057\n",
      "Epoch: 509, total loss: 1.0058, edge loss: 1.0012, node loss: 0.0047\n",
      "Epoch: 510, total loss: 1.0058, edge loss: 1.0011, node loss: 0.0047\n",
      "Epoch: 511, total loss: 1.0048, edge loss: 1.0001, node loss: 0.0047\n",
      "Epoch: 512, total loss: 1.0059, edge loss: 1.0006, node loss: 0.0053\n",
      "Epoch: 513, total loss: 1.0055, edge loss: 0.9993, node loss: 0.0061\n",
      "Epoch: 514, total loss: 1.0038, edge loss: 0.9988, node loss: 0.0050\n",
      "Epoch: 515, total loss: 1.0042, edge loss: 1.0000, node loss: 0.0042\n",
      "Epoch: 516, total loss: 1.0059, edge loss: 1.0002, node loss: 0.0057\n",
      "Epoch: 517, total loss: 1.0043, edge loss: 0.9999, node loss: 0.0043\n",
      "Epoch: 518, total loss: 1.0049, edge loss: 1.0004, node loss: 0.0045\n",
      "Epoch: 519, total loss: 1.0062, edge loss: 1.0004, node loss: 0.0058\n",
      "Epoch: 520, total loss: 1.0043, edge loss: 1.0003, node loss: 0.0040\n",
      "Epoch: 521, total loss: 1.0044, edge loss: 0.9995, node loss: 0.0049\n",
      "Epoch: 522, total loss: 1.0051, edge loss: 1.0001, node loss: 0.0050\n",
      "Epoch: 523, total loss: 1.0048, edge loss: 1.0010, node loss: 0.0039\n",
      "Epoch: 524, total loss: 1.0060, edge loss: 1.0004, node loss: 0.0056\n",
      "Epoch: 525, total loss: 1.0046, edge loss: 0.9996, node loss: 0.0050\n",
      "Epoch: 526, total loss: 1.0028, edge loss: 0.9986, node loss: 0.0041\n",
      "Epoch: 527, total loss: 1.0045, edge loss: 1.0007, node loss: 0.0038\n",
      "Epoch: 528, total loss: 1.0044, edge loss: 0.9993, node loss: 0.0051\n",
      "Epoch: 529, total loss: 1.0051, edge loss: 1.0009, node loss: 0.0043\n",
      "Epoch: 530, total loss: 1.0043, edge loss: 1.0004, node loss: 0.0039\n",
      "Epoch: 531, total loss: 1.0050, edge loss: 1.0006, node loss: 0.0044\n",
      "Epoch: 532, total loss: 1.0032, edge loss: 0.9991, node loss: 0.0041\n",
      "Epoch: 533, total loss: 1.0050, edge loss: 1.0005, node loss: 0.0046\n",
      "Epoch: 534, total loss: 1.0043, edge loss: 1.0004, node loss: 0.0039\n",
      "Epoch: 535, total loss: 1.0048, edge loss: 0.9996, node loss: 0.0052\n",
      "Epoch: 536, total loss: 1.0047, edge loss: 1.0004, node loss: 0.0043\n",
      "Epoch: 537, total loss: 1.0053, edge loss: 1.0004, node loss: 0.0049\n",
      "Epoch: 538, total loss: 1.0036, edge loss: 0.9998, node loss: 0.0038\n",
      "Epoch: 539, total loss: 1.0050, edge loss: 1.0004, node loss: 0.0046\n",
      "Epoch: 540, total loss: 1.0059, edge loss: 1.0008, node loss: 0.0051\n",
      "Epoch: 541, total loss: 1.0037, edge loss: 0.9996, node loss: 0.0041\n",
      "Epoch: 542, total loss: 1.0041, edge loss: 0.9992, node loss: 0.0049\n",
      "Epoch: 543, total loss: 1.0042, edge loss: 0.9999, node loss: 0.0043\n",
      "Epoch: 544, total loss: 1.0046, edge loss: 0.9998, node loss: 0.0048\n",
      "Epoch: 545, total loss: 1.0034, edge loss: 0.9994, node loss: 0.0040\n",
      "Epoch: 546, total loss: 1.0042, edge loss: 1.0000, node loss: 0.0042\n",
      "Epoch: 547, total loss: 1.0055, edge loss: 1.0005, node loss: 0.0050\n",
      "Epoch: 548, total loss: 1.0044, edge loss: 1.0003, node loss: 0.0041\n",
      "Epoch: 549, total loss: 1.0035, edge loss: 0.9994, node loss: 0.0040\n",
      "Epoch: 550, total loss: 1.0042, edge loss: 1.0003, node loss: 0.0039\n",
      "Epoch: 551, total loss: 1.0046, edge loss: 0.9999, node loss: 0.0047\n",
      "Epoch: 552, total loss: 1.0050, edge loss: 1.0001, node loss: 0.0049\n",
      "Epoch: 553, total loss: 1.0053, edge loss: 1.0006, node loss: 0.0047\n",
      "Epoch: 554, total loss: 1.0045, edge loss: 0.9999, node loss: 0.0046\n",
      "Epoch: 555, total loss: 1.0051, edge loss: 1.0000, node loss: 0.0051\n",
      "Epoch: 556, total loss: 1.0047, edge loss: 0.9998, node loss: 0.0050\n",
      "Epoch: 557, total loss: 1.0055, edge loss: 1.0001, node loss: 0.0055\n",
      "Epoch: 558, total loss: 1.0051, edge loss: 0.9998, node loss: 0.0053\n",
      "Epoch: 559, total loss: 1.0048, edge loss: 1.0006, node loss: 0.0042\n",
      "Epoch: 560, total loss: 1.0039, edge loss: 0.9998, node loss: 0.0041\n",
      "Epoch: 561, total loss: 1.0045, edge loss: 0.9991, node loss: 0.0054\n",
      "Epoch: 562, total loss: 1.0045, edge loss: 1.0005, node loss: 0.0040\n",
      "Epoch: 563, total loss: 1.0043, edge loss: 0.9987, node loss: 0.0056\n",
      "Epoch: 564, total loss: 1.0032, edge loss: 0.9993, node loss: 0.0039\n",
      "Epoch: 565, total loss: 1.0048, edge loss: 1.0003, node loss: 0.0044\n",
      "Epoch: 566, total loss: 1.0033, edge loss: 0.9995, node loss: 0.0038\n",
      "Epoch: 567, total loss: 1.0038, edge loss: 0.9997, node loss: 0.0041\n",
      "Epoch: 568, total loss: 1.0053, edge loss: 1.0012, node loss: 0.0041\n",
      "Epoch: 569, total loss: 1.0048, edge loss: 1.0000, node loss: 0.0048\n",
      "Epoch: 570, total loss: 1.0039, edge loss: 0.9992, node loss: 0.0047\n",
      "Epoch: 571, total loss: 1.0050, edge loss: 1.0004, node loss: 0.0046\n",
      "Epoch: 572, total loss: 1.0020, edge loss: 0.9983, node loss: 0.0038\n",
      "Epoch: 573, total loss: 1.0056, edge loss: 1.0000, node loss: 0.0056\n",
      "Epoch: 574, total loss: 1.0056, edge loss: 1.0007, node loss: 0.0049\n",
      "Epoch: 575, total loss: 1.0034, edge loss: 0.9996, node loss: 0.0037\n",
      "Epoch: 576, total loss: 1.0033, edge loss: 0.9995, node loss: 0.0038\n",
      "Epoch: 577, total loss: 1.0056, edge loss: 1.0006, node loss: 0.0050\n",
      "Epoch: 578, total loss: 1.0027, edge loss: 0.9985, node loss: 0.0042\n",
      "Epoch: 579, total loss: 1.0039, edge loss: 0.9997, node loss: 0.0042\n",
      "Epoch: 580, total loss: 1.0040, edge loss: 0.9998, node loss: 0.0042\n",
      "Epoch: 581, total loss: 1.0043, edge loss: 0.9998, node loss: 0.0044\n",
      "Epoch: 582, total loss: 1.0042, edge loss: 1.0002, node loss: 0.0040\n",
      "Epoch: 583, total loss: 1.0044, edge loss: 1.0002, node loss: 0.0042\n",
      "Epoch: 584, total loss: 1.0047, edge loss: 1.0007, node loss: 0.0040\n",
      "Epoch: 585, total loss: 1.0037, edge loss: 0.9998, node loss: 0.0038\n",
      "Epoch: 586, total loss: 1.0051, edge loss: 1.0004, node loss: 0.0046\n",
      "Epoch: 587, total loss: 1.0045, edge loss: 1.0000, node loss: 0.0045\n",
      "Epoch: 588, total loss: 1.0050, edge loss: 1.0001, node loss: 0.0050\n",
      "Epoch: 589, total loss: 1.0039, edge loss: 1.0002, node loss: 0.0037\n",
      "Epoch: 590, total loss: 1.0046, edge loss: 1.0004, node loss: 0.0042\n",
      "Epoch: 591, total loss: 1.0048, edge loss: 1.0006, node loss: 0.0041\n",
      "Epoch: 592, total loss: 1.0032, edge loss: 0.9996, node loss: 0.0035\n",
      "Epoch: 593, total loss: 1.0045, edge loss: 1.0004, node loss: 0.0042\n",
      "Epoch: 594, total loss: 1.0051, edge loss: 1.0002, node loss: 0.0049\n",
      "Epoch: 595, total loss: 1.0034, edge loss: 0.9990, node loss: 0.0043\n",
      "Epoch: 596, total loss: 1.0045, edge loss: 1.0004, node loss: 0.0041\n",
      "Epoch: 597, total loss: 1.0037, edge loss: 0.9999, node loss: 0.0038\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 598, total loss: 1.0038, edge loss: 0.9999, node loss: 0.0039\n",
      "Epoch: 599, total loss: 1.0062, edge loss: 1.0011, node loss: 0.0051\n",
      "Epoch: 600, total loss: 1.0047, edge loss: 1.0008, node loss: 0.0040\n",
      "Epoch: 601, total loss: 1.0042, edge loss: 0.9999, node loss: 0.0043\n",
      "Epoch: 602, total loss: 1.0032, edge loss: 0.9994, node loss: 0.0039\n",
      "Epoch: 603, total loss: 1.0029, edge loss: 0.9994, node loss: 0.0035\n",
      "Epoch: 604, total loss: 1.0048, edge loss: 1.0006, node loss: 0.0042\n",
      "Epoch: 605, total loss: 1.0045, edge loss: 1.0006, node loss: 0.0040\n",
      "Epoch: 606, total loss: 1.0042, edge loss: 1.0008, node loss: 0.0034\n",
      "Epoch: 607, total loss: 1.0038, edge loss: 1.0000, node loss: 0.0037\n",
      "Epoch: 608, total loss: 1.0031, edge loss: 0.9997, node loss: 0.0034\n",
      "Epoch: 609, total loss: 1.0036, edge loss: 0.9998, node loss: 0.0038\n",
      "Epoch: 610, total loss: 1.0042, edge loss: 1.0007, node loss: 0.0035\n",
      "Epoch: 611, total loss: 1.0042, edge loss: 1.0007, node loss: 0.0035\n",
      "Epoch: 612, total loss: 1.0038, edge loss: 0.9999, node loss: 0.0039\n",
      "Epoch: 613, total loss: 1.0042, edge loss: 1.0003, node loss: 0.0039\n",
      "Epoch: 614, total loss: 1.0048, edge loss: 1.0003, node loss: 0.0045\n",
      "Epoch: 615, total loss: 1.0045, edge loss: 1.0006, node loss: 0.0039\n",
      "Epoch: 616, total loss: 1.0050, edge loss: 1.0007, node loss: 0.0043\n",
      "Epoch: 617, total loss: 1.0037, edge loss: 0.9996, node loss: 0.0041\n",
      "Epoch: 618, total loss: 1.0036, edge loss: 1.0001, node loss: 0.0035\n",
      "Epoch: 619, total loss: 1.0048, edge loss: 1.0010, node loss: 0.0038\n",
      "Epoch: 620, total loss: 1.0049, edge loss: 0.9996, node loss: 0.0053\n",
      "Epoch: 621, total loss: 1.0046, edge loss: 1.0006, node loss: 0.0040\n",
      "Epoch: 622, total loss: 1.0056, edge loss: 1.0019, node loss: 0.0037\n",
      "Epoch: 623, total loss: 1.0049, edge loss: 1.0008, node loss: 0.0042\n",
      "Epoch: 624, total loss: 1.0032, edge loss: 0.9997, node loss: 0.0035\n",
      "Epoch: 625, total loss: 1.0055, edge loss: 0.9998, node loss: 0.0057\n",
      "Epoch: 626, total loss: 1.0034, edge loss: 0.9996, node loss: 0.0038\n",
      "Epoch: 627, total loss: 1.0055, edge loss: 1.0011, node loss: 0.0044\n",
      "Epoch: 628, total loss: 1.0053, edge loss: 1.0006, node loss: 0.0048\n",
      "Epoch: 629, total loss: 1.0046, edge loss: 1.0003, node loss: 0.0043\n",
      "Epoch: 630, total loss: 1.0046, edge loss: 0.9998, node loss: 0.0047\n",
      "Epoch: 631, total loss: 1.0043, edge loss: 1.0001, node loss: 0.0042\n",
      "Epoch: 632, total loss: 1.0055, edge loss: 1.0003, node loss: 0.0052\n",
      "Epoch: 633, total loss: 1.0049, edge loss: 1.0006, node loss: 0.0043\n",
      "Epoch: 634, total loss: 1.0044, edge loss: 1.0003, node loss: 0.0042\n",
      "Epoch: 635, total loss: 1.0043, edge loss: 1.0006, node loss: 0.0037\n",
      "Epoch: 636, total loss: 1.0034, edge loss: 0.9997, node loss: 0.0037\n",
      "Epoch: 637, total loss: 1.0046, edge loss: 1.0008, node loss: 0.0037\n",
      "Epoch: 638, total loss: 1.0040, edge loss: 0.9997, node loss: 0.0042\n",
      "Epoch: 639, total loss: 1.0051, edge loss: 1.0005, node loss: 0.0047\n",
      "Epoch: 640, total loss: 1.0046, edge loss: 1.0009, node loss: 0.0037\n",
      "Epoch: 641, total loss: 1.0043, edge loss: 1.0001, node loss: 0.0042\n",
      "Epoch: 642, total loss: 1.0030, edge loss: 0.9995, node loss: 0.0035\n",
      "Epoch: 643, total loss: 1.0050, edge loss: 1.0008, node loss: 0.0042\n",
      "Epoch: 644, total loss: 1.0042, edge loss: 0.9997, node loss: 0.0045\n",
      "Epoch: 645, total loss: 1.0028, edge loss: 0.9995, node loss: 0.0032\n",
      "Epoch: 646, total loss: 1.0035, edge loss: 0.9996, node loss: 0.0039\n",
      "Epoch: 647, total loss: 1.0052, edge loss: 1.0004, node loss: 0.0048\n",
      "Epoch: 648, total loss: 1.0045, edge loss: 0.9994, node loss: 0.0050\n",
      "Epoch: 649, total loss: 1.0035, edge loss: 1.0002, node loss: 0.0034\n",
      "Epoch: 650, total loss: 1.0039, edge loss: 1.0001, node loss: 0.0038\n",
      "Epoch: 651, total loss: 1.0045, edge loss: 1.0009, node loss: 0.0036\n",
      "Epoch: 652, total loss: 1.0042, edge loss: 1.0004, node loss: 0.0038\n",
      "Epoch: 653, total loss: 1.0047, edge loss: 1.0005, node loss: 0.0042\n",
      "Epoch: 654, total loss: 1.0037, edge loss: 1.0000, node loss: 0.0037\n",
      "Epoch: 655, total loss: 1.0041, edge loss: 1.0002, node loss: 0.0039\n",
      "Epoch: 656, total loss: 1.0030, edge loss: 0.9998, node loss: 0.0032\n",
      "Epoch: 657, total loss: 1.0042, edge loss: 1.0006, node loss: 0.0036\n",
      "Epoch: 658, total loss: 1.0037, edge loss: 0.9997, node loss: 0.0039\n",
      "Epoch: 659, total loss: 1.0037, edge loss: 1.0002, node loss: 0.0035\n",
      "Epoch: 660, total loss: 1.0037, edge loss: 1.0001, node loss: 0.0036\n",
      "Epoch: 661, total loss: 1.0048, edge loss: 1.0014, node loss: 0.0034\n",
      "Epoch: 662, total loss: 1.0034, edge loss: 0.9996, node loss: 0.0038\n",
      "Epoch: 663, total loss: 1.0043, edge loss: 1.0006, node loss: 0.0037\n",
      "Epoch: 664, total loss: 1.0030, edge loss: 0.9989, node loss: 0.0041\n",
      "Epoch: 665, total loss: 1.0030, edge loss: 0.9994, node loss: 0.0036\n",
      "Epoch: 666, total loss: 1.0038, edge loss: 1.0001, node loss: 0.0037\n",
      "Epoch: 667, total loss: 1.0037, edge loss: 0.9999, node loss: 0.0038\n",
      "Epoch: 668, total loss: 1.0035, edge loss: 0.9994, node loss: 0.0041\n",
      "Epoch: 669, total loss: 1.0040, edge loss: 0.9999, node loss: 0.0040\n",
      "Epoch: 670, total loss: 1.0039, edge loss: 1.0000, node loss: 0.0039\n",
      "Epoch: 671, total loss: 1.0046, edge loss: 1.0011, node loss: 0.0035\n",
      "Epoch: 672, total loss: 1.0047, edge loss: 1.0005, node loss: 0.0043\n",
      "Epoch: 673, total loss: 1.0027, edge loss: 0.9993, node loss: 0.0033\n",
      "Epoch: 674, total loss: 1.0038, edge loss: 0.9999, node loss: 0.0039\n",
      "Epoch: 675, total loss: 1.0040, edge loss: 1.0005, node loss: 0.0035\n",
      "Epoch: 676, total loss: 1.0030, edge loss: 0.9994, node loss: 0.0036\n",
      "Epoch: 677, total loss: 1.0036, edge loss: 1.0005, node loss: 0.0032\n",
      "Epoch: 678, total loss: 1.0047, edge loss: 1.0001, node loss: 0.0046\n",
      "Epoch: 679, total loss: 1.0039, edge loss: 1.0005, node loss: 0.0034\n",
      "Epoch: 680, total loss: 1.0041, edge loss: 1.0004, node loss: 0.0037\n",
      "Epoch: 681, total loss: 1.0041, edge loss: 0.9995, node loss: 0.0047\n",
      "Epoch: 682, total loss: 1.0040, edge loss: 1.0002, node loss: 0.0038\n",
      "Epoch: 683, total loss: 1.0038, edge loss: 0.9994, node loss: 0.0044\n",
      "Epoch: 684, total loss: 1.0033, edge loss: 0.9995, node loss: 0.0037\n",
      "Epoch: 685, total loss: 1.0053, edge loss: 1.0008, node loss: 0.0046\n",
      "Epoch: 686, total loss: 1.0041, edge loss: 1.0002, node loss: 0.0039\n",
      "Epoch: 687, total loss: 1.0039, edge loss: 0.9999, node loss: 0.0040\n",
      "Epoch: 688, total loss: 1.0045, edge loss: 1.0007, node loss: 0.0038\n",
      "Epoch: 689, total loss: 1.0042, edge loss: 0.9998, node loss: 0.0044\n",
      "Epoch: 690, total loss: 1.0033, edge loss: 0.9996, node loss: 0.0037\n",
      "Epoch: 691, total loss: 1.0053, edge loss: 0.9998, node loss: 0.0054\n",
      "Epoch: 692, total loss: 1.0055, edge loss: 1.0005, node loss: 0.0049\n",
      "Epoch: 693, total loss: 1.0032, edge loss: 0.9997, node loss: 0.0034\n",
      "Epoch: 694, total loss: 1.0033, edge loss: 0.9995, node loss: 0.0038\n",
      "Epoch: 695, total loss: 1.0042, edge loss: 0.9993, node loss: 0.0049\n",
      "Epoch: 696, total loss: 1.0041, edge loss: 1.0001, node loss: 0.0041\n",
      "Epoch: 697, total loss: 1.0023, edge loss: 0.9990, node loss: 0.0033\n",
      "Epoch: 698, total loss: 1.0037, edge loss: 1.0000, node loss: 0.0037\n",
      "Epoch: 699, total loss: 1.0043, edge loss: 1.0003, node loss: 0.0040\n",
      "Epoch: 700, total loss: 1.0037, edge loss: 1.0002, node loss: 0.0035\n",
      "Epoch: 701, total loss: 1.0041, edge loss: 1.0002, node loss: 0.0039\n",
      "Epoch: 702, total loss: 1.0032, edge loss: 0.9995, node loss: 0.0037\n",
      "Epoch: 703, total loss: 1.0030, edge loss: 0.9993, node loss: 0.0037\n",
      "Epoch: 704, total loss: 1.0031, edge loss: 0.9996, node loss: 0.0035\n",
      "Epoch: 705, total loss: 1.0047, edge loss: 1.0000, node loss: 0.0047\n",
      "Epoch: 706, total loss: 1.0039, edge loss: 1.0002, node loss: 0.0037\n",
      "Epoch: 707, total loss: 1.0042, edge loss: 1.0001, node loss: 0.0040\n",
      "Epoch: 708, total loss: 1.0023, edge loss: 0.9993, node loss: 0.0030\n",
      "Epoch: 709, total loss: 1.0025, edge loss: 0.9994, node loss: 0.0031\n",
      "Epoch: 710, total loss: 1.0033, edge loss: 0.9994, node loss: 0.0039\n",
      "Epoch: 711, total loss: 1.0037, edge loss: 1.0009, node loss: 0.0028\n",
      "Epoch: 712, total loss: 1.0043, edge loss: 0.9995, node loss: 0.0048\n",
      "Epoch: 713, total loss: 1.0039, edge loss: 0.9998, node loss: 0.0041\n",
      "Epoch: 714, total loss: 1.0035, edge loss: 0.9995, node loss: 0.0040\n",
      "Epoch: 715, total loss: 1.0030, edge loss: 1.0001, node loss: 0.0030\n",
      "Epoch: 716, total loss: 1.0033, edge loss: 0.9996, node loss: 0.0037\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 717, total loss: 1.0036, edge loss: 0.9998, node loss: 0.0038\n",
      "Epoch: 718, total loss: 1.0031, edge loss: 0.9998, node loss: 0.0033\n",
      "Epoch: 719, total loss: 1.0055, edge loss: 1.0002, node loss: 0.0054\n",
      "Epoch: 720, total loss: 1.0039, edge loss: 0.9995, node loss: 0.0044\n",
      "Epoch: 721, total loss: 1.0030, edge loss: 1.0001, node loss: 0.0029\n",
      "Epoch: 722, total loss: 1.0034, edge loss: 0.9992, node loss: 0.0042\n",
      "Epoch: 723, total loss: 1.0038, edge loss: 1.0001, node loss: 0.0037\n",
      "Epoch: 724, total loss: 1.0063, edge loss: 1.0007, node loss: 0.0056\n",
      "Epoch: 725, total loss: 1.0037, edge loss: 0.9998, node loss: 0.0039\n",
      "Epoch: 726, total loss: 1.0043, edge loss: 1.0001, node loss: 0.0042\n",
      "Epoch: 727, total loss: 1.0031, edge loss: 0.9997, node loss: 0.0034\n",
      "Epoch: 728, total loss: 1.0025, edge loss: 0.9993, node loss: 0.0033\n",
      "Epoch: 729, total loss: 1.0026, edge loss: 0.9994, node loss: 0.0032\n",
      "Epoch: 730, total loss: 1.0042, edge loss: 1.0007, node loss: 0.0035\n",
      "Epoch: 731, total loss: 1.0033, edge loss: 1.0003, node loss: 0.0030\n",
      "Epoch: 732, total loss: 1.0037, edge loss: 1.0000, node loss: 0.0037\n",
      "Epoch: 733, total loss: 1.0040, edge loss: 1.0003, node loss: 0.0038\n",
      "Epoch: 734, total loss: 1.0030, edge loss: 0.9997, node loss: 0.0033\n",
      "Epoch: 735, total loss: 1.0027, edge loss: 0.9992, node loss: 0.0035\n",
      "Epoch: 736, total loss: 1.0034, edge loss: 1.0003, node loss: 0.0031\n",
      "Epoch: 737, total loss: 1.0034, edge loss: 0.9998, node loss: 0.0036\n",
      "Epoch: 738, total loss: 1.0045, edge loss: 1.0010, node loss: 0.0035\n",
      "Epoch: 739, total loss: 1.0028, edge loss: 0.9992, node loss: 0.0036\n",
      "Epoch: 740, total loss: 1.0045, edge loss: 1.0001, node loss: 0.0043\n",
      "Epoch: 741, total loss: 1.0059, edge loss: 1.0008, node loss: 0.0051\n",
      "Epoch: 742, total loss: 1.0019, edge loss: 0.9988, node loss: 0.0031\n",
      "Epoch: 743, total loss: 1.0033, edge loss: 0.9996, node loss: 0.0037\n",
      "Epoch: 744, total loss: 1.0035, edge loss: 1.0000, node loss: 0.0035\n",
      "Epoch: 745, total loss: 1.0031, edge loss: 0.9997, node loss: 0.0034\n",
      "Epoch: 746, total loss: 1.0033, edge loss: 1.0000, node loss: 0.0033\n",
      "Epoch: 747, total loss: 1.0037, edge loss: 1.0003, node loss: 0.0034\n",
      "Epoch: 748, total loss: 1.0032, edge loss: 1.0001, node loss: 0.0031\n",
      "Epoch: 749, total loss: 1.0029, edge loss: 0.9997, node loss: 0.0032\n",
      "Epoch: 750, total loss: 1.0056, edge loss: 1.0010, node loss: 0.0046\n",
      "Epoch: 751, total loss: 1.0032, edge loss: 1.0002, node loss: 0.0030\n",
      "Epoch: 752, total loss: 1.0053, edge loss: 1.0015, node loss: 0.0037\n",
      "Epoch: 753, total loss: 1.0030, edge loss: 0.9992, node loss: 0.0037\n",
      "Epoch: 754, total loss: 1.0037, edge loss: 1.0001, node loss: 0.0036\n",
      "Epoch: 755, total loss: 1.0035, edge loss: 1.0007, node loss: 0.0028\n",
      "Epoch: 756, total loss: 1.0042, edge loss: 1.0007, node loss: 0.0035\n",
      "Epoch: 757, total loss: 1.0026, edge loss: 0.9995, node loss: 0.0031\n",
      "Epoch: 758, total loss: 1.0037, edge loss: 1.0000, node loss: 0.0037\n",
      "Epoch: 759, total loss: 1.0029, edge loss: 1.0001, node loss: 0.0028\n",
      "Epoch: 760, total loss: 1.0035, edge loss: 1.0005, node loss: 0.0030\n",
      "Epoch: 761, total loss: 1.0030, edge loss: 1.0000, node loss: 0.0030\n",
      "Epoch: 762, total loss: 1.0035, edge loss: 1.0000, node loss: 0.0035\n",
      "Epoch: 763, total loss: 1.0044, edge loss: 1.0006, node loss: 0.0037\n",
      "Epoch: 764, total loss: 1.0031, edge loss: 1.0000, node loss: 0.0031\n",
      "Epoch: 765, total loss: 1.0034, edge loss: 1.0000, node loss: 0.0034\n",
      "Epoch: 766, total loss: 1.0044, edge loss: 0.9997, node loss: 0.0047\n",
      "Epoch: 767, total loss: 1.0024, edge loss: 0.9993, node loss: 0.0031\n",
      "Epoch: 768, total loss: 1.0034, edge loss: 1.0004, node loss: 0.0030\n",
      "Epoch: 769, total loss: 1.0025, edge loss: 0.9990, node loss: 0.0035\n",
      "Epoch: 770, total loss: 1.0036, edge loss: 1.0005, node loss: 0.0030\n",
      "Epoch: 771, total loss: 1.0041, edge loss: 1.0003, node loss: 0.0038\n",
      "Epoch: 772, total loss: 1.0035, edge loss: 1.0001, node loss: 0.0034\n",
      "Epoch: 773, total loss: 1.0040, edge loss: 1.0002, node loss: 0.0037\n",
      "Epoch: 774, total loss: 1.0041, edge loss: 1.0007, node loss: 0.0034\n",
      "Epoch: 775, total loss: 1.0035, edge loss: 1.0000, node loss: 0.0035\n",
      "Epoch: 776, total loss: 1.0034, edge loss: 1.0003, node loss: 0.0032\n",
      "Epoch: 777, total loss: 1.0044, edge loss: 1.0009, node loss: 0.0035\n",
      "Epoch: 778, total loss: 1.0027, edge loss: 0.9997, node loss: 0.0030\n",
      "Epoch: 779, total loss: 1.0032, edge loss: 1.0003, node loss: 0.0029\n",
      "Epoch: 780, total loss: 1.0032, edge loss: 0.9997, node loss: 0.0034\n",
      "Epoch: 781, total loss: 1.0017, edge loss: 0.9987, node loss: 0.0031\n",
      "Epoch: 782, total loss: 1.0029, edge loss: 0.9991, node loss: 0.0038\n",
      "Epoch: 783, total loss: 1.0034, edge loss: 1.0003, node loss: 0.0031\n",
      "Epoch: 784, total loss: 1.0034, edge loss: 1.0003, node loss: 0.0031\n",
      "Epoch: 785, total loss: 1.0036, edge loss: 0.9997, node loss: 0.0039\n",
      "Epoch: 786, total loss: 1.0033, edge loss: 1.0000, node loss: 0.0034\n",
      "Epoch: 787, total loss: 1.0025, edge loss: 0.9997, node loss: 0.0028\n",
      "Epoch: 788, total loss: 1.0029, edge loss: 0.9998, node loss: 0.0031\n",
      "Epoch: 789, total loss: 1.0030, edge loss: 0.9996, node loss: 0.0034\n",
      "Epoch: 790, total loss: 1.0025, edge loss: 0.9996, node loss: 0.0029\n",
      "Epoch: 791, total loss: 1.0037, edge loss: 1.0007, node loss: 0.0029\n",
      "Epoch: 792, total loss: 1.0032, edge loss: 1.0000, node loss: 0.0032\n",
      "Epoch: 793, total loss: 1.0037, edge loss: 1.0007, node loss: 0.0030\n",
      "Epoch: 794, total loss: 1.0038, edge loss: 1.0003, node loss: 0.0035\n",
      "Epoch: 795, total loss: 1.0033, edge loss: 1.0001, node loss: 0.0031\n",
      "Epoch: 796, total loss: 1.0037, edge loss: 1.0005, node loss: 0.0032\n",
      "Epoch: 797, total loss: 1.0032, edge loss: 0.9998, node loss: 0.0034\n",
      "Epoch: 798, total loss: 1.0023, edge loss: 0.9992, node loss: 0.0031\n",
      "Epoch: 799, total loss: 1.0030, edge loss: 0.9999, node loss: 0.0031\n",
      "Epoch: 800, total loss: 1.0024, edge loss: 0.9995, node loss: 0.0029\n",
      "Epoch: 801, total loss: 1.0024, edge loss: 0.9994, node loss: 0.0031\n",
      "Epoch: 802, total loss: 1.0025, edge loss: 0.9996, node loss: 0.0029\n",
      "Epoch: 803, total loss: 1.0043, edge loss: 1.0005, node loss: 0.0038\n",
      "Epoch: 804, total loss: 1.0043, edge loss: 1.0010, node loss: 0.0033\n",
      "Epoch: 805, total loss: 1.0038, edge loss: 1.0004, node loss: 0.0034\n",
      "Epoch: 806, total loss: 1.0030, edge loss: 1.0001, node loss: 0.0029\n",
      "Epoch: 807, total loss: 1.0041, edge loss: 1.0008, node loss: 0.0032\n",
      "Epoch: 808, total loss: 1.0023, edge loss: 0.9993, node loss: 0.0030\n",
      "Epoch: 809, total loss: 1.0037, edge loss: 0.9997, node loss: 0.0040\n",
      "Epoch: 810, total loss: 1.0028, edge loss: 1.0002, node loss: 0.0026\n",
      "Epoch: 811, total loss: 1.0035, edge loss: 1.0004, node loss: 0.0030\n",
      "Epoch: 812, total loss: 1.0039, edge loss: 1.0006, node loss: 0.0033\n",
      "Epoch: 813, total loss: 1.0028, edge loss: 0.9997, node loss: 0.0031\n",
      "Epoch: 814, total loss: 1.0034, edge loss: 1.0003, node loss: 0.0031\n",
      "Epoch: 815, total loss: 1.0035, edge loss: 1.0000, node loss: 0.0035\n",
      "Epoch: 816, total loss: 1.0027, edge loss: 0.9998, node loss: 0.0029\n",
      "Epoch: 817, total loss: 1.0048, edge loss: 1.0007, node loss: 0.0041\n",
      "Epoch: 818, total loss: 1.0042, edge loss: 1.0003, node loss: 0.0040\n",
      "Epoch: 819, total loss: 1.0026, edge loss: 0.9997, node loss: 0.0029\n",
      "Epoch: 820, total loss: 1.0033, edge loss: 1.0003, node loss: 0.0030\n",
      "Epoch: 821, total loss: 1.0040, edge loss: 1.0009, node loss: 0.0031\n",
      "Epoch: 822, total loss: 1.0031, edge loss: 1.0000, node loss: 0.0031\n",
      "Epoch: 823, total loss: 1.0034, edge loss: 0.9998, node loss: 0.0036\n",
      "Epoch: 824, total loss: 1.0035, edge loss: 0.9994, node loss: 0.0041\n",
      "Epoch: 825, total loss: 1.0050, edge loss: 1.0009, node loss: 0.0041\n",
      "Epoch: 826, total loss: 1.0017, edge loss: 0.9990, node loss: 0.0027\n",
      "Epoch: 827, total loss: 1.0034, edge loss: 1.0002, node loss: 0.0033\n",
      "Epoch: 828, total loss: 1.0033, edge loss: 1.0001, node loss: 0.0032\n",
      "Epoch: 829, total loss: 1.0029, edge loss: 0.9999, node loss: 0.0031\n",
      "Epoch: 830, total loss: 1.0029, edge loss: 0.9998, node loss: 0.0032\n",
      "Epoch: 831, total loss: 1.0043, edge loss: 1.0009, node loss: 0.0035\n",
      "Epoch: 832, total loss: 1.0030, edge loss: 1.0000, node loss: 0.0030\n",
      "Epoch: 833, total loss: 1.0039, edge loss: 1.0006, node loss: 0.0033\n",
      "Epoch: 834, total loss: 1.0031, edge loss: 1.0000, node loss: 0.0031\n",
      "Epoch: 835, total loss: 1.0030, edge loss: 1.0001, node loss: 0.0029\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 836, total loss: 1.0041, edge loss: 1.0005, node loss: 0.0036\n",
      "Epoch: 837, total loss: 1.0022, edge loss: 0.9991, node loss: 0.0031\n",
      "Epoch: 838, total loss: 1.0025, edge loss: 0.9992, node loss: 0.0033\n",
      "Epoch: 839, total loss: 1.0049, edge loss: 1.0005, node loss: 0.0045\n",
      "Epoch: 840, total loss: 1.0040, edge loss: 1.0008, node loss: 0.0032\n",
      "Epoch: 841, total loss: 1.0043, edge loss: 1.0002, node loss: 0.0041\n",
      "Epoch: 842, total loss: 1.0032, edge loss: 1.0004, node loss: 0.0028\n",
      "Epoch: 843, total loss: 1.0039, edge loss: 1.0003, node loss: 0.0036\n",
      "Epoch: 844, total loss: 1.0033, edge loss: 1.0005, node loss: 0.0028\n",
      "Epoch: 845, total loss: 1.0034, edge loss: 1.0000, node loss: 0.0034\n",
      "Epoch: 846, total loss: 1.0035, edge loss: 1.0002, node loss: 0.0033\n",
      "Epoch: 847, total loss: 1.0040, edge loss: 1.0004, node loss: 0.0036\n",
      "Epoch: 848, total loss: 1.0032, edge loss: 0.9997, node loss: 0.0035\n",
      "Epoch: 849, total loss: 1.0033, edge loss: 1.0001, node loss: 0.0032\n",
      "Epoch: 850, total loss: 1.0023, edge loss: 0.9993, node loss: 0.0029\n",
      "Epoch: 851, total loss: 1.0040, edge loss: 1.0008, node loss: 0.0032\n",
      "Epoch: 852, total loss: 1.0041, edge loss: 1.0000, node loss: 0.0040\n",
      "Epoch: 853, total loss: 1.0031, edge loss: 0.9999, node loss: 0.0032\n",
      "Epoch: 854, total loss: 1.0033, edge loss: 1.0005, node loss: 0.0028\n",
      "Epoch: 855, total loss: 1.0035, edge loss: 1.0001, node loss: 0.0034\n",
      "Epoch: 856, total loss: 1.0040, edge loss: 0.9997, node loss: 0.0043\n",
      "Epoch: 857, total loss: 1.0037, edge loss: 1.0004, node loss: 0.0033\n",
      "Epoch: 858, total loss: 1.0032, edge loss: 1.0000, node loss: 0.0033\n",
      "Epoch: 859, total loss: 1.0036, edge loss: 1.0005, node loss: 0.0032\n",
      "Epoch: 860, total loss: 1.0031, edge loss: 1.0002, node loss: 0.0029\n",
      "Epoch: 861, total loss: 1.0031, edge loss: 1.0002, node loss: 0.0029\n",
      "Epoch: 862, total loss: 1.0030, edge loss: 1.0001, node loss: 0.0029\n",
      "Epoch: 863, total loss: 1.0021, edge loss: 0.9991, node loss: 0.0030\n",
      "Epoch: 864, total loss: 1.0035, edge loss: 1.0003, node loss: 0.0032\n",
      "Epoch: 865, total loss: 1.0031, edge loss: 1.0003, node loss: 0.0028\n",
      "Epoch: 866, total loss: 1.0021, edge loss: 0.9993, node loss: 0.0028\n",
      "Epoch: 867, total loss: 1.0031, edge loss: 0.9998, node loss: 0.0033\n",
      "Epoch: 868, total loss: 1.0035, edge loss: 1.0005, node loss: 0.0030\n",
      "Epoch: 869, total loss: 1.0030, edge loss: 0.9991, node loss: 0.0039\n",
      "Epoch: 870, total loss: 1.0021, edge loss: 0.9992, node loss: 0.0029\n",
      "Epoch: 871, total loss: 1.0029, edge loss: 1.0002, node loss: 0.0027\n",
      "Epoch: 872, total loss: 1.0030, edge loss: 0.9999, node loss: 0.0031\n",
      "Epoch: 873, total loss: 1.0029, edge loss: 0.9998, node loss: 0.0031\n",
      "Epoch: 874, total loss: 1.0057, edge loss: 1.0015, node loss: 0.0042\n",
      "Epoch: 875, total loss: 1.0026, edge loss: 0.9994, node loss: 0.0033\n",
      "Epoch: 876, total loss: 1.0040, edge loss: 1.0005, node loss: 0.0036\n",
      "Epoch: 877, total loss: 1.0039, edge loss: 1.0006, node loss: 0.0033\n",
      "Epoch: 878, total loss: 1.0027, edge loss: 0.9998, node loss: 0.0028\n",
      "Epoch: 879, total loss: 1.0054, edge loss: 1.0016, node loss: 0.0038\n",
      "Epoch: 880, total loss: 1.0035, edge loss: 1.0007, node loss: 0.0028\n",
      "Epoch: 881, total loss: 1.0030, edge loss: 0.9998, node loss: 0.0032\n",
      "Epoch: 882, total loss: 1.0037, edge loss: 1.0005, node loss: 0.0032\n",
      "Epoch: 883, total loss: 1.0026, edge loss: 0.9998, node loss: 0.0029\n",
      "Epoch: 884, total loss: 1.0029, edge loss: 0.9998, node loss: 0.0030\n",
      "Epoch: 885, total loss: 1.0033, edge loss: 1.0004, node loss: 0.0029\n",
      "Epoch: 886, total loss: 1.0032, edge loss: 1.0004, node loss: 0.0029\n",
      "Epoch: 887, total loss: 1.0031, edge loss: 1.0005, node loss: 0.0026\n",
      "Epoch: 888, total loss: 1.0019, edge loss: 0.9993, node loss: 0.0026\n",
      "Epoch: 889, total loss: 1.0031, edge loss: 0.9998, node loss: 0.0033\n",
      "Epoch: 890, total loss: 1.0027, edge loss: 0.9992, node loss: 0.0034\n",
      "Epoch: 891, total loss: 1.0027, edge loss: 0.9999, node loss: 0.0028\n",
      "Epoch: 892, total loss: 1.0031, edge loss: 1.0003, node loss: 0.0028\n",
      "Epoch: 893, total loss: 1.0033, edge loss: 1.0005, node loss: 0.0028\n",
      "Epoch: 894, total loss: 1.0030, edge loss: 0.9999, node loss: 0.0031\n",
      "Epoch: 895, total loss: 1.0033, edge loss: 1.0000, node loss: 0.0033\n",
      "Epoch: 896, total loss: 1.0028, edge loss: 1.0001, node loss: 0.0027\n",
      "Epoch: 897, total loss: 1.0023, edge loss: 0.9992, node loss: 0.0031\n",
      "Epoch: 898, total loss: 1.0025, edge loss: 1.0000, node loss: 0.0025\n",
      "Epoch: 899, total loss: 1.0034, edge loss: 1.0003, node loss: 0.0031\n",
      "Epoch: 900, total loss: 1.0036, edge loss: 1.0006, node loss: 0.0030\n",
      "Epoch: 901, total loss: 1.0031, edge loss: 1.0005, node loss: 0.0027\n",
      "Epoch: 902, total loss: 1.0044, edge loss: 1.0001, node loss: 0.0043\n",
      "Epoch: 903, total loss: 1.0034, edge loss: 1.0001, node loss: 0.0033\n",
      "Epoch: 904, total loss: 1.0033, edge loss: 1.0004, node loss: 0.0029\n",
      "Epoch: 905, total loss: 1.0030, edge loss: 1.0000, node loss: 0.0030\n",
      "Epoch: 906, total loss: 1.0038, edge loss: 1.0008, node loss: 0.0030\n",
      "Epoch: 907, total loss: 1.0030, edge loss: 1.0001, node loss: 0.0028\n",
      "Epoch: 908, total loss: 1.0030, edge loss: 0.9991, node loss: 0.0038\n",
      "Epoch: 909, total loss: 1.0027, edge loss: 0.9998, node loss: 0.0029\n",
      "Epoch: 910, total loss: 1.0035, edge loss: 1.0008, node loss: 0.0026\n",
      "Epoch: 911, total loss: 1.0036, edge loss: 1.0007, node loss: 0.0029\n",
      "Epoch: 912, total loss: 1.0032, edge loss: 1.0000, node loss: 0.0032\n",
      "Epoch: 913, total loss: 1.0024, edge loss: 0.9998, node loss: 0.0026\n",
      "Epoch: 914, total loss: 1.0046, edge loss: 1.0011, node loss: 0.0035\n",
      "Epoch: 915, total loss: 1.0038, edge loss: 1.0009, node loss: 0.0029\n",
      "Epoch: 916, total loss: 1.0029, edge loss: 0.9991, node loss: 0.0038\n",
      "Epoch: 917, total loss: 1.0022, edge loss: 0.9992, node loss: 0.0030\n",
      "Epoch: 918, total loss: 1.0029, edge loss: 0.9999, node loss: 0.0030\n",
      "Epoch: 919, total loss: 1.0030, edge loss: 1.0003, node loss: 0.0027\n",
      "Epoch: 920, total loss: 1.0028, edge loss: 1.0001, node loss: 0.0027\n",
      "Epoch: 921, total loss: 1.0030, edge loss: 0.9998, node loss: 0.0032\n",
      "Epoch: 922, total loss: 1.0036, edge loss: 1.0000, node loss: 0.0036\n",
      "Epoch: 923, total loss: 1.0041, edge loss: 1.0005, node loss: 0.0036\n",
      "Epoch: 924, total loss: 1.0022, edge loss: 0.9994, node loss: 0.0029\n",
      "Epoch: 925, total loss: 1.0028, edge loss: 0.9997, node loss: 0.0031\n",
      "Epoch: 926, total loss: 1.0040, edge loss: 1.0003, node loss: 0.0037\n",
      "Epoch: 927, total loss: 1.0031, edge loss: 1.0001, node loss: 0.0030\n",
      "Epoch: 928, total loss: 1.0025, edge loss: 1.0000, node loss: 0.0025\n",
      "Epoch: 929, total loss: 1.0026, edge loss: 0.9995, node loss: 0.0031\n",
      "Epoch: 930, total loss: 1.0023, edge loss: 0.9994, node loss: 0.0029\n",
      "Epoch: 931, total loss: 1.0026, edge loss: 0.9996, node loss: 0.0030\n",
      "Epoch: 932, total loss: 1.0041, edge loss: 1.0012, node loss: 0.0030\n",
      "Epoch: 933, total loss: 1.0029, edge loss: 1.0004, node loss: 0.0025\n",
      "Epoch: 934, total loss: 1.0024, edge loss: 0.9997, node loss: 0.0028\n",
      "Epoch: 935, total loss: 1.0033, edge loss: 1.0008, node loss: 0.0025\n",
      "Epoch: 936, total loss: 1.0035, edge loss: 0.9996, node loss: 0.0038\n",
      "Epoch: 937, total loss: 1.0023, edge loss: 0.9996, node loss: 0.0027\n",
      "Epoch: 938, total loss: 1.0024, edge loss: 0.9995, node loss: 0.0028\n",
      "Epoch: 939, total loss: 1.0031, edge loss: 1.0006, node loss: 0.0025\n",
      "Epoch: 940, total loss: 1.0030, edge loss: 1.0001, node loss: 0.0028\n",
      "Epoch: 941, total loss: 1.0019, edge loss: 0.9993, node loss: 0.0026\n",
      "Epoch: 942, total loss: 1.0040, edge loss: 1.0007, node loss: 0.0033\n",
      "Epoch: 943, total loss: 1.0025, edge loss: 0.9994, node loss: 0.0032\n",
      "Epoch: 944, total loss: 1.0022, edge loss: 0.9994, node loss: 0.0029\n",
      "Epoch: 945, total loss: 1.0033, edge loss: 0.9989, node loss: 0.0044\n",
      "Epoch: 946, total loss: 1.0037, edge loss: 1.0007, node loss: 0.0030\n",
      "Epoch: 947, total loss: 1.0029, edge loss: 1.0004, node loss: 0.0026\n",
      "Epoch: 948, total loss: 1.0039, edge loss: 1.0001, node loss: 0.0038\n",
      "Epoch: 949, total loss: 1.0017, edge loss: 0.9989, node loss: 0.0028\n",
      "Epoch: 950, total loss: 1.0014, edge loss: 0.9991, node loss: 0.0023\n",
      "Epoch: 951, total loss: 1.0028, edge loss: 0.9996, node loss: 0.0032\n",
      "Epoch: 952, total loss: 1.0036, edge loss: 1.0009, node loss: 0.0027\n",
      "Epoch: 953, total loss: 1.0020, edge loss: 0.9992, node loss: 0.0027\n",
      "Epoch: 954, total loss: 1.0025, edge loss: 0.9996, node loss: 0.0029\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 955, total loss: 1.0033, edge loss: 1.0005, node loss: 0.0028\n",
      "Epoch: 956, total loss: 1.0035, edge loss: 1.0006, node loss: 0.0029\n",
      "Epoch: 957, total loss: 1.0036, edge loss: 1.0000, node loss: 0.0036\n",
      "Epoch: 958, total loss: 1.0033, edge loss: 1.0008, node loss: 0.0024\n",
      "Epoch: 959, total loss: 1.0031, edge loss: 1.0004, node loss: 0.0027\n",
      "Epoch: 960, total loss: 1.0044, edge loss: 1.0007, node loss: 0.0037\n",
      "Epoch: 961, total loss: 1.0030, edge loss: 0.9999, node loss: 0.0031\n",
      "Epoch: 962, total loss: 1.0022, edge loss: 0.9997, node loss: 0.0024\n",
      "Epoch: 963, total loss: 1.0024, edge loss: 0.9997, node loss: 0.0027\n",
      "Epoch: 964, total loss: 1.0024, edge loss: 0.9997, node loss: 0.0028\n",
      "Epoch: 965, total loss: 1.0023, edge loss: 0.9995, node loss: 0.0028\n",
      "Epoch: 966, total loss: 1.0022, edge loss: 0.9995, node loss: 0.0027\n",
      "Epoch: 967, total loss: 1.0035, edge loss: 1.0005, node loss: 0.0030\n",
      "Epoch: 968, total loss: 1.0023, edge loss: 0.9996, node loss: 0.0028\n",
      "Epoch: 969, total loss: 1.0035, edge loss: 1.0006, node loss: 0.0028\n",
      "Epoch: 970, total loss: 1.0025, edge loss: 0.9996, node loss: 0.0029\n",
      "Epoch: 971, total loss: 1.0029, edge loss: 0.9993, node loss: 0.0036\n",
      "Epoch: 972, total loss: 1.0020, edge loss: 0.9994, node loss: 0.0026\n",
      "Epoch: 973, total loss: 1.0033, edge loss: 0.9999, node loss: 0.0034\n",
      "Epoch: 974, total loss: 1.0033, edge loss: 1.0002, node loss: 0.0031\n",
      "Epoch: 975, total loss: 1.0035, edge loss: 1.0008, node loss: 0.0027\n",
      "Epoch: 976, total loss: 1.0025, edge loss: 0.9997, node loss: 0.0028\n",
      "Epoch: 977, total loss: 1.0022, edge loss: 0.9989, node loss: 0.0033\n",
      "Epoch: 978, total loss: 1.0027, edge loss: 1.0001, node loss: 0.0027\n",
      "Epoch: 979, total loss: 1.0024, edge loss: 0.9996, node loss: 0.0028\n",
      "Epoch: 980, total loss: 1.0031, edge loss: 1.0003, node loss: 0.0028\n",
      "Epoch: 981, total loss: 1.0023, edge loss: 0.9998, node loss: 0.0025\n",
      "Epoch: 982, total loss: 1.0022, edge loss: 0.9995, node loss: 0.0027\n",
      "Epoch: 983, total loss: 1.0034, edge loss: 1.0005, node loss: 0.0028\n",
      "Epoch: 984, total loss: 1.0026, edge loss: 0.9996, node loss: 0.0030\n",
      "Epoch: 985, total loss: 1.0026, edge loss: 1.0005, node loss: 0.0021\n",
      "Epoch: 986, total loss: 1.0021, edge loss: 0.9994, node loss: 0.0027\n",
      "Epoch: 987, total loss: 1.0023, edge loss: 0.9998, node loss: 0.0026\n",
      "Epoch: 988, total loss: 1.0031, edge loss: 1.0001, node loss: 0.0030\n",
      "Epoch: 989, total loss: 1.0015, edge loss: 0.9991, node loss: 0.0024\n",
      "Epoch: 990, total loss: 1.0039, edge loss: 1.0014, node loss: 0.0024\n",
      "Epoch: 991, total loss: 1.0028, edge loss: 0.9996, node loss: 0.0031\n",
      "Epoch: 992, total loss: 1.0038, edge loss: 1.0003, node loss: 0.0035\n",
      "Epoch: 993, total loss: 1.0035, edge loss: 1.0007, node loss: 0.0029\n",
      "Epoch: 994, total loss: 1.0030, edge loss: 1.0002, node loss: 0.0027\n",
      "Epoch: 995, total loss: 1.0033, edge loss: 0.9997, node loss: 0.0036\n",
      "Epoch: 996, total loss: 1.0034, edge loss: 1.0007, node loss: 0.0027\n",
      "Epoch: 997, total loss: 1.0031, edge loss: 1.0006, node loss: 0.0025\n",
      "Epoch: 998, total loss: 1.0031, edge loss: 1.0006, node loss: 0.0025\n",
      "Epoch: 999, total loss: 1.0029, edge loss: 0.9998, node loss: 0.0032\n",
      "Epoch: 1000, total loss: 1.0030, edge loss: 1.0002, node loss: 0.0027\n",
      "Epoch: 1001, total loss: 1.0036, edge loss: 1.0006, node loss: 0.0030\n",
      "Epoch: 1002, total loss: 1.0017, edge loss: 0.9990, node loss: 0.0028\n",
      "Epoch: 1003, total loss: 1.0024, edge loss: 0.9995, node loss: 0.0028\n",
      "Epoch: 1004, total loss: 1.0027, edge loss: 1.0004, node loss: 0.0023\n",
      "Epoch: 1005, total loss: 1.0028, edge loss: 1.0000, node loss: 0.0028\n",
      "Epoch: 1006, total loss: 1.0033, edge loss: 1.0005, node loss: 0.0028\n",
      "Epoch: 1007, total loss: 1.0032, edge loss: 1.0007, node loss: 0.0024\n",
      "Epoch: 1008, total loss: 1.0037, edge loss: 1.0003, node loss: 0.0034\n",
      "Epoch: 1009, total loss: 1.0027, edge loss: 1.0000, node loss: 0.0026\n",
      "Epoch: 1010, total loss: 1.0035, edge loss: 1.0005, node loss: 0.0030\n",
      "Epoch: 1011, total loss: 1.0041, edge loss: 1.0000, node loss: 0.0041\n",
      "Epoch: 1012, total loss: 1.0026, edge loss: 0.9997, node loss: 0.0029\n",
      "Epoch: 1013, total loss: 1.0025, edge loss: 0.9999, node loss: 0.0026\n",
      "Epoch: 1014, total loss: 1.0022, edge loss: 0.9994, node loss: 0.0028\n",
      "Epoch: 1015, total loss: 1.0024, edge loss: 0.9997, node loss: 0.0028\n",
      "Epoch: 1016, total loss: 1.0038, edge loss: 1.0000, node loss: 0.0038\n",
      "Epoch: 1017, total loss: 1.0025, edge loss: 1.0000, node loss: 0.0025\n",
      "Epoch: 1018, total loss: 1.0030, edge loss: 1.0001, node loss: 0.0029\n",
      "Epoch: 1019, total loss: 1.0023, edge loss: 0.9997, node loss: 0.0026\n",
      "Epoch: 1020, total loss: 1.0028, edge loss: 1.0002, node loss: 0.0026\n",
      "Epoch: 1021, total loss: 1.0032, edge loss: 1.0000, node loss: 0.0032\n",
      "Epoch: 1022, total loss: 1.0041, edge loss: 1.0003, node loss: 0.0039\n",
      "Epoch: 1023, total loss: 1.0016, edge loss: 0.9991, node loss: 0.0025\n",
      "Epoch: 1024, total loss: 1.0021, edge loss: 0.9996, node loss: 0.0024\n",
      "Epoch: 1025, total loss: 1.0025, edge loss: 1.0000, node loss: 0.0025\n",
      "Epoch: 1026, total loss: 1.0032, edge loss: 1.0004, node loss: 0.0028\n",
      "Epoch: 1027, total loss: 1.0023, edge loss: 0.9994, node loss: 0.0029\n",
      "Epoch: 1028, total loss: 1.0025, edge loss: 1.0001, node loss: 0.0025\n",
      "Epoch: 1029, total loss: 1.0022, edge loss: 0.9999, node loss: 0.0023\n",
      "Epoch: 1030, total loss: 1.0031, edge loss: 1.0005, node loss: 0.0026\n",
      "Epoch: 1031, total loss: 1.0025, edge loss: 0.9998, node loss: 0.0027\n",
      "Epoch: 1032, total loss: 1.0020, edge loss: 0.9995, node loss: 0.0025\n",
      "Epoch: 1033, total loss: 1.0024, edge loss: 0.9997, node loss: 0.0027\n",
      "Epoch: 1034, total loss: 1.0029, edge loss: 0.9996, node loss: 0.0033\n",
      "Epoch: 1035, total loss: 1.0024, edge loss: 0.9999, node loss: 0.0025\n",
      "Epoch: 1036, total loss: 1.0031, edge loss: 1.0001, node loss: 0.0030\n",
      "Epoch: 1037, total loss: 1.0035, edge loss: 1.0007, node loss: 0.0028\n",
      "Epoch: 1038, total loss: 1.0026, edge loss: 1.0001, node loss: 0.0025\n",
      "Epoch: 1039, total loss: 1.0030, edge loss: 1.0003, node loss: 0.0027\n",
      "Epoch: 1040, total loss: 1.0027, edge loss: 1.0001, node loss: 0.0026\n",
      "Epoch: 1041, total loss: 1.0021, edge loss: 0.9996, node loss: 0.0025\n",
      "Epoch: 1042, total loss: 1.0020, edge loss: 0.9992, node loss: 0.0028\n",
      "Epoch: 1043, total loss: 1.0029, edge loss: 1.0005, node loss: 0.0024\n",
      "Epoch: 1044, total loss: 1.0023, edge loss: 0.9994, node loss: 0.0029\n",
      "Epoch: 1045, total loss: 1.0024, edge loss: 1.0000, node loss: 0.0024\n",
      "Epoch: 1046, total loss: 1.0025, edge loss: 0.9997, node loss: 0.0028\n",
      "Epoch: 1047, total loss: 1.0029, edge loss: 0.9999, node loss: 0.0030\n",
      "Epoch: 1048, total loss: 1.0021, edge loss: 0.9997, node loss: 0.0024\n",
      "Epoch: 1049, total loss: 1.0034, edge loss: 1.0004, node loss: 0.0031\n",
      "Epoch: 1050, total loss: 1.0025, edge loss: 0.9996, node loss: 0.0029\n",
      "Epoch: 1051, total loss: 1.0025, edge loss: 0.9995, node loss: 0.0030\n",
      "Epoch: 1052, total loss: 1.0025, edge loss: 0.9994, node loss: 0.0031\n",
      "Epoch: 1053, total loss: 1.0013, edge loss: 0.9986, node loss: 0.0026\n",
      "Epoch: 1054, total loss: 1.0028, edge loss: 1.0001, node loss: 0.0027\n",
      "Epoch: 1055, total loss: 1.0024, edge loss: 0.9995, node loss: 0.0029\n",
      "Epoch: 1056, total loss: 1.0029, edge loss: 0.9999, node loss: 0.0030\n",
      "Epoch: 1057, total loss: 1.0028, edge loss: 1.0005, node loss: 0.0023\n",
      "Epoch: 1058, total loss: 1.0017, edge loss: 0.9988, node loss: 0.0028\n",
      "Epoch: 1059, total loss: 1.0035, edge loss: 1.0003, node loss: 0.0032\n",
      "Epoch: 1060, total loss: 1.0027, edge loss: 1.0003, node loss: 0.0024\n",
      "Epoch: 1061, total loss: 1.0032, edge loss: 1.0005, node loss: 0.0026\n",
      "Epoch: 1062, total loss: 1.0026, edge loss: 0.9995, node loss: 0.0031\n",
      "Epoch: 1063, total loss: 1.0040, edge loss: 1.0014, node loss: 0.0026\n",
      "Epoch: 1064, total loss: 1.0035, edge loss: 1.0006, node loss: 0.0028\n",
      "Epoch: 1065, total loss: 1.0034, edge loss: 1.0008, node loss: 0.0027\n",
      "Epoch: 1066, total loss: 1.0029, edge loss: 0.9999, node loss: 0.0030\n",
      "Epoch: 1067, total loss: 1.0030, edge loss: 1.0005, node loss: 0.0026\n",
      "Epoch: 1068, total loss: 1.0027, edge loss: 1.0002, node loss: 0.0025\n",
      "Epoch: 1069, total loss: 1.0031, edge loss: 1.0007, node loss: 0.0024\n",
      "Epoch: 1070, total loss: 1.0044, edge loss: 1.0013, node loss: 0.0031\n",
      "Epoch: 1071, total loss: 1.0034, edge loss: 1.0007, node loss: 0.0027\n",
      "Epoch: 1072, total loss: 1.0034, edge loss: 1.0004, node loss: 0.0030\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1073, total loss: 1.0022, edge loss: 0.9997, node loss: 0.0026\n",
      "Epoch: 1074, total loss: 1.0017, edge loss: 0.9992, node loss: 0.0026\n",
      "Epoch: 1075, total loss: 1.0032, edge loss: 1.0002, node loss: 0.0030\n",
      "Epoch: 1076, total loss: 1.0033, edge loss: 1.0007, node loss: 0.0026\n",
      "Epoch: 1077, total loss: 1.0018, edge loss: 0.9994, node loss: 0.0024\n",
      "Epoch: 1078, total loss: 1.0030, edge loss: 0.9994, node loss: 0.0036\n",
      "Epoch: 1079, total loss: 1.0021, edge loss: 0.9992, node loss: 0.0028\n",
      "Epoch: 1080, total loss: 1.0021, edge loss: 0.9997, node loss: 0.0024\n",
      "Epoch: 1081, total loss: 1.0022, edge loss: 0.9996, node loss: 0.0027\n",
      "Epoch: 1082, total loss: 1.0031, edge loss: 1.0001, node loss: 0.0030\n",
      "Epoch: 1083, total loss: 1.0027, edge loss: 1.0001, node loss: 0.0026\n",
      "Epoch: 1084, total loss: 1.0021, edge loss: 0.9996, node loss: 0.0025\n",
      "Epoch: 1085, total loss: 1.0034, edge loss: 1.0003, node loss: 0.0032\n",
      "Epoch: 1086, total loss: 1.0025, edge loss: 0.9992, node loss: 0.0033\n",
      "Epoch: 1087, total loss: 1.0026, edge loss: 1.0000, node loss: 0.0026\n",
      "Epoch: 1088, total loss: 1.0030, edge loss: 1.0007, node loss: 0.0024\n",
      "Epoch: 1089, total loss: 1.0031, edge loss: 1.0000, node loss: 0.0030\n",
      "Epoch: 1090, total loss: 1.0022, edge loss: 0.9998, node loss: 0.0023\n",
      "Epoch: 1091, total loss: 1.0023, edge loss: 0.9998, node loss: 0.0026\n",
      "Epoch: 1092, total loss: 1.0030, edge loss: 1.0000, node loss: 0.0030\n",
      "Epoch: 1093, total loss: 1.0028, edge loss: 1.0005, node loss: 0.0024\n",
      "Epoch: 1094, total loss: 1.0017, edge loss: 0.9993, node loss: 0.0024\n",
      "Epoch: 1095, total loss: 1.0038, edge loss: 1.0011, node loss: 0.0026\n",
      "Epoch: 1096, total loss: 1.0029, edge loss: 0.9997, node loss: 0.0032\n",
      "Epoch: 1097, total loss: 1.0022, edge loss: 0.9999, node loss: 0.0023\n",
      "Epoch: 1098, total loss: 1.0027, edge loss: 1.0004, node loss: 0.0023\n",
      "Epoch: 1099, total loss: 1.0029, edge loss: 0.9999, node loss: 0.0030\n",
      "Epoch: 1100, total loss: 1.0035, edge loss: 1.0004, node loss: 0.0030\n",
      "Epoch: 1101, total loss: 1.0022, edge loss: 0.9997, node loss: 0.0025\n",
      "Epoch: 1102, total loss: 1.0026, edge loss: 0.9995, node loss: 0.0030\n",
      "Epoch: 1103, total loss: 1.0025, edge loss: 0.9997, node loss: 0.0029\n",
      "Epoch: 1104, total loss: 1.0033, edge loss: 1.0003, node loss: 0.0030\n",
      "Epoch: 1105, total loss: 1.0028, edge loss: 1.0006, node loss: 0.0023\n",
      "Epoch: 1106, total loss: 1.0017, edge loss: 0.9988, node loss: 0.0030\n",
      "Epoch: 1107, total loss: 1.0020, edge loss: 0.9993, node loss: 0.0027\n",
      "Epoch: 1108, total loss: 1.0020, edge loss: 0.9998, node loss: 0.0022\n",
      "Epoch: 1109, total loss: 1.0023, edge loss: 0.9998, node loss: 0.0026\n",
      "Epoch: 1110, total loss: 1.0025, edge loss: 1.0001, node loss: 0.0024\n",
      "Epoch: 1111, total loss: 1.0024, edge loss: 1.0000, node loss: 0.0024\n",
      "Epoch: 1112, total loss: 1.0032, edge loss: 1.0004, node loss: 0.0028\n",
      "Epoch: 1113, total loss: 1.0024, edge loss: 1.0000, node loss: 0.0024\n",
      "Epoch: 1114, total loss: 1.0011, edge loss: 0.9986, node loss: 0.0025\n",
      "Epoch: 1115, total loss: 1.0033, edge loss: 1.0003, node loss: 0.0030\n",
      "Epoch: 1116, total loss: 1.0028, edge loss: 0.9998, node loss: 0.0029\n",
      "Epoch: 1117, total loss: 1.0016, edge loss: 0.9992, node loss: 0.0023\n",
      "Epoch: 1118, total loss: 1.0028, edge loss: 0.9996, node loss: 0.0033\n",
      "Epoch: 1119, total loss: 1.0019, edge loss: 0.9994, node loss: 0.0025\n",
      "Epoch: 1120, total loss: 1.0026, edge loss: 1.0000, node loss: 0.0027\n",
      "Epoch: 1121, total loss: 1.0020, edge loss: 0.9993, node loss: 0.0027\n",
      "Epoch: 1122, total loss: 1.0041, edge loss: 1.0008, node loss: 0.0033\n",
      "Epoch: 1123, total loss: 1.0011, edge loss: 0.9986, node loss: 0.0025\n",
      "Epoch: 1124, total loss: 1.0029, edge loss: 1.0005, node loss: 0.0023\n",
      "Epoch: 1125, total loss: 1.0024, edge loss: 0.9995, node loss: 0.0029\n",
      "Epoch: 1126, total loss: 1.0026, edge loss: 1.0004, node loss: 0.0022\n",
      "Epoch: 1127, total loss: 1.0024, edge loss: 0.9998, node loss: 0.0026\n",
      "Epoch: 1128, total loss: 1.0018, edge loss: 0.9994, node loss: 0.0024\n",
      "Epoch: 1129, total loss: 1.0011, edge loss: 0.9988, node loss: 0.0023\n",
      "Epoch: 1130, total loss: 1.0025, edge loss: 0.9997, node loss: 0.0028\n",
      "Epoch: 1131, total loss: 1.0030, edge loss: 1.0001, node loss: 0.0029\n",
      "Epoch: 1132, total loss: 1.0019, edge loss: 0.9994, node loss: 0.0025\n",
      "Epoch: 1133, total loss: 1.0011, edge loss: 0.9984, node loss: 0.0027\n",
      "Epoch: 1134, total loss: 1.0025, edge loss: 1.0003, node loss: 0.0022\n",
      "Epoch: 1135, total loss: 1.0022, edge loss: 0.9995, node loss: 0.0027\n",
      "Epoch: 1136, total loss: 1.0034, edge loss: 1.0006, node loss: 0.0027\n",
      "Epoch: 1137, total loss: 1.0029, edge loss: 1.0004, node loss: 0.0026\n",
      "Epoch: 1138, total loss: 1.0018, edge loss: 0.9993, node loss: 0.0025\n",
      "Epoch: 1139, total loss: 1.0043, edge loss: 0.9998, node loss: 0.0045\n",
      "Epoch: 1140, total loss: 1.0032, edge loss: 1.0006, node loss: 0.0027\n",
      "Epoch: 1141, total loss: 1.0024, edge loss: 1.0000, node loss: 0.0024\n",
      "Epoch: 1142, total loss: 1.0033, edge loss: 1.0008, node loss: 0.0024\n",
      "Epoch: 1143, total loss: 1.0018, edge loss: 0.9992, node loss: 0.0026\n",
      "Epoch: 1144, total loss: 1.0027, edge loss: 1.0003, node loss: 0.0024\n",
      "Epoch: 1145, total loss: 1.0018, edge loss: 0.9993, node loss: 0.0025\n",
      "Epoch: 1146, total loss: 1.0036, edge loss: 1.0002, node loss: 0.0033\n",
      "Epoch: 1147, total loss: 1.0032, edge loss: 1.0002, node loss: 0.0030\n",
      "Epoch: 1148, total loss: 1.0029, edge loss: 1.0006, node loss: 0.0023\n",
      "Epoch: 1149, total loss: 1.0035, edge loss: 1.0007, node loss: 0.0028\n",
      "Epoch: 1150, total loss: 1.0026, edge loss: 1.0003, node loss: 0.0023\n",
      "Epoch: 1151, total loss: 1.0037, edge loss: 1.0011, node loss: 0.0026\n",
      "Epoch: 1152, total loss: 1.0031, edge loss: 1.0004, node loss: 0.0027\n",
      "Epoch: 1153, total loss: 1.0035, edge loss: 1.0006, node loss: 0.0029\n",
      "Epoch: 1154, total loss: 1.0020, edge loss: 0.9995, node loss: 0.0025\n",
      "Epoch: 1155, total loss: 1.0028, edge loss: 1.0001, node loss: 0.0027\n",
      "Epoch: 1156, total loss: 1.0018, edge loss: 0.9995, node loss: 0.0023\n",
      "Epoch: 1157, total loss: 1.0019, edge loss: 0.9995, node loss: 0.0024\n",
      "Epoch: 1158, total loss: 1.0019, edge loss: 0.9997, node loss: 0.0022\n",
      "Epoch: 1159, total loss: 1.0019, edge loss: 0.9994, node loss: 0.0026\n",
      "Epoch: 1160, total loss: 1.0027, edge loss: 1.0005, node loss: 0.0022\n",
      "Epoch: 1161, total loss: 1.0018, edge loss: 0.9991, node loss: 0.0027\n",
      "Epoch: 1162, total loss: 1.0029, edge loss: 1.0002, node loss: 0.0028\n",
      "Epoch: 1163, total loss: 1.0033, edge loss: 0.9997, node loss: 0.0036\n",
      "Epoch: 1164, total loss: 1.0022, edge loss: 0.9996, node loss: 0.0026\n",
      "Epoch: 1165, total loss: 1.0038, edge loss: 1.0006, node loss: 0.0032\n",
      "Epoch: 1166, total loss: 1.0016, edge loss: 0.9991, node loss: 0.0025\n",
      "Epoch: 1167, total loss: 1.0027, edge loss: 1.0000, node loss: 0.0027\n",
      "Epoch: 1168, total loss: 1.0025, edge loss: 1.0001, node loss: 0.0024\n",
      "Epoch: 1169, total loss: 1.0036, edge loss: 0.9997, node loss: 0.0039\n",
      "Epoch: 1170, total loss: 1.0014, edge loss: 0.9991, node loss: 0.0024\n",
      "Epoch: 1171, total loss: 1.0019, edge loss: 0.9995, node loss: 0.0024\n",
      "Epoch: 1172, total loss: 1.0023, edge loss: 0.9999, node loss: 0.0024\n",
      "Epoch: 1173, total loss: 1.0026, edge loss: 1.0003, node loss: 0.0023\n",
      "Epoch: 1174, total loss: 1.0032, edge loss: 1.0004, node loss: 0.0027\n",
      "Epoch: 1175, total loss: 1.0033, edge loss: 1.0007, node loss: 0.0027\n",
      "Epoch: 1176, total loss: 1.0025, edge loss: 1.0001, node loss: 0.0024\n",
      "Epoch: 1177, total loss: 1.0015, edge loss: 0.9991, node loss: 0.0024\n",
      "Epoch: 1178, total loss: 1.0027, edge loss: 1.0005, node loss: 0.0022\n",
      "Epoch: 1179, total loss: 1.0010, edge loss: 0.9987, node loss: 0.0023\n",
      "Epoch: 1180, total loss: 1.0036, edge loss: 1.0008, node loss: 0.0028\n",
      "Epoch: 1181, total loss: 1.0031, edge loss: 1.0002, node loss: 0.0028\n",
      "Epoch: 1182, total loss: 1.0017, edge loss: 0.9993, node loss: 0.0025\n",
      "Epoch: 1183, total loss: 1.0030, edge loss: 1.0000, node loss: 0.0030\n",
      "Epoch: 1184, total loss: 1.0023, edge loss: 1.0000, node loss: 0.0023\n",
      "Epoch: 1185, total loss: 1.0019, edge loss: 0.9994, node loss: 0.0025\n",
      "Epoch: 1186, total loss: 1.0040, edge loss: 1.0016, node loss: 0.0023\n",
      "Epoch: 1187, total loss: 1.0017, edge loss: 0.9994, node loss: 0.0023\n",
      "Epoch: 1188, total loss: 1.0028, edge loss: 1.0005, node loss: 0.0022\n",
      "Epoch: 1189, total loss: 1.0025, edge loss: 1.0003, node loss: 0.0023\n",
      "Epoch: 1190, total loss: 1.0018, edge loss: 0.9994, node loss: 0.0024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1191, total loss: 1.0026, edge loss: 1.0001, node loss: 0.0025\n",
      "Epoch: 1192, total loss: 1.0015, edge loss: 0.9993, node loss: 0.0022\n",
      "Epoch: 1193, total loss: 1.0023, edge loss: 1.0002, node loss: 0.0021\n",
      "Epoch: 1194, total loss: 1.0033, edge loss: 1.0004, node loss: 0.0030\n",
      "Epoch: 1195, total loss: 1.0019, edge loss: 0.9995, node loss: 0.0024\n",
      "Epoch: 1196, total loss: 1.0034, edge loss: 1.0001, node loss: 0.0033\n",
      "Epoch: 1197, total loss: 1.0042, edge loss: 1.0013, node loss: 0.0030\n",
      "Epoch: 1198, total loss: 1.0015, edge loss: 0.9991, node loss: 0.0024\n",
      "Epoch: 1199, total loss: 1.0025, edge loss: 0.9998, node loss: 0.0026\n",
      "Epoch: 1200, total loss: 1.0025, edge loss: 1.0000, node loss: 0.0025\n",
      "Epoch: 1201, total loss: 1.0016, edge loss: 0.9994, node loss: 0.0022\n",
      "Epoch: 1202, total loss: 1.0026, edge loss: 0.9999, node loss: 0.0027\n",
      "Epoch: 1203, total loss: 1.0031, edge loss: 1.0006, node loss: 0.0025\n",
      "Epoch: 1204, total loss: 1.0033, edge loss: 1.0007, node loss: 0.0025\n",
      "Epoch: 1205, total loss: 1.0020, edge loss: 0.9993, node loss: 0.0027\n",
      "Epoch: 1206, total loss: 1.0025, edge loss: 0.9999, node loss: 0.0025\n",
      "Epoch: 1207, total loss: 1.0034, edge loss: 1.0007, node loss: 0.0027\n",
      "Epoch: 1208, total loss: 1.0027, edge loss: 1.0003, node loss: 0.0024\n",
      "Epoch: 1209, total loss: 1.0017, edge loss: 0.9994, node loss: 0.0023\n",
      "Epoch: 1210, total loss: 1.0021, edge loss: 0.9993, node loss: 0.0028\n",
      "Epoch: 1211, total loss: 1.0015, edge loss: 0.9992, node loss: 0.0023\n",
      "Epoch: 1212, total loss: 1.0024, edge loss: 0.9994, node loss: 0.0030\n",
      "Epoch: 1213, total loss: 1.0032, edge loss: 1.0006, node loss: 0.0026\n",
      "Epoch: 1214, total loss: 1.0028, edge loss: 1.0003, node loss: 0.0025\n",
      "Epoch: 1215, total loss: 1.0026, edge loss: 0.9992, node loss: 0.0034\n",
      "Epoch: 1216, total loss: 1.0043, edge loss: 1.0017, node loss: 0.0026\n",
      "Epoch: 1217, total loss: 1.0024, edge loss: 1.0002, node loss: 0.0022\n",
      "Epoch: 1218, total loss: 1.0028, edge loss: 1.0000, node loss: 0.0028\n",
      "Epoch: 1219, total loss: 1.0031, edge loss: 1.0007, node loss: 0.0023\n",
      "Epoch: 1220, total loss: 1.0007, edge loss: 0.9985, node loss: 0.0022\n",
      "Epoch: 1221, total loss: 1.0032, edge loss: 1.0002, node loss: 0.0030\n",
      "Epoch: 1222, total loss: 1.0020, edge loss: 0.9998, node loss: 0.0022\n",
      "Epoch: 1223, total loss: 1.0029, edge loss: 1.0005, node loss: 0.0023\n",
      "Epoch: 1224, total loss: 1.0019, edge loss: 0.9996, node loss: 0.0023\n",
      "Epoch: 1225, total loss: 1.0018, edge loss: 0.9992, node loss: 0.0026\n",
      "Epoch: 1226, total loss: 1.0016, edge loss: 0.9993, node loss: 0.0022\n",
      "Epoch: 1227, total loss: 1.0025, edge loss: 1.0004, node loss: 0.0022\n",
      "Epoch: 1228, total loss: 1.0018, edge loss: 0.9997, node loss: 0.0021\n",
      "Epoch: 1229, total loss: 1.0022, edge loss: 0.9998, node loss: 0.0024\n",
      "Epoch: 1230, total loss: 1.0037, edge loss: 1.0004, node loss: 0.0032\n",
      "Epoch: 1231, total loss: 1.0025, edge loss: 1.0001, node loss: 0.0024\n",
      "Epoch: 1232, total loss: 1.0015, edge loss: 0.9992, node loss: 0.0023\n",
      "Epoch: 1233, total loss: 1.0027, edge loss: 1.0002, node loss: 0.0024\n",
      "Epoch: 1234, total loss: 1.0009, edge loss: 0.9987, node loss: 0.0022\n",
      "Epoch: 1235, total loss: 1.0027, edge loss: 1.0002, node loss: 0.0026\n",
      "Epoch: 1236, total loss: 1.0027, edge loss: 1.0004, node loss: 0.0022\n",
      "Epoch: 1237, total loss: 1.0026, edge loss: 0.9998, node loss: 0.0028\n",
      "Epoch: 1238, total loss: 1.0023, edge loss: 1.0001, node loss: 0.0023\n",
      "Epoch: 1239, total loss: 1.0031, edge loss: 1.0000, node loss: 0.0031\n",
      "Epoch: 1240, total loss: 1.0025, edge loss: 1.0000, node loss: 0.0025\n",
      "Epoch: 1241, total loss: 1.0026, edge loss: 1.0000, node loss: 0.0026\n",
      "Epoch: 1242, total loss: 1.0027, edge loss: 1.0002, node loss: 0.0026\n",
      "Epoch: 1243, total loss: 1.0037, edge loss: 1.0015, node loss: 0.0022\n",
      "Epoch: 1244, total loss: 1.0014, edge loss: 0.9991, node loss: 0.0023\n",
      "Epoch: 1245, total loss: 1.0024, edge loss: 0.9999, node loss: 0.0024\n",
      "Epoch: 1246, total loss: 1.0032, edge loss: 1.0002, node loss: 0.0029\n",
      "Epoch: 1247, total loss: 1.0020, edge loss: 0.9997, node loss: 0.0023\n",
      "Epoch: 1248, total loss: 1.0019, edge loss: 0.9993, node loss: 0.0026\n",
      "Epoch: 1249, total loss: 1.0022, edge loss: 0.9999, node loss: 0.0023\n",
      "Epoch: 1250, total loss: 1.0028, edge loss: 0.9998, node loss: 0.0029\n",
      "Epoch: 1251, total loss: 1.0031, edge loss: 0.9997, node loss: 0.0034\n",
      "Epoch: 1252, total loss: 1.0024, edge loss: 0.9999, node loss: 0.0025\n",
      "Epoch: 1253, total loss: 1.0020, edge loss: 0.9999, node loss: 0.0022\n",
      "Epoch: 1254, total loss: 1.0028, edge loss: 1.0004, node loss: 0.0024\n",
      "Epoch: 1255, total loss: 1.0023, edge loss: 0.9999, node loss: 0.0024\n",
      "Epoch: 1256, total loss: 1.0026, edge loss: 1.0002, node loss: 0.0023\n",
      "Epoch: 1257, total loss: 1.0025, edge loss: 1.0002, node loss: 0.0023\n",
      "Epoch: 1258, total loss: 1.0021, edge loss: 0.9995, node loss: 0.0026\n",
      "Epoch: 1259, total loss: 1.0030, edge loss: 1.0008, node loss: 0.0021\n",
      "Epoch: 1260, total loss: 1.0027, edge loss: 1.0004, node loss: 0.0023\n",
      "Epoch: 1261, total loss: 1.0010, edge loss: 0.9983, node loss: 0.0027\n",
      "Epoch: 1262, total loss: 1.0015, edge loss: 0.9988, node loss: 0.0027\n",
      "Epoch: 1263, total loss: 1.0024, edge loss: 1.0001, node loss: 0.0023\n",
      "Epoch: 1264, total loss: 1.0025, edge loss: 1.0002, node loss: 0.0024\n",
      "Epoch: 1265, total loss: 1.0034, edge loss: 1.0002, node loss: 0.0033\n",
      "Epoch: 1266, total loss: 1.0020, edge loss: 0.9999, node loss: 0.0021\n",
      "Epoch: 1267, total loss: 1.0020, edge loss: 0.9997, node loss: 0.0023\n",
      "Epoch: 1268, total loss: 1.0012, edge loss: 0.9989, node loss: 0.0023\n",
      "Epoch: 1269, total loss: 1.0017, edge loss: 0.9995, node loss: 0.0022\n",
      "Epoch: 1270, total loss: 1.0031, edge loss: 1.0005, node loss: 0.0026\n",
      "Epoch: 1271, total loss: 1.0025, edge loss: 1.0001, node loss: 0.0024\n",
      "Epoch: 1272, total loss: 1.0027, edge loss: 1.0002, node loss: 0.0025\n",
      "Epoch: 1273, total loss: 1.0029, edge loss: 1.0004, node loss: 0.0026\n",
      "Epoch: 1274, total loss: 1.0021, edge loss: 0.9998, node loss: 0.0023\n",
      "Epoch: 1275, total loss: 1.0027, edge loss: 0.9998, node loss: 0.0029\n",
      "Epoch: 1276, total loss: 1.0026, edge loss: 1.0004, node loss: 0.0022\n",
      "Epoch: 1277, total loss: 1.0022, edge loss: 0.9998, node loss: 0.0023\n",
      "Epoch: 1278, total loss: 1.0024, edge loss: 1.0003, node loss: 0.0021\n",
      "Epoch: 1279, total loss: 1.0020, edge loss: 0.9995, node loss: 0.0025\n",
      "Epoch: 1280, total loss: 1.0015, edge loss: 0.9990, node loss: 0.0025\n",
      "Epoch: 1281, total loss: 1.0010, edge loss: 0.9989, node loss: 0.0021\n",
      "Epoch: 1282, total loss: 1.0023, edge loss: 1.0000, node loss: 0.0023\n",
      "Epoch: 1283, total loss: 1.0024, edge loss: 1.0003, node loss: 0.0021\n",
      "Epoch: 1284, total loss: 1.0015, edge loss: 0.9992, node loss: 0.0022\n",
      "Epoch: 1285, total loss: 1.0018, edge loss: 0.9995, node loss: 0.0022\n",
      "Epoch: 1286, total loss: 1.0018, edge loss: 0.9995, node loss: 0.0023\n",
      "Epoch: 1287, total loss: 1.0031, edge loss: 1.0007, node loss: 0.0024\n",
      "Epoch: 1288, total loss: 1.0026, edge loss: 1.0002, node loss: 0.0024\n",
      "Epoch: 1289, total loss: 1.0027, edge loss: 1.0003, node loss: 0.0024\n",
      "Epoch: 1290, total loss: 1.0026, edge loss: 1.0004, node loss: 0.0022\n",
      "Epoch: 1291, total loss: 1.0022, edge loss: 0.9993, node loss: 0.0029\n",
      "Epoch: 1292, total loss: 1.0019, edge loss: 0.9999, node loss: 0.0020\n",
      "Epoch: 1293, total loss: 1.0028, edge loss: 1.0005, node loss: 0.0023\n",
      "Epoch: 1294, total loss: 1.0026, edge loss: 1.0000, node loss: 0.0026\n",
      "Epoch: 1295, total loss: 1.0026, edge loss: 0.9996, node loss: 0.0030\n",
      "Epoch: 1296, total loss: 1.0023, edge loss: 1.0003, node loss: 0.0021\n",
      "Epoch: 1297, total loss: 1.0008, edge loss: 0.9986, node loss: 0.0022\n",
      "Epoch: 1298, total loss: 1.0031, edge loss: 1.0008, node loss: 0.0023\n",
      "Epoch: 1299, total loss: 1.0026, edge loss: 0.9999, node loss: 0.0026\n",
      "Epoch: 1300, total loss: 1.0027, edge loss: 1.0005, node loss: 0.0022\n",
      "Epoch: 1301, total loss: 1.0020, edge loss: 0.9997, node loss: 0.0023\n",
      "Epoch: 1302, total loss: 1.0030, edge loss: 1.0006, node loss: 0.0024\n",
      "Epoch: 1303, total loss: 1.0033, edge loss: 1.0010, node loss: 0.0023\n",
      "Epoch: 1304, total loss: 1.0023, edge loss: 1.0000, node loss: 0.0023\n",
      "Epoch: 1305, total loss: 1.0029, edge loss: 1.0003, node loss: 0.0026\n",
      "Epoch: 1306, total loss: 1.0031, edge loss: 1.0011, node loss: 0.0020\n",
      "Epoch: 1307, total loss: 1.0032, edge loss: 1.0004, node loss: 0.0028\n",
      "Epoch: 1308, total loss: 1.0028, edge loss: 1.0003, node loss: 0.0026\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1309, total loss: 1.0016, edge loss: 0.9995, node loss: 0.0022\n",
      "Epoch: 1310, total loss: 1.0026, edge loss: 1.0004, node loss: 0.0021\n",
      "Epoch: 1311, total loss: 1.0024, edge loss: 1.0004, node loss: 0.0020\n",
      "Epoch: 1312, total loss: 1.0028, edge loss: 1.0006, node loss: 0.0022\n",
      "Epoch: 1313, total loss: 1.0027, edge loss: 1.0000, node loss: 0.0027\n",
      "Epoch: 1314, total loss: 1.0017, edge loss: 0.9996, node loss: 0.0022\n",
      "Epoch: 1315, total loss: 1.0030, edge loss: 1.0011, node loss: 0.0020\n",
      "Epoch: 1316, total loss: 1.0026, edge loss: 1.0005, node loss: 0.0021\n",
      "Epoch: 1317, total loss: 1.0031, edge loss: 1.0004, node loss: 0.0027\n",
      "Epoch: 1318, total loss: 1.0023, edge loss: 1.0000, node loss: 0.0023\n",
      "Epoch: 1319, total loss: 1.0021, edge loss: 0.9999, node loss: 0.0022\n",
      "Epoch: 1320, total loss: 1.0025, edge loss: 1.0003, node loss: 0.0022\n",
      "Epoch: 1321, total loss: 1.0017, edge loss: 0.9995, node loss: 0.0023\n",
      "Epoch: 1322, total loss: 1.0031, edge loss: 1.0004, node loss: 0.0027\n",
      "Epoch: 1323, total loss: 1.0027, edge loss: 1.0006, node loss: 0.0021\n",
      "Epoch: 1324, total loss: 1.0011, edge loss: 0.9990, node loss: 0.0021\n",
      "Epoch: 1325, total loss: 1.0016, edge loss: 0.9994, node loss: 0.0022\n",
      "Epoch: 1326, total loss: 1.0024, edge loss: 0.9998, node loss: 0.0026\n",
      "Epoch: 1327, total loss: 1.0024, edge loss: 1.0004, node loss: 0.0020\n",
      "Epoch: 1328, total loss: 1.0025, edge loss: 1.0002, node loss: 0.0023\n",
      "Epoch: 1329, total loss: 1.0037, edge loss: 1.0012, node loss: 0.0025\n",
      "Epoch: 1330, total loss: 1.0024, edge loss: 1.0003, node loss: 0.0021\n",
      "Epoch: 1331, total loss: 1.0013, edge loss: 0.9989, node loss: 0.0024\n",
      "Epoch: 1332, total loss: 1.0019, edge loss: 0.9999, node loss: 0.0020\n",
      "Epoch: 1333, total loss: 1.0027, edge loss: 0.9999, node loss: 0.0028\n",
      "Epoch: 1334, total loss: 1.0033, edge loss: 1.0009, node loss: 0.0024\n",
      "Epoch: 1335, total loss: 1.0021, edge loss: 0.9996, node loss: 0.0025\n",
      "Epoch: 1336, total loss: 1.0040, edge loss: 1.0012, node loss: 0.0027\n",
      "Epoch: 1337, total loss: 1.0023, edge loss: 0.9996, node loss: 0.0027\n",
      "Epoch: 1338, total loss: 1.0026, edge loss: 0.9998, node loss: 0.0029\n",
      "Epoch: 1339, total loss: 1.0031, edge loss: 1.0008, node loss: 0.0024\n",
      "Epoch: 1340, total loss: 1.0026, edge loss: 1.0005, node loss: 0.0021\n",
      "Epoch: 1341, total loss: 1.0022, edge loss: 1.0001, node loss: 0.0021\n",
      "Epoch: 1342, total loss: 1.0018, edge loss: 0.9994, node loss: 0.0024\n",
      "Epoch: 1343, total loss: 1.0018, edge loss: 0.9998, node loss: 0.0020\n",
      "Epoch: 1344, total loss: 1.0021, edge loss: 0.9999, node loss: 0.0023\n",
      "Epoch: 1345, total loss: 1.0018, edge loss: 0.9996, node loss: 0.0022\n",
      "Epoch: 1346, total loss: 1.0020, edge loss: 0.9996, node loss: 0.0023\n",
      "Epoch: 1347, total loss: 1.0035, edge loss: 1.0007, node loss: 0.0028\n",
      "Epoch: 1348, total loss: 1.0030, edge loss: 1.0005, node loss: 0.0025\n",
      "Epoch: 1349, total loss: 1.0028, edge loss: 0.9999, node loss: 0.0029\n",
      "Epoch: 1350, total loss: 1.0030, edge loss: 1.0005, node loss: 0.0025\n",
      "Epoch: 1351, total loss: 1.0024, edge loss: 1.0002, node loss: 0.0022\n",
      "Epoch: 1352, total loss: 1.0036, edge loss: 1.0013, node loss: 0.0024\n",
      "Epoch: 1353, total loss: 1.0019, edge loss: 0.9996, node loss: 0.0023\n",
      "Epoch: 1354, total loss: 1.0014, edge loss: 0.9990, node loss: 0.0023\n",
      "Epoch: 1355, total loss: 1.0023, edge loss: 0.9998, node loss: 0.0024\n",
      "Epoch: 1356, total loss: 1.0022, edge loss: 1.0001, node loss: 0.0021\n",
      "Epoch: 1357, total loss: 1.0026, edge loss: 1.0005, node loss: 0.0022\n",
      "Epoch: 1358, total loss: 1.0025, edge loss: 1.0002, node loss: 0.0023\n",
      "Epoch: 1359, total loss: 1.0026, edge loss: 1.0001, node loss: 0.0025\n",
      "Epoch: 1360, total loss: 1.0026, edge loss: 1.0003, node loss: 0.0024\n",
      "Epoch: 1361, total loss: 1.0017, edge loss: 0.9993, node loss: 0.0024\n",
      "Epoch: 1362, total loss: 1.0034, edge loss: 1.0008, node loss: 0.0026\n",
      "Epoch: 1363, total loss: 1.0035, edge loss: 1.0009, node loss: 0.0025\n",
      "Epoch: 1364, total loss: 1.0020, edge loss: 0.9995, node loss: 0.0026\n",
      "Epoch: 1365, total loss: 1.0022, edge loss: 0.9999, node loss: 0.0023\n",
      "Epoch: 1366, total loss: 1.0023, edge loss: 0.9999, node loss: 0.0023\n",
      "Epoch: 1367, total loss: 1.0021, edge loss: 1.0000, node loss: 0.0022\n",
      "Epoch: 1368, total loss: 1.0021, edge loss: 0.9998, node loss: 0.0022\n",
      "Epoch: 1369, total loss: 1.0017, edge loss: 0.9994, node loss: 0.0023\n",
      "Epoch: 1370, total loss: 1.0026, edge loss: 0.9997, node loss: 0.0028\n",
      "Epoch: 1371, total loss: 1.0020, edge loss: 1.0000, node loss: 0.0021\n",
      "Epoch: 1372, total loss: 1.0026, edge loss: 0.9997, node loss: 0.0029\n",
      "Epoch: 1373, total loss: 1.0031, edge loss: 1.0007, node loss: 0.0024\n",
      "Epoch: 1374, total loss: 1.0016, edge loss: 0.9997, node loss: 0.0018\n",
      "Epoch: 1375, total loss: 1.0032, edge loss: 1.0004, node loss: 0.0028\n",
      "Epoch: 1376, total loss: 1.0014, edge loss: 0.9991, node loss: 0.0023\n",
      "Epoch: 1377, total loss: 1.0020, edge loss: 0.9998, node loss: 0.0022\n",
      "Epoch: 1378, total loss: 1.0025, edge loss: 1.0003, node loss: 0.0022\n",
      "Epoch: 1379, total loss: 1.0031, edge loss: 1.0006, node loss: 0.0024\n",
      "Epoch: 1380, total loss: 1.0020, edge loss: 0.9996, node loss: 0.0024\n",
      "Epoch: 1381, total loss: 1.0009, edge loss: 0.9990, node loss: 0.0019\n",
      "Epoch: 1382, total loss: 1.0037, edge loss: 1.0012, node loss: 0.0025\n",
      "Epoch: 1383, total loss: 1.0027, edge loss: 1.0001, node loss: 0.0025\n",
      "Epoch: 1384, total loss: 1.0019, edge loss: 0.9996, node loss: 0.0023\n",
      "Epoch: 1385, total loss: 1.0016, edge loss: 0.9995, node loss: 0.0021\n",
      "Epoch: 1386, total loss: 1.0032, edge loss: 1.0012, node loss: 0.0020\n",
      "Epoch: 1387, total loss: 1.0022, edge loss: 1.0002, node loss: 0.0020\n",
      "Epoch: 1388, total loss: 1.0038, edge loss: 1.0018, node loss: 0.0020\n",
      "Epoch: 1389, total loss: 1.0037, edge loss: 1.0011, node loss: 0.0026\n",
      "Epoch: 1390, total loss: 1.0030, edge loss: 1.0006, node loss: 0.0024\n",
      "Epoch: 1391, total loss: 1.0024, edge loss: 1.0002, node loss: 0.0022\n",
      "Epoch: 1392, total loss: 1.0016, edge loss: 0.9995, node loss: 0.0021\n",
      "Epoch: 1393, total loss: 1.0010, edge loss: 0.9990, node loss: 0.0020\n",
      "Epoch: 1394, total loss: 1.0021, edge loss: 0.9998, node loss: 0.0022\n",
      "Epoch: 1395, total loss: 1.0020, edge loss: 0.9999, node loss: 0.0021\n",
      "Epoch: 1396, total loss: 1.0031, edge loss: 1.0008, node loss: 0.0023\n",
      "Epoch: 1397, total loss: 1.0021, edge loss: 0.9998, node loss: 0.0023\n",
      "Epoch: 1398, total loss: 1.0018, edge loss: 0.9994, node loss: 0.0024\n",
      "Epoch: 1399, total loss: 1.0013, edge loss: 0.9993, node loss: 0.0020\n",
      "Epoch: 1400, total loss: 1.0028, edge loss: 1.0006, node loss: 0.0022\n",
      "Epoch: 1401, total loss: 1.0012, edge loss: 0.9993, node loss: 0.0020\n",
      "Epoch: 1402, total loss: 1.0029, edge loss: 1.0003, node loss: 0.0026\n",
      "Epoch: 1403, total loss: 1.0030, edge loss: 1.0005, node loss: 0.0025\n",
      "Epoch: 1404, total loss: 1.0019, edge loss: 0.9999, node loss: 0.0019\n",
      "Epoch: 1405, total loss: 1.0014, edge loss: 0.9995, node loss: 0.0019\n",
      "Epoch: 1406, total loss: 1.0016, edge loss: 0.9993, node loss: 0.0023\n",
      "Epoch: 1407, total loss: 1.0012, edge loss: 0.9993, node loss: 0.0020\n",
      "Epoch: 1408, total loss: 1.0018, edge loss: 0.9994, node loss: 0.0024\n",
      "Epoch: 1409, total loss: 1.0029, edge loss: 1.0009, node loss: 0.0020\n",
      "Epoch: 1410, total loss: 1.0027, edge loss: 1.0006, node loss: 0.0021\n",
      "Epoch: 1411, total loss: 1.0027, edge loss: 1.0007, node loss: 0.0020\n",
      "Epoch: 1412, total loss: 1.0021, edge loss: 1.0000, node loss: 0.0021\n",
      "Epoch: 1413, total loss: 1.0025, edge loss: 0.9998, node loss: 0.0027\n",
      "Epoch: 1414, total loss: 1.0032, edge loss: 1.0006, node loss: 0.0027\n",
      "Epoch: 1415, total loss: 1.0023, edge loss: 1.0002, node loss: 0.0022\n",
      "Epoch: 1416, total loss: 1.0027, edge loss: 1.0009, node loss: 0.0018\n",
      "Epoch: 1417, total loss: 1.0021, edge loss: 0.9999, node loss: 0.0022\n",
      "Epoch: 1418, total loss: 1.0028, edge loss: 1.0001, node loss: 0.0027\n",
      "Epoch: 1419, total loss: 1.0031, edge loss: 1.0010, node loss: 0.0021\n",
      "Epoch: 1420, total loss: 1.0016, edge loss: 0.9994, node loss: 0.0021\n",
      "Epoch: 1421, total loss: 1.0023, edge loss: 1.0003, node loss: 0.0020\n",
      "Epoch: 1422, total loss: 1.0015, edge loss: 0.9990, node loss: 0.0026\n",
      "Epoch: 1423, total loss: 1.0021, edge loss: 1.0000, node loss: 0.0021\n",
      "Epoch: 1424, total loss: 1.0034, edge loss: 1.0007, node loss: 0.0027\n",
      "Epoch: 1425, total loss: 1.0031, edge loss: 1.0009, node loss: 0.0022\n",
      "Epoch: 1426, total loss: 1.0022, edge loss: 1.0001, node loss: 0.0020\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1427, total loss: 1.0021, edge loss: 1.0002, node loss: 0.0019\n",
      "Epoch: 1428, total loss: 1.0021, edge loss: 0.9999, node loss: 0.0022\n",
      "Epoch: 1429, total loss: 1.0025, edge loss: 1.0002, node loss: 0.0023\n",
      "Epoch: 1430, total loss: 1.0025, edge loss: 1.0002, node loss: 0.0023\n",
      "Epoch: 1431, total loss: 1.0016, edge loss: 0.9992, node loss: 0.0024\n",
      "Epoch: 1432, total loss: 1.0023, edge loss: 0.9998, node loss: 0.0026\n",
      "Epoch: 1433, total loss: 1.0020, edge loss: 0.9999, node loss: 0.0021\n",
      "Epoch: 1434, total loss: 1.0025, edge loss: 1.0001, node loss: 0.0024\n",
      "Epoch: 1435, total loss: 1.0020, edge loss: 0.9997, node loss: 0.0023\n",
      "Epoch: 1436, total loss: 1.0019, edge loss: 0.9994, node loss: 0.0025\n",
      "Epoch: 1437, total loss: 1.0019, edge loss: 0.9995, node loss: 0.0024\n",
      "Epoch: 1438, total loss: 1.0032, edge loss: 1.0005, node loss: 0.0027\n",
      "Epoch: 1439, total loss: 1.0014, edge loss: 0.9995, node loss: 0.0019\n",
      "Epoch: 1440, total loss: 1.0025, edge loss: 1.0004, node loss: 0.0021\n",
      "Epoch: 1441, total loss: 1.0018, edge loss: 0.9997, node loss: 0.0021\n",
      "Epoch: 1442, total loss: 1.0031, edge loss: 1.0005, node loss: 0.0026\n",
      "Epoch: 1443, total loss: 1.0024, edge loss: 0.9999, node loss: 0.0025\n",
      "Epoch: 1444, total loss: 1.0023, edge loss: 1.0004, node loss: 0.0019\n",
      "Epoch: 1445, total loss: 1.0024, edge loss: 1.0002, node loss: 0.0022\n",
      "Epoch: 1446, total loss: 1.0024, edge loss: 1.0005, node loss: 0.0019\n",
      "Epoch: 1447, total loss: 1.0016, edge loss: 0.9993, node loss: 0.0022\n",
      "Epoch: 1448, total loss: 1.0028, edge loss: 1.0005, node loss: 0.0023\n",
      "Epoch: 1449, total loss: 1.0018, edge loss: 0.9995, node loss: 0.0023\n",
      "Epoch: 1450, total loss: 1.0018, edge loss: 0.9998, node loss: 0.0021\n",
      "Epoch: 1451, total loss: 1.0028, edge loss: 1.0008, node loss: 0.0020\n",
      "Epoch: 1452, total loss: 1.0013, edge loss: 0.9994, node loss: 0.0019\n",
      "Epoch: 1453, total loss: 1.0032, edge loss: 1.0010, node loss: 0.0022\n",
      "Epoch: 1454, total loss: 1.0025, edge loss: 1.0007, node loss: 0.0018\n",
      "Epoch: 1455, total loss: 1.0017, edge loss: 0.9993, node loss: 0.0024\n",
      "Epoch: 1456, total loss: 1.0019, edge loss: 0.9999, node loss: 0.0019\n",
      "Epoch: 1457, total loss: 1.0021, edge loss: 1.0000, node loss: 0.0021\n",
      "Epoch: 1458, total loss: 1.0035, edge loss: 1.0011, node loss: 0.0024\n",
      "Epoch: 1459, total loss: 1.0030, edge loss: 1.0002, node loss: 0.0028\n",
      "Epoch: 1460, total loss: 1.0016, edge loss: 0.9994, node loss: 0.0023\n",
      "Epoch: 1461, total loss: 1.0023, edge loss: 1.0002, node loss: 0.0021\n",
      "Epoch: 1462, total loss: 1.0023, edge loss: 1.0002, node loss: 0.0021\n",
      "Epoch: 1463, total loss: 1.0021, edge loss: 0.9999, node loss: 0.0022\n",
      "Epoch: 1464, total loss: 1.0019, edge loss: 0.9998, node loss: 0.0022\n",
      "Epoch: 1465, total loss: 1.0020, edge loss: 0.9998, node loss: 0.0022\n",
      "Epoch: 1466, total loss: 1.0020, edge loss: 1.0000, node loss: 0.0020\n",
      "Epoch: 1467, total loss: 1.0017, edge loss: 0.9996, node loss: 0.0022\n",
      "Epoch: 1468, total loss: 1.0031, edge loss: 1.0007, node loss: 0.0024\n",
      "Epoch: 1469, total loss: 1.0030, edge loss: 1.0007, node loss: 0.0023\n",
      "Epoch: 1470, total loss: 1.0017, edge loss: 0.9997, node loss: 0.0020\n",
      "Epoch: 1471, total loss: 1.0014, edge loss: 0.9991, node loss: 0.0023\n",
      "Epoch: 1472, total loss: 1.0017, edge loss: 0.9998, node loss: 0.0020\n",
      "Epoch: 1473, total loss: 1.0027, edge loss: 1.0003, node loss: 0.0024\n",
      "Epoch: 1474, total loss: 1.0034, edge loss: 1.0009, node loss: 0.0025\n",
      "Epoch: 1475, total loss: 1.0013, edge loss: 0.9993, node loss: 0.0020\n",
      "Epoch: 1476, total loss: 1.0026, edge loss: 1.0001, node loss: 0.0025\n",
      "Epoch: 1477, total loss: 1.0031, edge loss: 1.0008, node loss: 0.0023\n",
      "Epoch: 1478, total loss: 1.0028, edge loss: 1.0009, node loss: 0.0019\n",
      "Epoch: 1479, total loss: 1.0017, edge loss: 0.9993, node loss: 0.0023\n",
      "Epoch: 1480, total loss: 1.0018, edge loss: 0.9997, node loss: 0.0021\n",
      "Epoch: 1481, total loss: 1.0022, edge loss: 0.9998, node loss: 0.0024\n",
      "Epoch: 1482, total loss: 1.0023, edge loss: 0.9997, node loss: 0.0026\n",
      "Epoch: 1483, total loss: 1.0026, edge loss: 1.0005, node loss: 0.0022\n",
      "Epoch: 1484, total loss: 1.0027, edge loss: 1.0006, node loss: 0.0021\n",
      "Epoch: 1485, total loss: 1.0024, edge loss: 0.9995, node loss: 0.0029\n",
      "Epoch: 1486, total loss: 1.0030, edge loss: 1.0005, node loss: 0.0025\n",
      "Epoch: 1487, total loss: 1.0028, edge loss: 1.0004, node loss: 0.0024\n",
      "Epoch: 1488, total loss: 1.0008, edge loss: 0.9986, node loss: 0.0023\n",
      "Epoch: 1489, total loss: 1.0032, edge loss: 1.0008, node loss: 0.0024\n",
      "Epoch: 1490, total loss: 1.0028, edge loss: 1.0004, node loss: 0.0024\n",
      "Epoch: 1491, total loss: 1.0030, edge loss: 1.0002, node loss: 0.0027\n",
      "Epoch: 1492, total loss: 1.0024, edge loss: 1.0002, node loss: 0.0022\n",
      "Epoch: 1493, total loss: 1.0016, edge loss: 0.9996, node loss: 0.0020\n",
      "Epoch: 1494, total loss: 1.0027, edge loss: 1.0001, node loss: 0.0026\n",
      "Epoch: 1495, total loss: 1.0024, edge loss: 1.0002, node loss: 0.0022\n",
      "Epoch: 1496, total loss: 1.0015, edge loss: 0.9994, node loss: 0.0021\n",
      "Epoch: 1497, total loss: 1.0013, edge loss: 0.9993, node loss: 0.0020\n",
      "Epoch: 1498, total loss: 1.0007, edge loss: 0.9988, node loss: 0.0020\n",
      "Epoch: 1499, total loss: 1.0028, edge loss: 1.0010, node loss: 0.0018\n",
      "Epoch: 1500, total loss: 1.0022, edge loss: 1.0001, node loss: 0.0022\n",
      "Epoch: 1501, total loss: 1.0032, edge loss: 1.0009, node loss: 0.0023\n",
      "Epoch: 1502, total loss: 1.0005, edge loss: 0.9985, node loss: 0.0020\n",
      "Epoch: 1503, total loss: 1.0024, edge loss: 1.0004, node loss: 0.0020\n",
      "Epoch: 1504, total loss: 1.0018, edge loss: 0.9996, node loss: 0.0022\n",
      "Epoch: 1505, total loss: 1.0012, edge loss: 0.9992, node loss: 0.0020\n",
      "Epoch: 1506, total loss: 1.0017, edge loss: 0.9997, node loss: 0.0019\n",
      "Epoch: 1507, total loss: 1.0016, edge loss: 0.9994, node loss: 0.0022\n",
      "Epoch: 1508, total loss: 1.0016, edge loss: 0.9999, node loss: 0.0016\n",
      "Epoch: 1509, total loss: 1.0020, edge loss: 0.9999, node loss: 0.0021\n",
      "Epoch: 1510, total loss: 1.0019, edge loss: 0.9998, node loss: 0.0021\n",
      "Epoch: 1511, total loss: 1.0016, edge loss: 0.9996, node loss: 0.0021\n",
      "Epoch: 1512, total loss: 1.0033, edge loss: 1.0003, node loss: 0.0030\n",
      "Epoch: 1513, total loss: 1.0033, edge loss: 1.0007, node loss: 0.0026\n",
      "Epoch: 1514, total loss: 1.0025, edge loss: 1.0004, node loss: 0.0020\n",
      "Epoch: 1515, total loss: 1.0022, edge loss: 1.0002, node loss: 0.0020\n",
      "Epoch: 1516, total loss: 1.0028, edge loss: 1.0005, node loss: 0.0023\n",
      "Epoch: 1517, total loss: 1.0018, edge loss: 1.0000, node loss: 0.0018\n",
      "Epoch: 1518, total loss: 1.0029, edge loss: 1.0004, node loss: 0.0025\n",
      "Epoch: 1519, total loss: 1.0033, edge loss: 1.0011, node loss: 0.0022\n",
      "Epoch: 1520, total loss: 1.0020, edge loss: 0.9998, node loss: 0.0022\n",
      "Epoch: 1521, total loss: 1.0019, edge loss: 0.9998, node loss: 0.0021\n",
      "Epoch: 1522, total loss: 1.0023, edge loss: 1.0002, node loss: 0.0021\n",
      "Epoch: 1523, total loss: 1.0020, edge loss: 0.9996, node loss: 0.0024\n",
      "Epoch: 1524, total loss: 1.0025, edge loss: 1.0003, node loss: 0.0022\n",
      "Epoch: 1525, total loss: 1.0026, edge loss: 1.0004, node loss: 0.0022\n",
      "Epoch: 1526, total loss: 1.0021, edge loss: 1.0002, node loss: 0.0019\n",
      "Epoch: 1527, total loss: 1.0017, edge loss: 1.0000, node loss: 0.0017\n",
      "Epoch: 1528, total loss: 1.0010, edge loss: 0.9988, node loss: 0.0022\n",
      "Epoch: 1529, total loss: 1.0024, edge loss: 1.0004, node loss: 0.0020\n",
      "Epoch: 1530, total loss: 1.0021, edge loss: 1.0001, node loss: 0.0019\n",
      "Epoch: 1531, total loss: 1.0028, edge loss: 1.0004, node loss: 0.0023\n",
      "Epoch: 1532, total loss: 1.0029, edge loss: 1.0000, node loss: 0.0028\n",
      "Epoch: 1533, total loss: 1.0024, edge loss: 1.0003, node loss: 0.0021\n",
      "Epoch: 1534, total loss: 1.0016, edge loss: 0.9996, node loss: 0.0020\n",
      "Epoch: 1535, total loss: 1.0027, edge loss: 1.0008, node loss: 0.0019\n",
      "Epoch: 1536, total loss: 1.0022, edge loss: 1.0000, node loss: 0.0021\n",
      "Epoch: 1537, total loss: 1.0033, edge loss: 1.0000, node loss: 0.0033\n",
      "Epoch: 1538, total loss: 1.0028, edge loss: 1.0006, node loss: 0.0022\n",
      "Epoch: 1539, total loss: 1.0028, edge loss: 1.0004, node loss: 0.0024\n",
      "Epoch: 1540, total loss: 1.0019, edge loss: 0.9996, node loss: 0.0023\n",
      "Epoch: 1541, total loss: 1.0020, edge loss: 0.9997, node loss: 0.0023\n",
      "Epoch: 1542, total loss: 1.0033, edge loss: 1.0003, node loss: 0.0030\n",
      "Epoch: 1543, total loss: 1.0022, edge loss: 1.0002, node loss: 0.0021\n",
      "Epoch: 1544, total loss: 1.0039, edge loss: 1.0004, node loss: 0.0034\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1545, total loss: 1.0016, edge loss: 0.9998, node loss: 0.0018\n",
      "Epoch: 1546, total loss: 1.0024, edge loss: 0.9999, node loss: 0.0024\n",
      "Epoch: 1547, total loss: 1.0024, edge loss: 1.0003, node loss: 0.0021\n",
      "Epoch: 1548, total loss: 1.0032, edge loss: 1.0012, node loss: 0.0021\n",
      "Epoch: 1549, total loss: 1.0022, edge loss: 1.0003, node loss: 0.0019\n",
      "Epoch: 1550, total loss: 1.0024, edge loss: 1.0001, node loss: 0.0023\n",
      "Epoch: 1551, total loss: 1.0028, edge loss: 1.0004, node loss: 0.0024\n",
      "Epoch: 1552, total loss: 1.0026, edge loss: 1.0003, node loss: 0.0023\n",
      "Epoch: 1553, total loss: 1.0008, edge loss: 0.9988, node loss: 0.0020\n",
      "Epoch: 1554, total loss: 1.0026, edge loss: 1.0006, node loss: 0.0020\n",
      "Epoch: 1555, total loss: 1.0002, edge loss: 0.9983, node loss: 0.0019\n",
      "Epoch: 1556, total loss: 1.0018, edge loss: 0.9999, node loss: 0.0019\n",
      "Epoch: 1557, total loss: 1.0016, edge loss: 0.9996, node loss: 0.0020\n",
      "Epoch: 1558, total loss: 1.0022, edge loss: 1.0004, node loss: 0.0018\n",
      "Epoch: 1559, total loss: 1.0023, edge loss: 1.0002, node loss: 0.0021\n",
      "Epoch: 1560, total loss: 1.0022, edge loss: 1.0001, node loss: 0.0021\n",
      "Epoch: 1561, total loss: 1.0022, edge loss: 1.0000, node loss: 0.0022\n",
      "Epoch: 1562, total loss: 1.0015, edge loss: 0.9995, node loss: 0.0020\n",
      "Epoch: 1563, total loss: 1.0018, edge loss: 1.0001, node loss: 0.0018\n",
      "Epoch: 1564, total loss: 1.0020, edge loss: 0.9998, node loss: 0.0022\n",
      "Epoch: 1565, total loss: 1.0025, edge loss: 1.0005, node loss: 0.0020\n",
      "Epoch: 1566, total loss: 1.0013, edge loss: 0.9983, node loss: 0.0029\n",
      "Epoch: 1567, total loss: 1.0020, edge loss: 0.9998, node loss: 0.0022\n",
      "Epoch: 1568, total loss: 1.0026, edge loss: 1.0005, node loss: 0.0021\n",
      "Epoch: 1569, total loss: 1.0018, edge loss: 0.9997, node loss: 0.0021\n",
      "Epoch: 1570, total loss: 1.0019, edge loss: 1.0001, node loss: 0.0018\n",
      "Epoch: 1571, total loss: 1.0025, edge loss: 1.0007, node loss: 0.0018\n",
      "Epoch: 1572, total loss: 1.0023, edge loss: 1.0001, node loss: 0.0022\n",
      "Epoch: 1573, total loss: 1.0017, edge loss: 0.9997, node loss: 0.0020\n",
      "Epoch: 1574, total loss: 1.0031, edge loss: 1.0004, node loss: 0.0027\n",
      "Epoch: 1575, total loss: 1.0009, edge loss: 0.9991, node loss: 0.0018\n",
      "Epoch: 1576, total loss: 1.0024, edge loss: 1.0002, node loss: 0.0023\n",
      "Epoch: 1577, total loss: 1.0025, edge loss: 1.0004, node loss: 0.0021\n",
      "Epoch: 1578, total loss: 1.0026, edge loss: 1.0007, node loss: 0.0019\n",
      "Epoch: 1579, total loss: 1.0019, edge loss: 1.0001, node loss: 0.0018\n",
      "Epoch: 1580, total loss: 1.0028, edge loss: 1.0009, node loss: 0.0020\n",
      "Epoch: 1581, total loss: 1.0020, edge loss: 0.9995, node loss: 0.0025\n",
      "Epoch: 1582, total loss: 1.0028, edge loss: 0.9999, node loss: 0.0028\n",
      "Epoch: 1583, total loss: 1.0016, edge loss: 0.9998, node loss: 0.0018\n",
      "Epoch: 1584, total loss: 1.0029, edge loss: 1.0002, node loss: 0.0026\n",
      "Epoch: 1585, total loss: 1.0021, edge loss: 1.0002, node loss: 0.0019\n",
      "Epoch: 1586, total loss: 1.0026, edge loss: 1.0002, node loss: 0.0023\n",
      "Epoch: 1587, total loss: 1.0017, edge loss: 0.9996, node loss: 0.0021\n",
      "Epoch: 1588, total loss: 1.0012, edge loss: 0.9992, node loss: 0.0020\n",
      "Epoch: 1589, total loss: 1.0026, edge loss: 1.0005, node loss: 0.0022\n",
      "Epoch: 1590, total loss: 1.0016, edge loss: 0.9996, node loss: 0.0020\n",
      "Epoch: 1591, total loss: 1.0033, edge loss: 1.0010, node loss: 0.0023\n",
      "Epoch: 1592, total loss: 1.0017, edge loss: 0.9996, node loss: 0.0021\n",
      "Epoch: 1593, total loss: 1.0020, edge loss: 0.9999, node loss: 0.0020\n",
      "Epoch: 1594, total loss: 1.0024, edge loss: 1.0004, node loss: 0.0020\n",
      "Epoch: 1595, total loss: 1.0029, edge loss: 1.0001, node loss: 0.0028\n",
      "Epoch: 1596, total loss: 1.0027, edge loss: 1.0006, node loss: 0.0021\n",
      "Epoch: 1597, total loss: 1.0023, edge loss: 0.9999, node loss: 0.0024\n",
      "Epoch: 1598, total loss: 1.0021, edge loss: 0.9998, node loss: 0.0022\n",
      "Epoch: 1599, total loss: 1.0026, edge loss: 1.0008, node loss: 0.0018\n",
      "Epoch: 1600, total loss: 1.0022, edge loss: 1.0001, node loss: 0.0021\n",
      "Epoch: 1601, total loss: 1.0028, edge loss: 1.0004, node loss: 0.0024\n",
      "Epoch: 1602, total loss: 1.0029, edge loss: 1.0006, node loss: 0.0023\n",
      "Epoch: 1603, total loss: 1.0029, edge loss: 1.0009, node loss: 0.0020\n",
      "Epoch: 1604, total loss: 1.0022, edge loss: 1.0003, node loss: 0.0019\n",
      "Epoch: 1605, total loss: 1.0016, edge loss: 0.9997, node loss: 0.0019\n",
      "Epoch: 1606, total loss: 1.0023, edge loss: 1.0003, node loss: 0.0020\n",
      "Epoch: 1607, total loss: 1.0026, edge loss: 1.0005, node loss: 0.0020\n",
      "Epoch: 1608, total loss: 1.0012, edge loss: 0.9994, node loss: 0.0018\n",
      "Epoch: 1609, total loss: 1.0016, edge loss: 0.9999, node loss: 0.0018\n",
      "Epoch: 1610, total loss: 1.0018, edge loss: 0.9998, node loss: 0.0020\n",
      "Epoch: 1611, total loss: 1.0027, edge loss: 1.0009, node loss: 0.0018\n",
      "Epoch: 1612, total loss: 1.0024, edge loss: 1.0006, node loss: 0.0018\n",
      "Epoch: 1613, total loss: 1.0018, edge loss: 0.9999, node loss: 0.0019\n",
      "Epoch: 1614, total loss: 1.0020, edge loss: 0.9999, node loss: 0.0021\n",
      "Epoch: 1615, total loss: 1.0030, edge loss: 1.0008, node loss: 0.0022\n",
      "Epoch: 1616, total loss: 1.0029, edge loss: 1.0010, node loss: 0.0019\n",
      "Epoch: 1617, total loss: 1.0023, edge loss: 1.0000, node loss: 0.0023\n",
      "Epoch: 1618, total loss: 1.0025, edge loss: 0.9999, node loss: 0.0025\n",
      "Epoch: 1619, total loss: 1.0028, edge loss: 1.0008, node loss: 0.0020\n",
      "Epoch: 1620, total loss: 1.0013, edge loss: 0.9993, node loss: 0.0020\n",
      "Epoch: 1621, total loss: 1.0019, edge loss: 1.0002, node loss: 0.0017\n",
      "Epoch: 1622, total loss: 1.0015, edge loss: 0.9997, node loss: 0.0019\n",
      "Epoch: 1623, total loss: 1.0030, edge loss: 1.0001, node loss: 0.0029\n",
      "Epoch: 1624, total loss: 1.0012, edge loss: 0.9991, node loss: 0.0021\n",
      "Epoch: 1625, total loss: 1.0024, edge loss: 1.0006, node loss: 0.0018\n",
      "Epoch: 1626, total loss: 1.0017, edge loss: 0.9997, node loss: 0.0020\n",
      "Epoch: 1627, total loss: 1.0014, edge loss: 0.9988, node loss: 0.0026\n",
      "Epoch: 1628, total loss: 1.0019, edge loss: 1.0001, node loss: 0.0018\n",
      "Epoch: 1629, total loss: 1.0013, edge loss: 0.9994, node loss: 0.0018\n",
      "Epoch: 1630, total loss: 1.0027, edge loss: 1.0002, node loss: 0.0024\n",
      "Epoch: 1631, total loss: 1.0019, edge loss: 0.9998, node loss: 0.0021\n",
      "Epoch: 1632, total loss: 1.0022, edge loss: 1.0001, node loss: 0.0021\n",
      "Epoch: 1633, total loss: 1.0016, edge loss: 0.9996, node loss: 0.0020\n",
      "Epoch: 1634, total loss: 1.0024, edge loss: 1.0000, node loss: 0.0023\n",
      "Epoch: 1635, total loss: 1.0014, edge loss: 0.9992, node loss: 0.0021\n",
      "Epoch: 1636, total loss: 1.0017, edge loss: 0.9998, node loss: 0.0019\n",
      "Epoch: 1637, total loss: 1.0013, edge loss: 0.9994, node loss: 0.0018\n",
      "Epoch: 1638, total loss: 1.0018, edge loss: 1.0000, node loss: 0.0017\n",
      "Epoch: 1639, total loss: 1.0022, edge loss: 1.0004, node loss: 0.0019\n",
      "Epoch: 1640, total loss: 1.0015, edge loss: 0.9995, node loss: 0.0020\n",
      "Epoch: 1641, total loss: 1.0009, edge loss: 0.9990, node loss: 0.0018\n",
      "Epoch: 1642, total loss: 1.0028, edge loss: 1.0003, node loss: 0.0026\n",
      "Epoch: 1643, total loss: 1.0004, edge loss: 0.9987, node loss: 0.0017\n",
      "Epoch: 1644, total loss: 1.0028, edge loss: 1.0005, node loss: 0.0023\n",
      "Epoch: 1645, total loss: 1.0020, edge loss: 1.0000, node loss: 0.0020\n",
      "Epoch: 1646, total loss: 1.0020, edge loss: 1.0001, node loss: 0.0018\n",
      "Epoch: 1647, total loss: 1.0020, edge loss: 0.9999, node loss: 0.0020\n",
      "Epoch: 1648, total loss: 1.0024, edge loss: 1.0004, node loss: 0.0020\n",
      "Epoch: 1649, total loss: 1.0018, edge loss: 0.9997, node loss: 0.0020\n",
      "Epoch: 1650, total loss: 1.0032, edge loss: 1.0012, node loss: 0.0019\n",
      "Epoch: 1651, total loss: 1.0024, edge loss: 1.0005, node loss: 0.0020\n",
      "Epoch: 1652, total loss: 1.0021, edge loss: 1.0003, node loss: 0.0018\n",
      "Epoch: 1653, total loss: 1.0021, edge loss: 1.0001, node loss: 0.0020\n",
      "Epoch: 1654, total loss: 1.0022, edge loss: 0.9999, node loss: 0.0023\n",
      "Epoch: 1655, total loss: 1.0025, edge loss: 1.0006, node loss: 0.0020\n",
      "Epoch: 1656, total loss: 1.0011, edge loss: 0.9991, node loss: 0.0020\n",
      "Epoch: 1657, total loss: 1.0023, edge loss: 0.9999, node loss: 0.0024\n",
      "Epoch: 1658, total loss: 1.0022, edge loss: 1.0002, node loss: 0.0020\n",
      "Epoch: 1659, total loss: 1.0011, edge loss: 0.9992, node loss: 0.0018\n",
      "Epoch: 1660, total loss: 1.0019, edge loss: 1.0001, node loss: 0.0018\n",
      "Epoch: 1661, total loss: 1.0016, edge loss: 0.9995, node loss: 0.0021\n",
      "Epoch: 1662, total loss: 1.0022, edge loss: 1.0000, node loss: 0.0022\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1663, total loss: 1.0016, edge loss: 0.9997, node loss: 0.0019\n",
      "Epoch: 1664, total loss: 1.0011, edge loss: 0.9991, node loss: 0.0020\n",
      "Epoch: 1665, total loss: 1.0016, edge loss: 0.9995, node loss: 0.0021\n",
      "Epoch: 1666, total loss: 1.0010, edge loss: 0.9991, node loss: 0.0019\n",
      "Epoch: 1667, total loss: 1.0020, edge loss: 0.9993, node loss: 0.0026\n",
      "Epoch: 1668, total loss: 1.0014, edge loss: 0.9991, node loss: 0.0023\n",
      "Epoch: 1669, total loss: 1.0024, edge loss: 1.0005, node loss: 0.0019\n",
      "Epoch: 1670, total loss: 1.0024, edge loss: 1.0003, node loss: 0.0020\n",
      "Epoch: 1671, total loss: 1.0018, edge loss: 1.0001, node loss: 0.0018\n",
      "Epoch: 1672, total loss: 1.0018, edge loss: 0.9999, node loss: 0.0019\n",
      "Epoch: 1673, total loss: 1.0021, edge loss: 1.0001, node loss: 0.0020\n",
      "Epoch: 1674, total loss: 1.0021, edge loss: 1.0003, node loss: 0.0018\n",
      "Epoch: 1675, total loss: 1.0005, edge loss: 0.9982, node loss: 0.0024\n",
      "Epoch: 1676, total loss: 1.0014, edge loss: 0.9994, node loss: 0.0020\n",
      "Epoch: 1677, total loss: 1.0029, edge loss: 1.0013, node loss: 0.0016\n",
      "Epoch: 1678, total loss: 1.0017, edge loss: 0.9996, node loss: 0.0021\n",
      "Epoch: 1679, total loss: 1.0017, edge loss: 0.9997, node loss: 0.0019\n",
      "Epoch: 1680, total loss: 1.0032, edge loss: 1.0009, node loss: 0.0023\n",
      "Epoch: 1681, total loss: 1.0015, edge loss: 0.9998, node loss: 0.0017\n",
      "Epoch: 1682, total loss: 1.0030, edge loss: 1.0003, node loss: 0.0027\n",
      "Epoch: 1683, total loss: 1.0019, edge loss: 0.9998, node loss: 0.0021\n",
      "Epoch: 1684, total loss: 1.0022, edge loss: 0.9999, node loss: 0.0023\n",
      "Epoch: 1685, total loss: 1.0015, edge loss: 0.9997, node loss: 0.0018\n",
      "Epoch: 1686, total loss: 1.0023, edge loss: 1.0006, node loss: 0.0018\n",
      "Epoch: 1687, total loss: 1.0024, edge loss: 0.9996, node loss: 0.0028\n",
      "Epoch: 1688, total loss: 1.0030, edge loss: 1.0008, node loss: 0.0022\n",
      "Epoch: 1689, total loss: 1.0012, edge loss: 0.9991, node loss: 0.0021\n",
      "Epoch: 1690, total loss: 1.0030, edge loss: 1.0011, node loss: 0.0020\n",
      "Epoch: 1691, total loss: 1.0020, edge loss: 1.0001, node loss: 0.0019\n",
      "Epoch: 1692, total loss: 1.0021, edge loss: 1.0002, node loss: 0.0019\n",
      "Epoch: 1693, total loss: 1.0019, edge loss: 1.0002, node loss: 0.0017\n",
      "Epoch: 1694, total loss: 1.0015, edge loss: 0.9990, node loss: 0.0025\n",
      "Epoch: 1695, total loss: 1.0023, edge loss: 0.9999, node loss: 0.0024\n",
      "Epoch: 1696, total loss: 1.0022, edge loss: 1.0002, node loss: 0.0020\n",
      "Epoch: 1697, total loss: 1.0018, edge loss: 1.0000, node loss: 0.0018\n",
      "Epoch: 1698, total loss: 1.0027, edge loss: 1.0005, node loss: 0.0021\n",
      "Epoch: 1699, total loss: 1.0022, edge loss: 0.9999, node loss: 0.0024\n",
      "Epoch: 1700, total loss: 1.0018, edge loss: 0.9999, node loss: 0.0019\n",
      "Epoch: 1701, total loss: 1.0017, edge loss: 1.0001, node loss: 0.0016\n",
      "Epoch: 1702, total loss: 1.0028, edge loss: 1.0006, node loss: 0.0022\n",
      "Epoch: 1703, total loss: 1.0025, edge loss: 1.0004, node loss: 0.0021\n",
      "Epoch: 1704, total loss: 1.0029, edge loss: 1.0005, node loss: 0.0024\n",
      "Epoch: 1705, total loss: 1.0015, edge loss: 0.9995, node loss: 0.0019\n",
      "Epoch: 1706, total loss: 1.0012, edge loss: 0.9991, node loss: 0.0020\n",
      "Epoch: 1707, total loss: 1.0016, edge loss: 0.9997, node loss: 0.0019\n",
      "Epoch: 1708, total loss: 1.0034, edge loss: 1.0008, node loss: 0.0025\n",
      "Epoch: 1709, total loss: 1.0031, edge loss: 1.0013, node loss: 0.0018\n",
      "Epoch: 1710, total loss: 1.0019, edge loss: 1.0000, node loss: 0.0019\n",
      "Epoch: 1711, total loss: 1.0013, edge loss: 0.9992, node loss: 0.0021\n",
      "Epoch: 1712, total loss: 1.0015, edge loss: 0.9996, node loss: 0.0019\n",
      "Epoch: 1713, total loss: 1.0031, edge loss: 1.0008, node loss: 0.0023\n",
      "Epoch: 1714, total loss: 1.0015, edge loss: 0.9998, node loss: 0.0018\n",
      "Epoch: 1715, total loss: 1.0013, edge loss: 0.9996, node loss: 0.0018\n",
      "Epoch: 1716, total loss: 1.0016, edge loss: 0.9997, node loss: 0.0020\n",
      "Epoch: 1717, total loss: 1.0021, edge loss: 0.9999, node loss: 0.0021\n",
      "Epoch: 1718, total loss: 1.0027, edge loss: 1.0005, node loss: 0.0023\n",
      "Epoch: 1719, total loss: 1.0017, edge loss: 0.9999, node loss: 0.0018\n",
      "Epoch: 1720, total loss: 1.0015, edge loss: 0.9996, node loss: 0.0019\n",
      "Epoch: 1721, total loss: 1.0027, edge loss: 1.0007, node loss: 0.0020\n",
      "Epoch: 1722, total loss: 1.0013, edge loss: 0.9993, node loss: 0.0020\n",
      "Epoch: 1723, total loss: 1.0026, edge loss: 1.0005, node loss: 0.0020\n",
      "Epoch: 1724, total loss: 1.0009, edge loss: 0.9988, node loss: 0.0021\n",
      "Epoch: 1725, total loss: 1.0022, edge loss: 1.0005, node loss: 0.0017\n",
      "Epoch: 1726, total loss: 1.0018, edge loss: 0.9999, node loss: 0.0018\n",
      "Epoch: 1727, total loss: 1.0015, edge loss: 0.9998, node loss: 0.0017\n",
      "Epoch: 1728, total loss: 1.0032, edge loss: 1.0009, node loss: 0.0023\n",
      "Epoch: 1729, total loss: 1.0030, edge loss: 1.0010, node loss: 0.0020\n",
      "Epoch: 1730, total loss: 1.0019, edge loss: 0.9995, node loss: 0.0023\n",
      "Epoch: 1731, total loss: 1.0023, edge loss: 1.0003, node loss: 0.0020\n",
      "Epoch: 1732, total loss: 1.0026, edge loss: 1.0006, node loss: 0.0019\n",
      "Epoch: 1733, total loss: 1.0020, edge loss: 0.9995, node loss: 0.0025\n",
      "Epoch: 1734, total loss: 1.0013, edge loss: 0.9993, node loss: 0.0021\n",
      "Epoch: 1735, total loss: 1.0021, edge loss: 1.0000, node loss: 0.0021\n",
      "Epoch: 1736, total loss: 1.0021, edge loss: 0.9999, node loss: 0.0021\n",
      "Epoch: 1737, total loss: 1.0032, edge loss: 1.0011, node loss: 0.0021\n",
      "Epoch: 1738, total loss: 1.0025, edge loss: 1.0005, node loss: 0.0020\n",
      "Epoch: 1739, total loss: 1.0017, edge loss: 0.9999, node loss: 0.0018\n",
      "Epoch: 1740, total loss: 1.0020, edge loss: 1.0000, node loss: 0.0020\n",
      "Epoch: 1741, total loss: 1.0020, edge loss: 1.0001, node loss: 0.0019\n",
      "Epoch: 1742, total loss: 1.0019, edge loss: 1.0000, node loss: 0.0019\n",
      "Epoch: 1743, total loss: 1.0012, edge loss: 0.9996, node loss: 0.0016\n",
      "Epoch: 1744, total loss: 1.0027, edge loss: 1.0007, node loss: 0.0020\n",
      "Epoch: 1745, total loss: 1.0025, edge loss: 1.0003, node loss: 0.0022\n",
      "Epoch: 1746, total loss: 1.0020, edge loss: 1.0001, node loss: 0.0019\n",
      "Epoch: 1747, total loss: 1.0016, edge loss: 0.9997, node loss: 0.0018\n",
      "Epoch: 1748, total loss: 1.0014, edge loss: 0.9998, node loss: 0.0016\n",
      "Epoch: 1749, total loss: 1.0007, edge loss: 0.9990, node loss: 0.0017\n",
      "Epoch: 1750, total loss: 1.0023, edge loss: 1.0002, node loss: 0.0020\n",
      "Epoch: 1751, total loss: 1.0021, edge loss: 1.0001, node loss: 0.0020\n",
      "Epoch: 1752, total loss: 1.0025, edge loss: 1.0005, node loss: 0.0021\n",
      "Epoch: 1753, total loss: 1.0021, edge loss: 1.0001, node loss: 0.0020\n",
      "Epoch: 1754, total loss: 1.0010, edge loss: 0.9990, node loss: 0.0020\n",
      "Epoch: 1755, total loss: 1.0030, edge loss: 1.0009, node loss: 0.0021\n",
      "Epoch: 1756, total loss: 1.0018, edge loss: 1.0000, node loss: 0.0018\n",
      "Epoch: 1757, total loss: 1.0027, edge loss: 1.0004, node loss: 0.0023\n",
      "Epoch: 1758, total loss: 1.0029, edge loss: 1.0010, node loss: 0.0019\n",
      "Epoch: 1759, total loss: 1.0008, edge loss: 0.9987, node loss: 0.0020\n",
      "Epoch: 1760, total loss: 1.0019, edge loss: 1.0001, node loss: 0.0018\n",
      "Epoch: 1761, total loss: 1.0015, edge loss: 0.9990, node loss: 0.0024\n",
      "Epoch: 1762, total loss: 1.0018, edge loss: 0.9998, node loss: 0.0020\n",
      "Epoch: 1763, total loss: 1.0025, edge loss: 1.0003, node loss: 0.0022\n",
      "Epoch: 1764, total loss: 1.0018, edge loss: 0.9999, node loss: 0.0018\n",
      "Epoch: 1765, total loss: 1.0016, edge loss: 0.9998, node loss: 0.0018\n",
      "Epoch: 1766, total loss: 1.0022, edge loss: 1.0001, node loss: 0.0022\n",
      "Epoch: 1767, total loss: 1.0023, edge loss: 1.0005, node loss: 0.0018\n",
      "Epoch: 1768, total loss: 1.0020, edge loss: 1.0002, node loss: 0.0018\n",
      "Epoch: 1769, total loss: 1.0019, edge loss: 1.0000, node loss: 0.0019\n",
      "Epoch: 1770, total loss: 1.0009, edge loss: 0.9990, node loss: 0.0019\n",
      "Epoch: 1771, total loss: 1.0013, edge loss: 0.9992, node loss: 0.0021\n",
      "Epoch: 1772, total loss: 1.0019, edge loss: 0.9999, node loss: 0.0020\n",
      "Epoch: 1773, total loss: 1.0021, edge loss: 0.9998, node loss: 0.0024\n",
      "Epoch: 1774, total loss: 1.0019, edge loss: 1.0000, node loss: 0.0019\n",
      "Epoch: 1775, total loss: 1.0019, edge loss: 0.9998, node loss: 0.0021\n",
      "Epoch: 1776, total loss: 1.0018, edge loss: 0.9994, node loss: 0.0023\n",
      "Epoch: 1777, total loss: 1.0026, edge loss: 1.0003, node loss: 0.0023\n",
      "Epoch: 1778, total loss: 1.0027, edge loss: 1.0007, node loss: 0.0020\n",
      "Epoch: 1779, total loss: 1.0020, edge loss: 1.0003, node loss: 0.0017\n",
      "Epoch: 1780, total loss: 1.0027, edge loss: 1.0008, node loss: 0.0020\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1781, total loss: 1.0003, edge loss: 0.9984, node loss: 0.0019\n",
      "Epoch: 1782, total loss: 1.0016, edge loss: 0.9996, node loss: 0.0021\n",
      "Epoch: 1783, total loss: 1.0010, edge loss: 0.9995, node loss: 0.0015\n",
      "Epoch: 1784, total loss: 1.0027, edge loss: 1.0007, node loss: 0.0021\n",
      "Epoch: 1785, total loss: 1.0021, edge loss: 1.0002, node loss: 0.0019\n",
      "Epoch: 1786, total loss: 1.0019, edge loss: 0.9995, node loss: 0.0024\n",
      "Epoch: 1787, total loss: 1.0014, edge loss: 0.9996, node loss: 0.0018\n",
      "Epoch: 1788, total loss: 1.0018, edge loss: 1.0000, node loss: 0.0018\n",
      "Epoch: 1789, total loss: 1.0010, edge loss: 0.9990, node loss: 0.0019\n",
      "Epoch: 1790, total loss: 1.0021, edge loss: 1.0000, node loss: 0.0022\n",
      "Epoch: 1791, total loss: 1.0012, edge loss: 0.9995, node loss: 0.0017\n",
      "Epoch: 1792, total loss: 1.0022, edge loss: 1.0003, node loss: 0.0019\n",
      "Epoch: 1793, total loss: 1.0012, edge loss: 0.9994, node loss: 0.0018\n",
      "Epoch: 1794, total loss: 1.0025, edge loss: 1.0005, node loss: 0.0020\n",
      "Epoch: 1795, total loss: 1.0032, edge loss: 1.0012, node loss: 0.0020\n",
      "Epoch: 1796, total loss: 1.0019, edge loss: 0.9998, node loss: 0.0021\n",
      "Epoch: 1797, total loss: 1.0019, edge loss: 1.0001, node loss: 0.0018\n",
      "Epoch: 1798, total loss: 1.0025, edge loss: 1.0001, node loss: 0.0024\n",
      "Epoch: 1799, total loss: 1.0016, edge loss: 0.9996, node loss: 0.0020\n",
      "Epoch: 1800, total loss: 1.0016, edge loss: 0.9996, node loss: 0.0020\n",
      "Epoch: 1801, total loss: 1.0017, edge loss: 0.9995, node loss: 0.0022\n",
      "Epoch: 1802, total loss: 1.0014, edge loss: 0.9996, node loss: 0.0018\n",
      "Epoch: 1803, total loss: 1.0022, edge loss: 1.0000, node loss: 0.0022\n",
      "Epoch: 1804, total loss: 1.0025, edge loss: 1.0003, node loss: 0.0022\n",
      "Epoch: 1805, total loss: 1.0006, edge loss: 0.9988, node loss: 0.0019\n",
      "Epoch: 1806, total loss: 1.0024, edge loss: 1.0001, node loss: 0.0024\n",
      "Epoch: 1807, total loss: 1.0025, edge loss: 1.0003, node loss: 0.0023\n",
      "Epoch: 1808, total loss: 1.0012, edge loss: 0.9992, node loss: 0.0020\n",
      "Epoch: 1809, total loss: 1.0021, edge loss: 1.0005, node loss: 0.0017\n",
      "Epoch: 1810, total loss: 1.0013, edge loss: 0.9994, node loss: 0.0019\n",
      "Epoch: 1811, total loss: 1.0019, edge loss: 1.0000, node loss: 0.0019\n",
      "Epoch: 1812, total loss: 1.0026, edge loss: 1.0006, node loss: 0.0020\n",
      "Epoch: 1813, total loss: 1.0023, edge loss: 1.0003, node loss: 0.0020\n",
      "Epoch: 1814, total loss: 1.0015, edge loss: 0.9996, node loss: 0.0018\n",
      "Epoch: 1815, total loss: 1.0020, edge loss: 1.0003, node loss: 0.0017\n",
      "Epoch: 1816, total loss: 1.0029, edge loss: 1.0008, node loss: 0.0020\n",
      "Epoch: 1817, total loss: 1.0022, edge loss: 1.0004, node loss: 0.0018\n",
      "Epoch: 1818, total loss: 1.0021, edge loss: 1.0000, node loss: 0.0020\n",
      "Epoch: 1819, total loss: 1.0023, edge loss: 1.0006, node loss: 0.0017\n",
      "Epoch: 1820, total loss: 1.0029, edge loss: 1.0008, node loss: 0.0020\n",
      "Epoch: 1821, total loss: 1.0014, edge loss: 0.9993, node loss: 0.0021\n",
      "Epoch: 1822, total loss: 1.0013, edge loss: 0.9995, node loss: 0.0018\n",
      "Epoch: 1823, total loss: 1.0028, edge loss: 1.0005, node loss: 0.0022\n",
      "Epoch: 1824, total loss: 1.0018, edge loss: 0.9999, node loss: 0.0019\n",
      "Epoch: 1825, total loss: 1.0032, edge loss: 1.0008, node loss: 0.0024\n",
      "Epoch: 1826, total loss: 1.0022, edge loss: 1.0006, node loss: 0.0016\n",
      "Epoch: 1827, total loss: 1.0012, edge loss: 0.9994, node loss: 0.0017\n",
      "Epoch: 1828, total loss: 1.0015, edge loss: 0.9996, node loss: 0.0018\n",
      "Epoch: 1829, total loss: 1.0029, edge loss: 1.0006, node loss: 0.0023\n",
      "Epoch: 1830, total loss: 1.0019, edge loss: 1.0000, node loss: 0.0019\n",
      "Epoch: 1831, total loss: 1.0005, edge loss: 0.9986, node loss: 0.0019\n",
      "Epoch: 1832, total loss: 1.0035, edge loss: 1.0010, node loss: 0.0025\n",
      "Epoch: 1833, total loss: 1.0022, edge loss: 1.0000, node loss: 0.0022\n",
      "Epoch: 1834, total loss: 1.0010, edge loss: 0.9993, node loss: 0.0018\n",
      "Epoch: 1835, total loss: 1.0015, edge loss: 0.9996, node loss: 0.0019\n",
      "Epoch: 1836, total loss: 1.0026, edge loss: 1.0004, node loss: 0.0023\n",
      "Epoch: 1837, total loss: 1.0022, edge loss: 1.0003, node loss: 0.0019\n",
      "Epoch: 1838, total loss: 1.0028, edge loss: 1.0005, node loss: 0.0022\n",
      "Epoch: 1839, total loss: 1.0022, edge loss: 1.0002, node loss: 0.0020\n",
      "Epoch: 1840, total loss: 1.0027, edge loss: 1.0008, node loss: 0.0019\n",
      "Epoch: 1841, total loss: 1.0010, edge loss: 0.9992, node loss: 0.0018\n",
      "Epoch: 1842, total loss: 1.0019, edge loss: 1.0001, node loss: 0.0017\n",
      "Epoch: 1843, total loss: 1.0016, edge loss: 0.9998, node loss: 0.0018\n",
      "Epoch: 1844, total loss: 1.0011, edge loss: 0.9992, node loss: 0.0019\n",
      "Epoch: 1845, total loss: 1.0017, edge loss: 1.0001, node loss: 0.0017\n",
      "Epoch: 1846, total loss: 1.0012, edge loss: 0.9992, node loss: 0.0021\n",
      "Epoch: 1847, total loss: 1.0016, edge loss: 0.9999, node loss: 0.0017\n",
      "Epoch: 1848, total loss: 1.0018, edge loss: 1.0000, node loss: 0.0019\n",
      "Epoch: 1849, total loss: 1.0029, edge loss: 1.0011, node loss: 0.0018\n",
      "Epoch: 1850, total loss: 1.0020, edge loss: 1.0003, node loss: 0.0017\n",
      "Epoch: 1851, total loss: 1.0016, edge loss: 0.9994, node loss: 0.0022\n",
      "Epoch: 1852, total loss: 1.0020, edge loss: 0.9999, node loss: 0.0021\n",
      "Epoch: 1853, total loss: 1.0013, edge loss: 0.9992, node loss: 0.0021\n",
      "Epoch: 1854, total loss: 1.0021, edge loss: 1.0001, node loss: 0.0020\n",
      "Epoch: 1855, total loss: 1.0016, edge loss: 0.9993, node loss: 0.0023\n",
      "Epoch: 1856, total loss: 1.0013, edge loss: 0.9994, node loss: 0.0019\n",
      "Epoch: 1857, total loss: 1.0024, edge loss: 1.0007, node loss: 0.0016\n",
      "Epoch: 1858, total loss: 1.0021, edge loss: 1.0002, node loss: 0.0019\n",
      "Epoch: 1859, total loss: 1.0019, edge loss: 0.9999, node loss: 0.0020\n",
      "Epoch: 1860, total loss: 1.0019, edge loss: 1.0001, node loss: 0.0018\n",
      "Epoch: 1861, total loss: 1.0013, edge loss: 0.9997, node loss: 0.0016\n",
      "Epoch: 1862, total loss: 1.0017, edge loss: 1.0001, node loss: 0.0017\n",
      "Epoch: 1863, total loss: 1.0011, edge loss: 0.9993, node loss: 0.0018\n",
      "Epoch: 1864, total loss: 1.0028, edge loss: 1.0011, node loss: 0.0017\n",
      "Epoch: 1865, total loss: 1.0028, edge loss: 1.0009, node loss: 0.0019\n",
      "Epoch: 1866, total loss: 1.0014, edge loss: 0.9994, node loss: 0.0020\n",
      "Epoch: 1867, total loss: 1.0022, edge loss: 1.0004, node loss: 0.0017\n",
      "Epoch: 1868, total loss: 1.0016, edge loss: 0.9999, node loss: 0.0018\n",
      "Epoch: 1869, total loss: 1.0026, edge loss: 1.0008, node loss: 0.0018\n",
      "Epoch: 1870, total loss: 1.0031, edge loss: 1.0009, node loss: 0.0022\n",
      "Epoch: 1871, total loss: 1.0016, edge loss: 0.9999, node loss: 0.0017\n",
      "Epoch: 1872, total loss: 1.0019, edge loss: 1.0001, node loss: 0.0018\n",
      "Epoch: 1873, total loss: 1.0026, edge loss: 1.0009, node loss: 0.0018\n",
      "Epoch: 1874, total loss: 1.0017, edge loss: 0.9999, node loss: 0.0019\n",
      "Epoch: 1875, total loss: 1.0017, edge loss: 1.0001, node loss: 0.0016\n",
      "Epoch: 1876, total loss: 1.0015, edge loss: 0.9997, node loss: 0.0018\n",
      "Epoch: 1877, total loss: 1.0019, edge loss: 1.0003, node loss: 0.0017\n",
      "Epoch: 1878, total loss: 1.0009, edge loss: 0.9989, node loss: 0.0020\n",
      "Epoch: 1879, total loss: 1.0022, edge loss: 0.9999, node loss: 0.0023\n",
      "Epoch: 1880, total loss: 1.0017, edge loss: 0.9999, node loss: 0.0018\n",
      "Epoch: 1881, total loss: 1.0015, edge loss: 1.0000, node loss: 0.0015\n",
      "Epoch: 1882, total loss: 1.0020, edge loss: 1.0003, node loss: 0.0017\n",
      "Epoch: 1883, total loss: 1.0018, edge loss: 0.9996, node loss: 0.0022\n",
      "Epoch: 1884, total loss: 1.0018, edge loss: 1.0001, node loss: 0.0018\n",
      "Epoch: 1885, total loss: 1.0021, edge loss: 1.0003, node loss: 0.0019\n",
      "Epoch: 1886, total loss: 1.0028, edge loss: 1.0003, node loss: 0.0025\n",
      "Epoch: 1887, total loss: 1.0024, edge loss: 1.0007, node loss: 0.0017\n",
      "Epoch: 1888, total loss: 1.0019, edge loss: 0.9997, node loss: 0.0022\n",
      "Epoch: 1889, total loss: 1.0018, edge loss: 1.0002, node loss: 0.0016\n",
      "Epoch: 1890, total loss: 1.0018, edge loss: 0.9997, node loss: 0.0022\n",
      "Epoch: 1891, total loss: 1.0011, edge loss: 0.9988, node loss: 0.0023\n",
      "Epoch: 1892, total loss: 1.0022, edge loss: 1.0005, node loss: 0.0017\n",
      "Epoch: 1893, total loss: 1.0020, edge loss: 1.0000, node loss: 0.0019\n",
      "Epoch: 1894, total loss: 1.0015, edge loss: 1.0000, node loss: 0.0015\n",
      "Epoch: 1895, total loss: 1.0005, edge loss: 0.9988, node loss: 0.0017\n",
      "Epoch: 1896, total loss: 1.0014, edge loss: 0.9997, node loss: 0.0017\n",
      "Epoch: 1897, total loss: 1.0027, edge loss: 1.0006, node loss: 0.0021\n",
      "Epoch: 1898, total loss: 1.0013, edge loss: 0.9998, node loss: 0.0015\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1899, total loss: 1.0033, edge loss: 1.0012, node loss: 0.0021\n",
      "Epoch: 1900, total loss: 1.0014, edge loss: 0.9997, node loss: 0.0017\n",
      "Epoch: 1901, total loss: 1.0021, edge loss: 1.0004, node loss: 0.0017\n",
      "Epoch: 1902, total loss: 1.0019, edge loss: 0.9996, node loss: 0.0023\n",
      "Epoch: 1903, total loss: 1.0013, edge loss: 0.9993, node loss: 0.0020\n",
      "Epoch: 1904, total loss: 1.0024, edge loss: 1.0003, node loss: 0.0020\n",
      "Epoch: 1905, total loss: 1.0021, edge loss: 1.0003, node loss: 0.0019\n",
      "Epoch: 1906, total loss: 1.0024, edge loss: 1.0005, node loss: 0.0018\n",
      "Epoch: 1907, total loss: 1.0028, edge loss: 1.0010, node loss: 0.0018\n",
      "Epoch: 1908, total loss: 1.0022, edge loss: 1.0002, node loss: 0.0020\n",
      "Epoch: 1909, total loss: 1.0024, edge loss: 1.0004, node loss: 0.0020\n",
      "Epoch: 1910, total loss: 1.0019, edge loss: 1.0002, node loss: 0.0017\n",
      "Epoch: 1911, total loss: 1.0018, edge loss: 1.0000, node loss: 0.0017\n",
      "Epoch: 1912, total loss: 1.0024, edge loss: 1.0007, node loss: 0.0017\n",
      "Epoch: 1913, total loss: 1.0027, edge loss: 1.0009, node loss: 0.0018\n",
      "Epoch: 1914, total loss: 1.0007, edge loss: 0.9989, node loss: 0.0018\n",
      "Epoch: 1915, total loss: 1.0015, edge loss: 0.9999, node loss: 0.0016\n",
      "Epoch: 1916, total loss: 1.0013, edge loss: 0.9994, node loss: 0.0020\n",
      "Epoch: 1917, total loss: 1.0016, edge loss: 0.9997, node loss: 0.0020\n",
      "Epoch: 1918, total loss: 1.0022, edge loss: 1.0007, node loss: 0.0015\n",
      "Epoch: 1919, total loss: 1.0027, edge loss: 1.0009, node loss: 0.0017\n",
      "Epoch: 1920, total loss: 1.0021, edge loss: 1.0000, node loss: 0.0020\n",
      "Epoch: 1921, total loss: 1.0010, edge loss: 0.9993, node loss: 0.0018\n",
      "Epoch: 1922, total loss: 1.0019, edge loss: 1.0001, node loss: 0.0018\n",
      "Epoch: 1923, total loss: 1.0032, edge loss: 1.0010, node loss: 0.0022\n",
      "Epoch: 1924, total loss: 1.0013, edge loss: 0.9996, node loss: 0.0017\n",
      "Epoch: 1925, total loss: 1.0020, edge loss: 1.0001, node loss: 0.0019\n",
      "Epoch: 1926, total loss: 1.0013, edge loss: 0.9996, node loss: 0.0017\n",
      "Epoch: 1927, total loss: 1.0023, edge loss: 1.0005, node loss: 0.0019\n",
      "Epoch: 1928, total loss: 1.0021, edge loss: 1.0005, node loss: 0.0016\n",
      "Epoch: 1929, total loss: 1.0032, edge loss: 1.0014, node loss: 0.0018\n",
      "Epoch: 1930, total loss: 1.0012, edge loss: 0.9997, node loss: 0.0014\n",
      "Epoch: 1931, total loss: 1.0012, edge loss: 0.9993, node loss: 0.0019\n",
      "Epoch: 1932, total loss: 1.0023, edge loss: 1.0005, node loss: 0.0018\n",
      "Epoch: 1933, total loss: 1.0012, edge loss: 0.9988, node loss: 0.0024\n",
      "Epoch: 1934, total loss: 1.0018, edge loss: 0.9999, node loss: 0.0019\n",
      "Epoch: 1935, total loss: 1.0014, edge loss: 0.9996, node loss: 0.0018\n",
      "Epoch: 1936, total loss: 1.0011, edge loss: 0.9996, node loss: 0.0015\n",
      "Epoch: 1937, total loss: 1.0029, edge loss: 1.0012, node loss: 0.0017\n",
      "Epoch: 1938, total loss: 1.0024, edge loss: 1.0003, node loss: 0.0020\n",
      "Epoch: 1939, total loss: 1.0025, edge loss: 1.0004, node loss: 0.0021\n",
      "Epoch: 1940, total loss: 1.0011, edge loss: 0.9992, node loss: 0.0019\n",
      "Epoch: 1941, total loss: 1.0012, edge loss: 0.9997, node loss: 0.0015\n",
      "Epoch: 1942, total loss: 1.0019, edge loss: 1.0001, node loss: 0.0018\n",
      "Epoch: 1943, total loss: 1.0009, edge loss: 0.9994, node loss: 0.0016\n",
      "Epoch: 1944, total loss: 1.0016, edge loss: 0.9996, node loss: 0.0020\n",
      "Epoch: 1945, total loss: 1.0015, edge loss: 0.9994, node loss: 0.0021\n",
      "Epoch: 1946, total loss: 1.0017, edge loss: 0.9997, node loss: 0.0020\n",
      "Epoch: 1947, total loss: 1.0019, edge loss: 1.0000, node loss: 0.0019\n",
      "Epoch: 1948, total loss: 1.0010, edge loss: 0.9994, node loss: 0.0016\n",
      "Epoch: 1949, total loss: 1.0023, edge loss: 1.0006, node loss: 0.0017\n",
      "Epoch: 1950, total loss: 1.0011, edge loss: 0.9995, node loss: 0.0016\n",
      "Epoch: 1951, total loss: 1.0025, edge loss: 1.0006, node loss: 0.0019\n",
      "Epoch: 1952, total loss: 1.0008, edge loss: 0.9991, node loss: 0.0017\n",
      "Epoch: 1953, total loss: 1.0010, edge loss: 0.9991, node loss: 0.0019\n",
      "Epoch: 1954, total loss: 1.0011, edge loss: 0.9995, node loss: 0.0016\n",
      "Epoch: 1955, total loss: 1.0028, edge loss: 1.0010, node loss: 0.0018\n",
      "Epoch: 1956, total loss: 1.0007, edge loss: 0.9990, node loss: 0.0017\n",
      "Epoch: 1957, total loss: 1.0023, edge loss: 1.0004, node loss: 0.0019\n",
      "Epoch: 1958, total loss: 1.0019, edge loss: 1.0003, node loss: 0.0017\n",
      "Epoch: 1959, total loss: 1.0009, edge loss: 0.9992, node loss: 0.0017\n",
      "Epoch: 1960, total loss: 1.0010, edge loss: 0.9994, node loss: 0.0016\n",
      "Epoch: 1961, total loss: 1.0012, edge loss: 0.9993, node loss: 0.0019\n",
      "Epoch: 1962, total loss: 1.0020, edge loss: 1.0002, node loss: 0.0018\n",
      "Epoch: 1963, total loss: 1.0014, edge loss: 0.9998, node loss: 0.0016\n",
      "Epoch: 1964, total loss: 1.0011, edge loss: 0.9989, node loss: 0.0022\n",
      "Epoch: 1965, total loss: 1.0011, edge loss: 0.9995, node loss: 0.0016\n",
      "Epoch: 1966, total loss: 1.0027, edge loss: 1.0011, node loss: 0.0017\n",
      "Epoch: 1967, total loss: 1.0024, edge loss: 1.0000, node loss: 0.0024\n",
      "Epoch: 1968, total loss: 1.0021, edge loss: 1.0000, node loss: 0.0022\n",
      "Epoch: 1969, total loss: 1.0025, edge loss: 1.0006, node loss: 0.0019\n",
      "Epoch: 1970, total loss: 1.0019, edge loss: 1.0002, node loss: 0.0017\n",
      "Epoch: 1971, total loss: 1.0022, edge loss: 1.0001, node loss: 0.0021\n",
      "Epoch: 1972, total loss: 1.0013, edge loss: 0.9998, node loss: 0.0015\n",
      "Epoch: 1973, total loss: 1.0022, edge loss: 1.0004, node loss: 0.0018\n",
      "Epoch: 1974, total loss: 1.0033, edge loss: 1.0008, node loss: 0.0024\n",
      "Epoch: 1975, total loss: 1.0012, edge loss: 0.9998, node loss: 0.0014\n",
      "Epoch: 1976, total loss: 1.0023, edge loss: 1.0003, node loss: 0.0019\n",
      "Epoch: 1977, total loss: 1.0011, edge loss: 0.9993, node loss: 0.0018\n",
      "Epoch: 1978, total loss: 1.0024, edge loss: 1.0007, node loss: 0.0017\n",
      "Epoch: 1979, total loss: 1.0024, edge loss: 1.0001, node loss: 0.0023\n",
      "Epoch: 1980, total loss: 1.0028, edge loss: 1.0011, node loss: 0.0018\n",
      "Epoch: 1981, total loss: 1.0017, edge loss: 0.9997, node loss: 0.0021\n",
      "Epoch: 1982, total loss: 1.0014, edge loss: 0.9996, node loss: 0.0018\n",
      "Epoch: 1983, total loss: 1.0018, edge loss: 0.9997, node loss: 0.0020\n",
      "Epoch: 1984, total loss: 1.0016, edge loss: 1.0000, node loss: 0.0016\n",
      "Epoch: 1985, total loss: 1.0019, edge loss: 0.9994, node loss: 0.0025\n",
      "Epoch: 1986, total loss: 1.0015, edge loss: 0.9999, node loss: 0.0016\n",
      "Epoch: 1987, total loss: 1.0024, edge loss: 1.0008, node loss: 0.0015\n",
      "Epoch: 1988, total loss: 1.0019, edge loss: 1.0003, node loss: 0.0016\n",
      "Epoch: 1989, total loss: 1.0029, edge loss: 1.0010, node loss: 0.0019\n",
      "Epoch: 1990, total loss: 1.0021, edge loss: 1.0002, node loss: 0.0018\n",
      "Epoch: 1991, total loss: 1.0014, edge loss: 0.9995, node loss: 0.0019\n",
      "Epoch: 1992, total loss: 1.0022, edge loss: 1.0004, node loss: 0.0018\n",
      "Epoch: 1993, total loss: 1.0018, edge loss: 1.0003, node loss: 0.0014\n",
      "Epoch: 1994, total loss: 1.0015, edge loss: 0.9994, node loss: 0.0021\n",
      "Epoch: 1995, total loss: 1.0013, edge loss: 0.9998, node loss: 0.0015\n",
      "Epoch: 1996, total loss: 1.0019, edge loss: 0.9999, node loss: 0.0020\n",
      "Epoch: 1997, total loss: 1.0011, edge loss: 0.9995, node loss: 0.0016\n",
      "Epoch: 1998, total loss: 1.0003, edge loss: 0.9986, node loss: 0.0018\n",
      "Epoch: 1999, total loss: 1.0008, edge loss: 0.9990, node loss: 0.0017\n",
      "Epoch: 2000, total loss: 1.0016, edge loss: 0.9996, node loss: 0.0020\n",
      "Epoch: 2001, total loss: 1.0009, edge loss: 0.9991, node loss: 0.0018\n",
      "Epoch: 2002, total loss: 1.0020, edge loss: 1.0001, node loss: 0.0019\n",
      "Epoch: 2003, total loss: 1.0017, edge loss: 0.9997, node loss: 0.0019\n",
      "Epoch: 2004, total loss: 1.0011, edge loss: 0.9995, node loss: 0.0016\n",
      "Epoch: 2005, total loss: 1.0014, edge loss: 0.9992, node loss: 0.0021\n",
      "Epoch: 2006, total loss: 1.0012, edge loss: 0.9993, node loss: 0.0019\n",
      "Epoch: 2007, total loss: 1.0019, edge loss: 1.0003, node loss: 0.0017\n",
      "Epoch: 2008, total loss: 1.0022, edge loss: 1.0004, node loss: 0.0018\n",
      "Epoch: 2009, total loss: 1.0016, edge loss: 0.9999, node loss: 0.0017\n",
      "Epoch: 2010, total loss: 1.0013, edge loss: 0.9993, node loss: 0.0019\n",
      "Epoch: 2011, total loss: 1.0016, edge loss: 1.0000, node loss: 0.0016\n",
      "Epoch: 2012, total loss: 1.0023, edge loss: 1.0006, node loss: 0.0017\n",
      "Epoch: 2013, total loss: 1.0017, edge loss: 0.9998, node loss: 0.0019\n",
      "Epoch: 2014, total loss: 1.0031, edge loss: 1.0009, node loss: 0.0022\n",
      "Epoch: 2015, total loss: 1.0020, edge loss: 1.0004, node loss: 0.0016\n",
      "Epoch: 2016, total loss: 1.0026, edge loss: 1.0005, node loss: 0.0022\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2017, total loss: 1.0009, edge loss: 0.9994, node loss: 0.0015\n",
      "Epoch: 2018, total loss: 1.0014, edge loss: 0.9997, node loss: 0.0018\n",
      "Epoch: 2019, total loss: 1.0020, edge loss: 0.9999, node loss: 0.0021\n",
      "Epoch: 2020, total loss: 1.0014, edge loss: 0.9998, node loss: 0.0016\n",
      "Epoch: 2021, total loss: 1.0020, edge loss: 1.0003, node loss: 0.0017\n",
      "Epoch: 2022, total loss: 1.0020, edge loss: 1.0003, node loss: 0.0017\n",
      "Epoch: 2023, total loss: 1.0022, edge loss: 1.0006, node loss: 0.0017\n",
      "Epoch: 2024, total loss: 1.0021, edge loss: 1.0002, node loss: 0.0019\n",
      "Epoch: 2025, total loss: 1.0024, edge loss: 1.0008, node loss: 0.0016\n",
      "Epoch: 2026, total loss: 1.0026, edge loss: 1.0009, node loss: 0.0016\n",
      "Epoch: 2027, total loss: 1.0026, edge loss: 1.0008, node loss: 0.0018\n",
      "Epoch: 2028, total loss: 1.0036, edge loss: 1.0010, node loss: 0.0026\n",
      "Epoch: 2029, total loss: 1.0017, edge loss: 1.0001, node loss: 0.0015\n",
      "Epoch: 2030, total loss: 1.0018, edge loss: 1.0001, node loss: 0.0017\n",
      "Epoch: 2031, total loss: 1.0014, edge loss: 0.9997, node loss: 0.0017\n",
      "Epoch: 2032, total loss: 1.0017, edge loss: 1.0003, node loss: 0.0015\n",
      "Epoch: 2033, total loss: 1.0025, edge loss: 1.0007, node loss: 0.0019\n",
      "Epoch: 2034, total loss: 1.0028, edge loss: 1.0008, node loss: 0.0020\n",
      "Epoch: 2035, total loss: 1.0014, edge loss: 0.9995, node loss: 0.0019\n",
      "Epoch: 2036, total loss: 1.0015, edge loss: 0.9998, node loss: 0.0017\n",
      "Epoch: 2037, total loss: 1.0017, edge loss: 0.9999, node loss: 0.0018\n",
      "Epoch: 2038, total loss: 1.0019, edge loss: 1.0004, node loss: 0.0015\n",
      "Epoch: 2039, total loss: 1.0018, edge loss: 1.0002, node loss: 0.0016\n",
      "Epoch: 2040, total loss: 1.0019, edge loss: 1.0001, node loss: 0.0018\n",
      "Epoch: 2041, total loss: 1.0014, edge loss: 0.9997, node loss: 0.0017\n",
      "Epoch: 2042, total loss: 1.0028, edge loss: 1.0008, node loss: 0.0019\n",
      "Epoch: 2043, total loss: 1.0011, edge loss: 0.9991, node loss: 0.0019\n",
      "Epoch: 2044, total loss: 1.0026, edge loss: 1.0007, node loss: 0.0018\n",
      "Epoch: 2045, total loss: 1.0018, edge loss: 1.0001, node loss: 0.0017\n",
      "Epoch: 2046, total loss: 1.0012, edge loss: 0.9994, node loss: 0.0018\n",
      "Epoch: 2047, total loss: 1.0031, edge loss: 1.0012, node loss: 0.0019\n",
      "Epoch: 2048, total loss: 1.0015, edge loss: 0.9997, node loss: 0.0018\n",
      "Epoch: 2049, total loss: 1.0012, edge loss: 0.9997, node loss: 0.0015\n",
      "Epoch: 2050, total loss: 1.0017, edge loss: 0.9999, node loss: 0.0018\n",
      "Epoch: 2051, total loss: 1.0011, edge loss: 0.9994, node loss: 0.0017\n",
      "Epoch: 2052, total loss: 1.0013, edge loss: 0.9991, node loss: 0.0023\n",
      "Epoch: 2053, total loss: 1.0010, edge loss: 0.9992, node loss: 0.0018\n",
      "Epoch: 2054, total loss: 1.0008, edge loss: 0.9990, node loss: 0.0017\n",
      "Epoch: 2055, total loss: 1.0024, edge loss: 1.0005, node loss: 0.0020\n",
      "Epoch: 2056, total loss: 1.0010, edge loss: 0.9990, node loss: 0.0020\n",
      "Epoch: 2057, total loss: 1.0015, edge loss: 1.0000, node loss: 0.0015\n",
      "Epoch: 2058, total loss: 1.0013, edge loss: 0.9997, node loss: 0.0016\n",
      "Epoch: 2059, total loss: 1.0020, edge loss: 1.0003, node loss: 0.0017\n",
      "Epoch: 2060, total loss: 1.0019, edge loss: 1.0004, node loss: 0.0016\n",
      "Epoch: 2061, total loss: 1.0011, edge loss: 0.9990, node loss: 0.0021\n",
      "Epoch: 2062, total loss: 1.0008, edge loss: 0.9991, node loss: 0.0017\n",
      "Epoch: 2063, total loss: 1.0021, edge loss: 1.0005, node loss: 0.0016\n",
      "Epoch: 2064, total loss: 1.0024, edge loss: 1.0002, node loss: 0.0021\n",
      "Epoch: 2065, total loss: 1.0022, edge loss: 1.0005, node loss: 0.0016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Loss factor for normalization\n",
    "loss_factor = len(train_dataset) * n_t_steps\n",
    "\n",
    "# Initialize the optimizers\n",
    "node_optimizer = torch.optim.Adam(node_model.parameters(), lr=learning_rate)\n",
    "edge_optimizer = torch.optim.Adam(edge_model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Training loop\n",
    "total_losses = []\n",
    "edge_losses  = []\n",
    "node_losses  = []\n",
    "for epoch in range(n_epochs):\n",
    "    # Initialize train loss variable\n",
    "    total_loss_cum = 0\n",
    "    edge_loss_cum  = 0\n",
    "    node_loss_cum  = 0\n",
    "    for graph in train_dataset:\n",
    "        #print()\n",
    "        # Clone existing graph\n",
    "        graph_0 = graph.clone()\n",
    "        \n",
    "        # Initialize the gradient of the optimizers\n",
    "        node_optimizer.zero_grad()\n",
    "        edge_optimizer.zero_grad()\n",
    "        \n",
    "        # Start denoising-diffusing process\n",
    "        for t_step in np.arange(1, n_t_steps+1):\n",
    "            # Diffuse the graph with some noise\n",
    "            #print()\n",
    "            #print(f'Step: {t_step}')\n",
    "            #print('Diffusing...')\n",
    "            \n",
    "            graph_t, epsilon_t = diffusion_step(graph_0, t_step, n_t_steps, alpha_decay)\n",
    "            \n",
    "            # Update diffused graph as next one\n",
    "            graph_0 = graph_t.clone()\n",
    "\n",
    "            # Denoise the diffused graph\n",
    "            #print(f'Denoising...')\n",
    "            \n",
    "            # Add t_step information to graph_t\n",
    "            t_step_std = (t_step/n_t_steps - 0.5)  # Standard normalization\n",
    "            graph_t = add_features_to_graph(graph_t,\n",
    "                                            torch.tensor([[t_step_std]], dtype=torch.float))  # To match graph.y shape\n",
    "            \n",
    "            # Add target information\n",
    "            #graph_t = add_features_to_graph(graph_t,\n",
    "            #                                    graph_t.y)\n",
    "\n",
    "            # Perform a single forward pass for predicting node features\n",
    "            out_x = node_model(graph_t.x,\n",
    "                               graph_t.edge_index,\n",
    "                               graph_t.edge_attr)\n",
    "            \n",
    "            # Remove t_step information\n",
    "            out_x = out_x[:, :-1]\n",
    "\n",
    "            # Define x_i and x_j as features of every corresponding pair of nodes (same order than attributes)\n",
    "            x_i = graph_t.x[graph_t.edge_index[0]]\n",
    "            x_j = graph_t.x[graph_t.edge_index[1]]\n",
    "\n",
    "            # Perform a single forward pass for predicting edge attributes\n",
    "            # Introduce previous edge attributes as features as well\n",
    "            out_attr = edge_model(x_i, x_j, graph_t.edge_attr)\n",
    "\n",
    "            # Construct noise graph\n",
    "            pred_epsilon_t = Data(x=out_x,\n",
    "                                  edge_index=graph_t.edge_index,\n",
    "                                  edge_attr=out_attr.ravel())\n",
    "            \n",
    "            # Backpropagation and optimization step\n",
    "            #print('Backpropagating...')\n",
    "\n",
    "            # Calculate the loss for node features and edge attributes\n",
    "            node_loss, edge_loss = get_graph_losses(epsilon_t, pred_epsilon_t)\n",
    "            \n",
    "            # Backpropagate and optimize node loss\n",
    "            node_loss.backward(retain_graph=True)\n",
    "            node_optimizer.step()\n",
    "\n",
    "            # Backpropagate and optimize edge loss\n",
    "            edge_loss.backward(retain_graph=True)\n",
    "            edge_optimizer.step()\n",
    "\n",
    "            # Accumulate the total training loss\n",
    "            loss = node_loss + edge_loss\n",
    "            \n",
    "            # Get items\n",
    "            total_loss_cum += loss.item()\n",
    "            edge_loss_cum  += edge_loss.item()\n",
    "            node_loss_cum  += node_loss.item()\n",
    "    \n",
    "    # Compute the average train loss\n",
    "    total_loss_cum = total_loss_cum / loss_factor\n",
    "    edge_loss_cum  = edge_loss_cum  / loss_factor\n",
    "    node_loss_cum  = node_loss_cum  / loss_factor\n",
    "    \n",
    "    # Append average losses\n",
    "    total_losses.append(total_loss_cum)\n",
    "    edge_losses.append(edge_loss_cum)\n",
    "    node_losses.append(node_loss_cum)\n",
    "    \n",
    "    print(f'Epoch: {epoch+1}, total loss: {total_loss_cum:.4f}, edge loss: {edge_loss_cum:.4f}, node loss: {node_loss_cum:.4f}')\n",
    "    \n",
    "    # Save some checkpoints\n",
    "    if (epoch % 20) == 0:\n",
    "        torch.save(node_model.state_dict(), node_model_name)\n",
    "        torch.save(edge_model.state_dict(), edge_model_name)\n",
    "\n",
    "torch.save(node_model.state_dict(), node_model_name)\n",
    "torch.save(edge_model.state_dict(), edge_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aeeffa13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(np.log(total_losses), label='Total')\n",
    "plt.plot(np.log(edge_losses),  label='Edge')\n",
    "plt.plot(np.log(node_losses),  label='Node')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss function')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
