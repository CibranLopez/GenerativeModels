{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a69f99f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T15:51:38.296768Z",
     "start_time": "2024-05-02T15:51:28.138874Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from scipy.optimize       import minimize\n",
    "from libraries.graph      import graph_POSCAR_encoding, find_closest_key, composition_concentration_from_keys\n",
    "from torch_geometric.data import Data\n",
    "from pymatgen.core        import Structure"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "d156edb5",
   "metadata": {},
   "source": [
    "# Graph embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f2fc7cd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T15:51:40.558178Z",
     "start_time": "2024-05-02T15:51:37.668900Z"
    }
   },
   "source": [
    "distance_threshold = 5\n",
    "y = 1\n",
    "\n",
    "# Whether to care about lattice vectors or not\n",
    "is_molecule = False\n",
    "\n",
    "structure = Structure.from_file('POSCAR')\n",
    "\n",
    "nodes, edges, attributes = graph_POSCAR_encoding(structure,\n",
    "                                                 distance_threshold=distance_threshold,\n",
    "                                                 encoding_type='sphere-images')\n",
    "temp = Data(x=nodes,\n",
    "            edge_index=edges.t().contiguous(),\n",
    "            edge_attr=attributes.flatten(),\n",
    "            y=torch.tensor([y], dtype=torch.float)\n",
    "           )\n",
    "temp"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "edges   = temp.edge_index.detach().cpu().numpy().T\n",
    "weights = temp.edge_attr.detach().cpu().numpy()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-02T15:51:40.560098Z",
     "start_time": "2024-05-02T15:51:40.548242Z"
    }
   },
   "id": "e49688f2c39766b9",
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "coordinates = []\n",
    "for s in structure:\n",
    "    coordinates.append(s.coords)\n",
    "coordinates = np.array(coordinates)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-02T15:51:40.613036Z",
     "start_time": "2024-05-02T15:51:40.561685Z"
    }
   },
   "id": "2a035a31d1d1d3f3",
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "lattice_vectors = structure.lattice.matrix\n",
    "lattice_vectors"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-02T15:51:40.614857Z",
     "start_time": "2024-05-02T15:51:40.577611Z"
    }
   },
   "id": "d4dab8fa539eb9e3",
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Molecules"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a906225b24c6eb4e"
  },
  {
   "cell_type": "code",
   "source": [
    "if is_molecule:\n",
    "    # Initial guess for the positions\n",
    "    solution = np.random.rand(len(nodes) * 3)*10  # Initialize all points at origin, 1D array\n",
    "    #solution = coordinates.reshape(-1, 1).ravel()\n",
    "    \n",
    "    # Function to calculate the squared difference between distances and weights\n",
    "    def objective(solution_attempt, edges, weights):\n",
    "        positions = solution_attempt.reshape(-1, 3)  # Reshape to 2D array\n",
    "        errors = 0\n",
    "        for edge, weight in zip(edges, weights):\n",
    "            p1 = positions[edge[0]]\n",
    "            p2 = positions[edge[1]]\n",
    "            distance = np.linalg.norm(p2 - p1)\n",
    "            errors += np.power(distance - weight, 2)\n",
    "        print(errors)\n",
    "        return errors\n",
    "    \n",
    "    def worst_identification(edges, attributes, solution_attempt):\n",
    "        positions = solution_attempt.reshape(-1, 3)  # Reshape to 2D array\n",
    "    \n",
    "        particle_errors = []\n",
    "        for particle in np.unique(edges):\n",
    "            # Get those edge indexes where particle has a connection\n",
    "            particle_connections = np.where((edges[:, 0] == particle) | (edges[:, 1] == particle))\n",
    "    \n",
    "            particle_error = 0\n",
    "            for idx in particle_connections[0]:\n",
    "                # Load indexes in edge\n",
    "                edge = edges[idx]\n",
    "    \n",
    "                # Load expected attribute\n",
    "                p1 = positions[edge[0]]\n",
    "                p2 = positions[edge[1]]\n",
    "    \n",
    "                # Load reference attribute\n",
    "                weight = attributes[idx].item()\n",
    "                \n",
    "                # Compute error\n",
    "                distance = np.linalg.norm(p2 - p1)\n",
    "\n",
    "                # Append to trial errors for different atom images\n",
    "                trial_error = np.power(distance - weight, 2)\n",
    "    \n",
    "                # Add error\n",
    "                particle_error += trial_error\n",
    "    \n",
    "            # Average over the connection of the node\n",
    "            particle_error /= len(particle_connections[0])\n",
    "    \n",
    "            # Append particle error\n",
    "            particle_errors.append(particle_error)\n",
    "    \n",
    "        return np.argmax(particle_errors), np.max(particle_errors)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-02T15:51:40.663831Z",
     "start_time": "2024-05-02T15:51:40.600725Z"
    }
   },
   "id": "7ac6366d254a886d",
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Crystals"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a28dee7919724586"
  },
  {
   "cell_type": "code",
   "source": [
    "if not is_molecule:\n",
    "    # Initial guess for the lattice parameters\n",
    "    lattice_vectors = np.array([[10, 0,   0],\n",
    "                                [0,   10, 0],\n",
    "                                [0,   0,   10]])\n",
    "    \n",
    "    # Initial guess for the positions\n",
    "    initial_positions = np.random.rand(len(nodes) * 3)  # Initialize all points at origin, 1D array\n",
    "    #initial_positions = coordinates.reshape(-1, 1).ravel()\n",
    "    solution = np.concatenate([lattice_vectors.ravel(), initial_positions])\n",
    "    \n",
    "    # Function to calculate the squared difference between distances and weights\n",
    "    def objective(solution_attempt, edges, weights):\n",
    "        solution_attempt = solution_attempt.reshape(-1, 3)  # Reshape to 2D array\n",
    "        \n",
    "        lattice_vectors = solution_attempt[:3]\n",
    "        positions       = solution_attempt[3:]\n",
    "        \n",
    "        errors = 0\n",
    "        for edge, weight in zip(edges, weights):\n",
    "            p1 = positions[edge[0]]\n",
    "            p2 = positions[edge[1]]\n",
    "            \n",
    "            trial_errors = [] \n",
    "            for i in [-1, 0, 1]:\n",
    "                for j in [-1, 0, 1]:\n",
    "                    for k in [-1, 0, 1]:\n",
    "                        # i*lattice_vectors[0] + j*lattice_vectors[1] + k*lattice_vectors[2]\n",
    "                        ijk_lattice_vectors = np.sum([i, j, k] * lattice_vectors.T, axis=1)\n",
    "\n",
    "                        # Compute error\n",
    "                        distance = np.linalg.norm(p2 - p1 + ijk_lattice_vectors)\n",
    "\n",
    "                        # Append to trial errors for differente atom images\n",
    "                        trial_errors.append(np.power(distance - weight, 2))\n",
    "            errors += np.min(trial_errors)\n",
    "        #print(errors)\n",
    "        return errors\n",
    "    \n",
    "    def worst_identification(edges, attributes, solution_attempt):\n",
    "        solution_attempt = solution_attempt.reshape(-1, 3)  # Reshape to 2D array\n",
    "    \n",
    "        lattice_vectors = solution_attempt[:3]\n",
    "        positions       = solution_attempt[3:]\n",
    "    \n",
    "        particle_errors = []\n",
    "        for particle in np.unique(edges):\n",
    "            # Get those edge indexes where particle has a connection\n",
    "            particle_connections = np.where((edges[:, 0] == particle) | (edges[:, 1] == particle))\n",
    "    \n",
    "            particle_error = 0\n",
    "            for idx in particle_connections[0]:\n",
    "                # Load indexes in edge\n",
    "                edge = edges[idx]\n",
    "    \n",
    "                # Load expected attribute\n",
    "                p1 = positions[edge[0]]\n",
    "                p2 = positions[edge[1]]\n",
    "    \n",
    "                # Load reference attribute\n",
    "                weight = attributes[idx].item()\n",
    "    \n",
    "                trial_errors = []\n",
    "                for i in [-1, 0, 1]:\n",
    "                    for j in [-1, 0, 1]:\n",
    "                        for k in [-1, 0, 1]:\n",
    "                            # i*lattice_vectors[0] + j*lattice_vectors[1] + k*lattice_vectors[2]\n",
    "                            ijk_lattice_vectors = np.sum([i, j, k] * lattice_vectors.T, axis=1)\n",
    "    \n",
    "                            # Compute error\n",
    "                            distance = np.linalg.norm(p2 - p1 + ijk_lattice_vectors)\n",
    "    \n",
    "                            # Append to trial errors for different atom images\n",
    "                            trial_errors.append(np.power(distance - weight, 2))\n",
    "    \n",
    "                # Add error\n",
    "                particle_error += np.min(trial_errors)\n",
    "    \n",
    "            # Average over the connection of the node\n",
    "            particle_error /= len(particle_connections[0])\n",
    "    \n",
    "            # Append particle error\n",
    "            particle_errors.append(particle_error)\n",
    "    \n",
    "        return np.argmax(particle_errors), np.max(particle_errors)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-02T15:51:40.689620Z",
     "start_time": "2024-05-02T15:51:40.624873Z"
    }
   },
   "id": "a51f63950dfb581c",
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "error_threshold = 1e-5\n",
    "\n",
    "for attempt in range(100):\n",
    "    print()\n",
    "    print(f'Attempt {attempt}')\n",
    "    solution = minimize(objective, solution,\n",
    "                        args=(edges, weights),\n",
    "                        method='Powell')\n",
    "\n",
    "    is_success       = solution.success\n",
    "    solution_message = solution.message\n",
    "    worst_particle, worst_error = worst_identification(edges, attributes, solution.x)\n",
    "\n",
    "    attempt_error = objective(solution.x, edges, weights)\n",
    "    print(f'Total: {attempt_error} and local {worst_error} errors')\n",
    "\n",
    "    if attempt_error < error_threshold:\n",
    "        break\n",
    "\n",
    "    solution = solution.x.reshape(-1, 3)  # Reshape to 2D array\n",
    "\n",
    "    # Re-initialize that position\n",
    "    solution[worst_particle+3] = np.random.rand(3)\n",
    "\n",
    "    solution = solution.flatten()\n",
    "\n",
    "# Check convergence status\n",
    "if is_success:\n",
    "    print('Converged to a solution.')\n",
    "else:\n",
    "    print(f'Failed to converge: {solution_message}')"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2024-05-02T15:51:40.640764Z"
    }
   },
   "id": "4879fac7d2e4c31c",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "solution = solution.reshape(-1, 3)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e37b1c311249541",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Molecules"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "92e33b11e6a4d314"
  },
  {
   "cell_type": "code",
   "source": [
    "if is_molecule:\n",
    "    # Get the position of each atom in direct coordinates\n",
    "    #direct_positions = graph_to_cartesian_positions(graph)\n",
    "    #cartesian_positions = solution.x.reshape(-1, 3)*mw\n",
    "    #cartesian_positions = solution.x.reshape(-1, 3)\n",
    "    \n",
    "    lattice_vectors     = np.array([[10, 0,   0],\n",
    "                                    [0,   10, 0],\n",
    "                                    [0,   0,   10]])\n",
    "    cartesian_positions = solution"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cb602d6450f4a4bf",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Crystals"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4c0dbd7e78d13ddf"
  },
  {
   "cell_type": "code",
   "source": [
    "if not is_molecule:\n",
    "    # Get the position of each atom in direct coordinates\n",
    "    #direct_positions = graph_to_cartesian_positions(graph)\n",
    "    #cartesian_positions = solution.x.reshape(-1, 3)*mw\n",
    "    \n",
    "    lattice_vectors     = solution[:3]\n",
    "    cartesian_positions = solution[3:]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "710d6d50e5053578",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5f779bd46fd1c88b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-01T17:21:11.480296Z",
     "start_time": "2024-04-01T17:21:11.398238Z"
    }
   },
   "source": [
    "POSCAR_name = None\n",
    "\n",
    "# Get name for the first line of the POSCAR\n",
    "POSCAR_name = POSCAR_name or 'POSCAR from GenerativeModels'\n",
    "\n",
    "# Clone the input graph to preserve the original structure\n",
    "new_graph = temp.clone()\n",
    "\n",
    "# Load and detach embeddings for the graph nodes\n",
    "data_embeddings = new_graph.x.detach().cpu().numpy()\n",
    "\n",
    "# Loading dictionary of available embeddings for atoms\n",
    "available_embeddings = {}\n",
    "with open('../VASP/atomic_masses.dat', 'r') as atomic_masses_file:\n",
    "    for line in atomic_masses_file:\n",
    "        key, mass, charge, electronegativity, ionization_energy = line.split()\n",
    "\n",
    "        # Check if all information is present\n",
    "        if all(val != 'None' for val in (mass, charge, electronegativity, ionization_energy)):\n",
    "            available_embeddings[key] = np.array([mass, charge, electronegativity, ionization_energy], dtype=float)\n",
    "\n",
    "# Get most similar atoms for each graph node and create a list of keys\n",
    "keys = [find_closest_key(available_embeddings, emb) for emb in data_embeddings]\n",
    "\n",
    "# Get elements' composition, concentration, and positions\n",
    "POSCAR_composition, POSCAR_concentration, POSCAR_positions = composition_concentration_from_keys(keys, cartesian_positions)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f809aa30616ac841",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-01T17:21:12.112939Z",
     "start_time": "2024-04-01T17:21:12.084336Z"
    }
   },
   "source": [
    "# Write file\n",
    "with open('CONTCAR', 'w') as POSCAR_file:\n",
    "    # Delete previous data in the file\n",
    "    POSCAR_file.truncate()\n",
    "    \n",
    "    # Write POSCAR's name\n",
    "    POSCAR_file.write(f'{POSCAR_name}\\n')\n",
    "\n",
    "    # Write scaling factor (assumed to be 1.0)\n",
    "    POSCAR_file.write('1.0\\n')\n",
    "\n",
    "    # Write lattice parameters (assumed to be orthogonal)\n",
    "    np.savetxt(POSCAR_file, lattice_vectors, delimiter=' ')\n",
    "\n",
    "    # Write composition (each different species, previously sorted)\n",
    "    np.savetxt(POSCAR_file, [POSCAR_composition], fmt='%s', delimiter=' ')\n",
    "\n",
    "    # Write concentration (number of each of the previous elements)\n",
    "    np.savetxt(POSCAR_file, [POSCAR_concentration], fmt='%d', delimiter=' ')\n",
    "\n",
    "    # Write position in cartesian form\n",
    "    POSCAR_file.write('Cartesian\\n')\n",
    "    np.savetxt(POSCAR_file, POSCAR_positions, delimiter=' ')"
   ],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
